
zephyr.elf:     file format elf32-littlearm


Disassembly of section rom_start:

0000c000 <_vector_start>:
    c000:	20010688 	.word	0x20010688
    c004:	0000d21d 	.word	0x0000d21d
    c008:	0000f279 	.word	0x0000f279
    c00c:	0000d24d 	.word	0x0000d24d
    c010:	0000d24d 	.word	0x0000d24d
    c014:	0000d24d 	.word	0x0000d24d
    c018:	0000d24d 	.word	0x0000d24d
    c01c:	0000d24d 	.word	0x0000d24d
	...
    c02c:	0000d061 	.word	0x0000d061
    c030:	0000d24d 	.word	0x0000d24d
    c034:	00000000 	.word	0x00000000
    c038:	0000d009 	.word	0x0000d009
    c03c:	0000f259 	.word	0x0000f259

0000c040 <_irq_vector_table>:
    c040:	0000d1dd 0000d1dd 0000d1dd 0000d1dd     ................
    c050:	0000d1dd 0000d1dd 0000d1dd 0000d1dd     ................
    c060:	0000d1dd 0000d1dd 0000d1dd 0000d1dd     ................
    c070:	0000d1dd 0000d1dd 0000d1dd 0000d1dd     ................
    c080:	0000d1dd 0000d1dd 0000d1dd 0000d1dd     ................
    c090:	0000d1dd 0000d1dd 0000d1dd 0000d1dd     ................
    c0a0:	0000d1dd 0000d1dd 0000d1dd 0000d1dd     ................
    c0b0:	0000d1dd 0000d1dd 0000d1dd 0000d1dd     ................
    c0c0:	0000d1dd 0000d1dd 0000d1dd 0000d1dd     ................
    c0d0:	0000d1dd 0000d1dd 0000d1dd 0000d1dd     ................
    c0e0:	0000d1dd 0000d1dd 0000d1dd 0000d1dd     ................
    c0f0:	0000d1dd 0000d1dd 0000d1dd 0000d1dd     ................
    c100:	0000d1dd 0000d1dd 0000d1dd 0000d1dd     ................
    c110:	0000d1dd 0000d1dd 0000d1dd 0000d1dd     ................
    c120:	0000d1dd 0000d1dd 0000d1dd 0000d1dd     ................
    c130:	0000d1dd 0000d1dd 0000d1dd 0000d1dd     ................
    c140:	0000d1dd                                ....

0000c144 <_vector_end>:
	...

0000c200 <m_firmware_info>:
    c200:	281ee6de 8fcebb4c 00005b02 0000003c     ...(L....[..<...
    c210:	00003c4c 00000001 0000c000 0000c000     L<..............
    c220:	9102ffff 00000000 00000000 00000000     ................
	...

Disassembly of section text:

0000c23c <__aeabi_uldivmod>:
    c23c:	b953      	cbnz	r3, c254 <__aeabi_uldivmod+0x18>
    c23e:	b94a      	cbnz	r2, c254 <__aeabi_uldivmod+0x18>
    c240:	2900      	cmp	r1, #0
    c242:	bf08      	it	eq
    c244:	2800      	cmpeq	r0, #0
    c246:	bf1c      	itt	ne
    c248:	f04f 31ff 	movne.w	r1, #4294967295
    c24c:	f04f 30ff 	movne.w	r0, #4294967295
    c250:	f000 b970 	b.w	c534 <__aeabi_idiv0>
    c254:	f1ad 0c08 	sub.w	ip, sp, #8
    c258:	e96d ce04 	strd	ip, lr, [sp, #-16]!
    c25c:	f000 f806 	bl	c26c <__udivmoddi4>
    c260:	f8dd e004 	ldr.w	lr, [sp, #4]
    c264:	e9dd 2302 	ldrd	r2, r3, [sp, #8]
    c268:	b004      	add	sp, #16
    c26a:	4770      	bx	lr

0000c26c <__udivmoddi4>:
    c26c:	e92d 47f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
    c270:	9e08      	ldr	r6, [sp, #32]
    c272:	460d      	mov	r5, r1
    c274:	4604      	mov	r4, r0
    c276:	468a      	mov	sl, r1
    c278:	2b00      	cmp	r3, #0
    c27a:	d17f      	bne.n	c37c <__udivmoddi4+0x110>
    c27c:	428a      	cmp	r2, r1
    c27e:	4617      	mov	r7, r2
    c280:	d941      	bls.n	c306 <__udivmoddi4+0x9a>
    c282:	fab2 f282 	clz	r2, r2
    c286:	b14a      	cbz	r2, c29c <__udivmoddi4+0x30>
    c288:	f1c2 0120 	rsb	r1, r2, #32
    c28c:	fa05 f302 	lsl.w	r3, r5, r2
    c290:	4097      	lsls	r7, r2
    c292:	4094      	lsls	r4, r2
    c294:	fa20 f101 	lsr.w	r1, r0, r1
    c298:	ea41 0a03 	orr.w	sl, r1, r3
    c29c:	ea4f 4817 	mov.w	r8, r7, lsr #16
    c2a0:	ea4f 4c14 	mov.w	ip, r4, lsr #16
    c2a4:	fa1f f987 	uxth.w	r9, r7
    c2a8:	fbba fef8 	udiv	lr, sl, r8
    c2ac:	fb08 a31e 	mls	r3, r8, lr, sl
    c2b0:	fb0e f109 	mul.w	r1, lr, r9
    c2b4:	ea4c 4303 	orr.w	r3, ip, r3, lsl #16
    c2b8:	4299      	cmp	r1, r3
    c2ba:	d906      	bls.n	c2ca <__udivmoddi4+0x5e>
    c2bc:	18fb      	adds	r3, r7, r3
    c2be:	d202      	bcs.n	c2c6 <__udivmoddi4+0x5a>
    c2c0:	4299      	cmp	r1, r3
    c2c2:	f200 8124 	bhi.w	c50e <__udivmoddi4+0x2a2>
    c2c6:	f10e 3eff 	add.w	lr, lr, #4294967295
    c2ca:	1a59      	subs	r1, r3, r1
    c2cc:	b2a3      	uxth	r3, r4
    c2ce:	fbb1 f0f8 	udiv	r0, r1, r8
    c2d2:	fb08 1110 	mls	r1, r8, r0, r1
    c2d6:	fb00 f909 	mul.w	r9, r0, r9
    c2da:	ea43 4401 	orr.w	r4, r3, r1, lsl #16
    c2de:	45a1      	cmp	r9, r4
    c2e0:	d905      	bls.n	c2ee <__udivmoddi4+0x82>
    c2e2:	193c      	adds	r4, r7, r4
    c2e4:	d202      	bcs.n	c2ec <__udivmoddi4+0x80>
    c2e6:	45a1      	cmp	r9, r4
    c2e8:	f200 810e 	bhi.w	c508 <__udivmoddi4+0x29c>
    c2ec:	3801      	subs	r0, #1
    c2ee:	eba4 0409 	sub.w	r4, r4, r9
    c2f2:	ea40 400e 	orr.w	r0, r0, lr, lsl #16
    c2f6:	2100      	movs	r1, #0
    c2f8:	b11e      	cbz	r6, c302 <__udivmoddi4+0x96>
    c2fa:	40d4      	lsrs	r4, r2
    c2fc:	2300      	movs	r3, #0
    c2fe:	e9c6 4300 	strd	r4, r3, [r6]
    c302:	e8bd 87f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, pc}
    c306:	b902      	cbnz	r2, c30a <__udivmoddi4+0x9e>
    c308:	deff      	udf	#255	; 0xff
    c30a:	fab2 f282 	clz	r2, r2
    c30e:	2a00      	cmp	r2, #0
    c310:	d14f      	bne.n	c3b2 <__udivmoddi4+0x146>
    c312:	1bcb      	subs	r3, r1, r7
    c314:	ea4f 4e17 	mov.w	lr, r7, lsr #16
    c318:	fa1f f887 	uxth.w	r8, r7
    c31c:	2101      	movs	r1, #1
    c31e:	0c25      	lsrs	r5, r4, #16
    c320:	fbb3 fcfe 	udiv	ip, r3, lr
    c324:	fb0e 301c 	mls	r0, lr, ip, r3
    c328:	462b      	mov	r3, r5
    c32a:	fb08 f90c 	mul.w	r9, r8, ip
    c32e:	ea45 4500 	orr.w	r5, r5, r0, lsl #16
    c332:	45a9      	cmp	r9, r5
    c334:	d90a      	bls.n	c34c <__udivmoddi4+0xe0>
    c336:	197d      	adds	r5, r7, r5
    c338:	bf2c      	ite	cs
    c33a:	2301      	movcs	r3, #1
    c33c:	2300      	movcc	r3, #0
    c33e:	45a9      	cmp	r9, r5
    c340:	d902      	bls.n	c348 <__udivmoddi4+0xdc>
    c342:	2b00      	cmp	r3, #0
    c344:	f000 80d9 	beq.w	c4fa <__udivmoddi4+0x28e>
    c348:	f10c 3cff 	add.w	ip, ip, #4294967295
    c34c:	eba5 0509 	sub.w	r5, r5, r9
    c350:	b2a3      	uxth	r3, r4
    c352:	fbb5 f0fe 	udiv	r0, r5, lr
    c356:	fb0e 5510 	mls	r5, lr, r0, r5
    c35a:	fb08 f800 	mul.w	r8, r8, r0
    c35e:	ea43 4405 	orr.w	r4, r3, r5, lsl #16
    c362:	45a0      	cmp	r8, r4
    c364:	d905      	bls.n	c372 <__udivmoddi4+0x106>
    c366:	193c      	adds	r4, r7, r4
    c368:	d202      	bcs.n	c370 <__udivmoddi4+0x104>
    c36a:	45a0      	cmp	r8, r4
    c36c:	f200 80c9 	bhi.w	c502 <__udivmoddi4+0x296>
    c370:	3801      	subs	r0, #1
    c372:	eba4 0408 	sub.w	r4, r4, r8
    c376:	ea40 400c 	orr.w	r0, r0, ip, lsl #16
    c37a:	e7bd      	b.n	c2f8 <__udivmoddi4+0x8c>
    c37c:	428b      	cmp	r3, r1
    c37e:	d908      	bls.n	c392 <__udivmoddi4+0x126>
    c380:	2e00      	cmp	r6, #0
    c382:	f000 80b1 	beq.w	c4e8 <__udivmoddi4+0x27c>
    c386:	2100      	movs	r1, #0
    c388:	e9c6 0500 	strd	r0, r5, [r6]
    c38c:	4608      	mov	r0, r1
    c38e:	e8bd 87f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, pc}
    c392:	fab3 f183 	clz	r1, r3
    c396:	2900      	cmp	r1, #0
    c398:	d146      	bne.n	c428 <__udivmoddi4+0x1bc>
    c39a:	42ab      	cmp	r3, r5
    c39c:	f0c0 80a7 	bcc.w	c4ee <__udivmoddi4+0x282>
    c3a0:	4282      	cmp	r2, r0
    c3a2:	f240 80a4 	bls.w	c4ee <__udivmoddi4+0x282>
    c3a6:	4608      	mov	r0, r1
    c3a8:	2e00      	cmp	r6, #0
    c3aa:	d0aa      	beq.n	c302 <__udivmoddi4+0x96>
    c3ac:	e9c6 4a00 	strd	r4, sl, [r6]
    c3b0:	e7a7      	b.n	c302 <__udivmoddi4+0x96>
    c3b2:	f1c2 0020 	rsb	r0, r2, #32
    c3b6:	4097      	lsls	r7, r2
    c3b8:	fa01 f302 	lsl.w	r3, r1, r2
    c3bc:	ea4f 4e17 	mov.w	lr, r7, lsr #16
    c3c0:	40c1      	lsrs	r1, r0
    c3c2:	fa24 f500 	lsr.w	r5, r4, r0
    c3c6:	fa1f f887 	uxth.w	r8, r7
    c3ca:	4094      	lsls	r4, r2
    c3cc:	431d      	orrs	r5, r3
    c3ce:	fbb1 f0fe 	udiv	r0, r1, lr
    c3d2:	0c2b      	lsrs	r3, r5, #16
    c3d4:	fb0e 1110 	mls	r1, lr, r0, r1
    c3d8:	fb00 fc08 	mul.w	ip, r0, r8
    c3dc:	ea43 4301 	orr.w	r3, r3, r1, lsl #16
    c3e0:	459c      	cmp	ip, r3
    c3e2:	d909      	bls.n	c3f8 <__udivmoddi4+0x18c>
    c3e4:	18fb      	adds	r3, r7, r3
    c3e6:	bf2c      	ite	cs
    c3e8:	2101      	movcs	r1, #1
    c3ea:	2100      	movcc	r1, #0
    c3ec:	459c      	cmp	ip, r3
    c3ee:	d902      	bls.n	c3f6 <__udivmoddi4+0x18a>
    c3f0:	2900      	cmp	r1, #0
    c3f2:	f000 8095 	beq.w	c520 <__udivmoddi4+0x2b4>
    c3f6:	3801      	subs	r0, #1
    c3f8:	eba3 030c 	sub.w	r3, r3, ip
    c3fc:	b2ad      	uxth	r5, r5
    c3fe:	fbb3 f1fe 	udiv	r1, r3, lr
    c402:	fb0e 3311 	mls	r3, lr, r1, r3
    c406:	fb01 fc08 	mul.w	ip, r1, r8
    c40a:	ea45 4503 	orr.w	r5, r5, r3, lsl #16
    c40e:	45ac      	cmp	ip, r5
    c410:	d905      	bls.n	c41e <__udivmoddi4+0x1b2>
    c412:	197d      	adds	r5, r7, r5
    c414:	d202      	bcs.n	c41c <__udivmoddi4+0x1b0>
    c416:	45ac      	cmp	ip, r5
    c418:	f200 8089 	bhi.w	c52e <__udivmoddi4+0x2c2>
    c41c:	3901      	subs	r1, #1
    c41e:	eba5 030c 	sub.w	r3, r5, ip
    c422:	ea41 4100 	orr.w	r1, r1, r0, lsl #16
    c426:	e77a      	b.n	c31e <__udivmoddi4+0xb2>
    c428:	f1c1 0420 	rsb	r4, r1, #32
    c42c:	408b      	lsls	r3, r1
    c42e:	fa02 f701 	lsl.w	r7, r2, r1
    c432:	fa05 fc01 	lsl.w	ip, r5, r1
    c436:	40e2      	lsrs	r2, r4
    c438:	fa20 f804 	lsr.w	r8, r0, r4
    c43c:	40e5      	lsrs	r5, r4
    c43e:	fa00 fe01 	lsl.w	lr, r0, r1
    c442:	4313      	orrs	r3, r2
    c444:	ea48 020c 	orr.w	r2, r8, ip
    c448:	ea4f 4813 	mov.w	r8, r3, lsr #16
    c44c:	ea4f 4c12 	mov.w	ip, r2, lsr #16
    c450:	fa1f f983 	uxth.w	r9, r3
    c454:	fbb5 faf8 	udiv	sl, r5, r8
    c458:	fb08 551a 	mls	r5, r8, sl, r5
    c45c:	fb0a f009 	mul.w	r0, sl, r9
    c460:	ea4c 4c05 	orr.w	ip, ip, r5, lsl #16
    c464:	4560      	cmp	r0, ip
    c466:	d90a      	bls.n	c47e <__udivmoddi4+0x212>
    c468:	eb13 0c0c 	adds.w	ip, r3, ip
    c46c:	bf2c      	ite	cs
    c46e:	2501      	movcs	r5, #1
    c470:	2500      	movcc	r5, #0
    c472:	4560      	cmp	r0, ip
    c474:	d901      	bls.n	c47a <__udivmoddi4+0x20e>
    c476:	2d00      	cmp	r5, #0
    c478:	d055      	beq.n	c526 <__udivmoddi4+0x2ba>
    c47a:	f10a 3aff 	add.w	sl, sl, #4294967295
    c47e:	ebac 0c00 	sub.w	ip, ip, r0
    c482:	b292      	uxth	r2, r2
    c484:	fbbc f0f8 	udiv	r0, ip, r8
    c488:	fb08 cc10 	mls	ip, r8, r0, ip
    c48c:	fb00 f909 	mul.w	r9, r0, r9
    c490:	ea42 4c0c 	orr.w	ip, r2, ip, lsl #16
    c494:	45e1      	cmp	r9, ip
    c496:	d905      	bls.n	c4a4 <__udivmoddi4+0x238>
    c498:	eb13 0c0c 	adds.w	ip, r3, ip
    c49c:	d201      	bcs.n	c4a2 <__udivmoddi4+0x236>
    c49e:	45e1      	cmp	r9, ip
    c4a0:	d83b      	bhi.n	c51a <__udivmoddi4+0x2ae>
    c4a2:	3801      	subs	r0, #1
    c4a4:	ea40 400a 	orr.w	r0, r0, sl, lsl #16
    c4a8:	ebac 0c09 	sub.w	ip, ip, r9
    c4ac:	fba0 8907 	umull	r8, r9, r0, r7
    c4b0:	45cc      	cmp	ip, r9
    c4b2:	4645      	mov	r5, r8
    c4b4:	464a      	mov	r2, r9
    c4b6:	d302      	bcc.n	c4be <__udivmoddi4+0x252>
    c4b8:	d106      	bne.n	c4c8 <__udivmoddi4+0x25c>
    c4ba:	45c6      	cmp	lr, r8
    c4bc:	d204      	bcs.n	c4c8 <__udivmoddi4+0x25c>
    c4be:	3801      	subs	r0, #1
    c4c0:	ebb8 0507 	subs.w	r5, r8, r7
    c4c4:	eb69 0203 	sbc.w	r2, r9, r3
    c4c8:	b32e      	cbz	r6, c516 <__udivmoddi4+0x2aa>
    c4ca:	ebbe 0305 	subs.w	r3, lr, r5
    c4ce:	eb6c 0c02 	sbc.w	ip, ip, r2
    c4d2:	fa23 f201 	lsr.w	r2, r3, r1
    c4d6:	fa0c f404 	lsl.w	r4, ip, r4
    c4da:	fa2c f301 	lsr.w	r3, ip, r1
    c4de:	2100      	movs	r1, #0
    c4e0:	4314      	orrs	r4, r2
    c4e2:	e9c6 4300 	strd	r4, r3, [r6]
    c4e6:	e70c      	b.n	c302 <__udivmoddi4+0x96>
    c4e8:	4631      	mov	r1, r6
    c4ea:	4630      	mov	r0, r6
    c4ec:	e709      	b.n	c302 <__udivmoddi4+0x96>
    c4ee:	1a84      	subs	r4, r0, r2
    c4f0:	eb65 0303 	sbc.w	r3, r5, r3
    c4f4:	2001      	movs	r0, #1
    c4f6:	469a      	mov	sl, r3
    c4f8:	e756      	b.n	c3a8 <__udivmoddi4+0x13c>
    c4fa:	f1ac 0c02 	sub.w	ip, ip, #2
    c4fe:	443d      	add	r5, r7
    c500:	e724      	b.n	c34c <__udivmoddi4+0xe0>
    c502:	3802      	subs	r0, #2
    c504:	443c      	add	r4, r7
    c506:	e734      	b.n	c372 <__udivmoddi4+0x106>
    c508:	3802      	subs	r0, #2
    c50a:	443c      	add	r4, r7
    c50c:	e6ef      	b.n	c2ee <__udivmoddi4+0x82>
    c50e:	f1ae 0e02 	sub.w	lr, lr, #2
    c512:	443b      	add	r3, r7
    c514:	e6d9      	b.n	c2ca <__udivmoddi4+0x5e>
    c516:	4631      	mov	r1, r6
    c518:	e6f3      	b.n	c302 <__udivmoddi4+0x96>
    c51a:	3802      	subs	r0, #2
    c51c:	449c      	add	ip, r3
    c51e:	e7c1      	b.n	c4a4 <__udivmoddi4+0x238>
    c520:	3802      	subs	r0, #2
    c522:	443b      	add	r3, r7
    c524:	e768      	b.n	c3f8 <__udivmoddi4+0x18c>
    c526:	f1aa 0a02 	sub.w	sl, sl, #2
    c52a:	449c      	add	ip, r3
    c52c:	e7a7      	b.n	c47e <__udivmoddi4+0x212>
    c52e:	3902      	subs	r1, #2
    c530:	443d      	add	r5, r7
    c532:	e774      	b.n	c41e <__udivmoddi4+0x1b2>

0000c534 <__aeabi_idiv0>:
    c534:	4770      	bx	lr
    c536:	bf00      	nop

0000c538 <main>:

/* 1000 msec = 1 sec */
#define SLEEP_TIME 	1000

void main(void)
{
    c538:	b538      	push	{r3, r4, r5, lr}
	if (z_syscall_trap()) {
		return (const struct device *) arch_syscall_invoke1(*(uintptr_t *)&name, K_SYSCALL_DEVICE_GET_BINDING);
	}
#endif
	compiler_barrier();
	return z_impl_device_get_binding(name);
    c53a:	4813      	ldr	r0, [pc, #76]	; (c588 <main+0x50>)
    c53c:	f001 fdb6 	bl	e0ac <z_impl_device_get_binding>
    c540:	4604      	mov	r4, r0
	int cnt = 0;
	struct device *dev;

	dev = device_get_binding("GPIO_0");
	/* Set LED pin as output */
	gpio_pin_configure(dev, 3, GPIO_OUTPUT); //p0.03 == LED2
    c542:	2103      	movs	r1, #3
    c544:	f002 fc1f 	bl	ed86 <gpio_pin_configure.constprop.0>
	gpio_pin_configure(dev, 4, GPIO_OUTPUT); //p0.04 == LED3
    c548:	2104      	movs	r1, #4
    c54a:	4620      	mov	r0, r4
    c54c:	f002 fc1b 	bl	ed86 <gpio_pin_configure.constprop.0>
	gpio_pin_configure(dev, 17, GPIO_OUTPUT); //p0.17
    c550:	2111      	movs	r1, #17
    c552:	4620      	mov	r0, r4
    c554:	f002 fc17 	bl	ed86 <gpio_pin_configure.constprop.0>
	int cnt = 0;
    c558:	2500      	movs	r5, #0

	while (1) {
		/* Set pin to HIGH/LOW every 1 second */
        if(cnt % 2 == 0)
    c55a:	07eb      	lsls	r3, r5, #31
    c55c:	d40c      	bmi.n	c578 <main+0x40>
	if (z_syscall_trap()) {
		return (int) arch_syscall_invoke2(*(uintptr_t *)&port, *(uintptr_t *)&pins, K_SYSCALL_GPIO_PORT_TOGGLE_BITS);
	}
#endif
	compiler_barrier();
	return z_impl_gpio_port_toggle_bits(port, pins);
    c55e:	2108      	movs	r1, #8
    c560:	4620      	mov	r0, r4
    c562:	f002 fc0d 	bl	ed80 <z_impl_gpio_port_toggle_bits>
    c566:	2110      	movs	r1, #16
    c568:	4620      	mov	r0, r4
    c56a:	f002 fc09 	bl	ed80 <z_impl_gpio_port_toggle_bits>
    c56e:	f44f 3100 	mov.w	r1, #131072	; 0x20000
    c572:	4620      	mov	r0, r4
    c574:	f002 fc04 	bl	ed80 <z_impl_gpio_port_toggle_bits>
            gpio_pin_toggle(dev, 3);	//p0.03 == LED2
		    gpio_pin_toggle(dev, 4);	//p0.04 == LED3
		    gpio_pin_toggle(dev, 17);
        }
			//p0.17 Toggling pin 17
		cnt++;
    c578:	3501      	adds	r5, #1
		parm0.val = timeout;
		return (int32_t) arch_syscall_invoke2(parm0.split.lo, parm0.split.hi, K_SYSCALL_K_SLEEP);
	}
#endif
	compiler_barrier();
	return z_impl_k_sleep(timeout);
    c57a:	2100      	movs	r1, #0
    c57c:	f44f 4000 	mov.w	r0, #32768	; 0x8000
    c580:	f002 f996 	bl	e8b0 <z_impl_k_sleep>
 * @return Zero if the requested time has elapsed or the number of milliseconds
 * left to sleep, if thread was woken up by \ref k_wakeup call.
 */
static inline int32_t k_msleep(int32_t ms)
{
	return k_sleep(Z_TIMEOUT_MS(ms));
    c584:	e7e9      	b.n	c55a <main+0x22>
    c586:	bf00      	nop
    c588:	0000fadc 	.word	0x0000fadc

0000c58c <print_digits>:
}
#endif /* CONFIG_PRINTK */

static void print_digits(out_func_t out, void *ctx, printk_val_t num, int base,
			 bool pad_before, char pad_char, int min_width)
{
    c58c:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
    c590:	b087      	sub	sp, #28
    c592:	460f      	mov	r7, r1
    c594:	4619      	mov	r1, r3
	char buf[DIGITS_BUFLEN];
	int i;

	/* Print it backwards into the end of the buffer, low digits first */
	for (i = DIGITS_BUFLEN - 1; num != 0; i--) {
		buf[i] = "0123456789abcdef"[num % base];
    c596:	9b10      	ldr	r3, [sp, #64]	; 0x40
{
    c598:	4606      	mov	r6, r0
	for (i = DIGITS_BUFLEN - 1; num != 0; i--) {
    c59a:	2514      	movs	r5, #20
{
    c59c:	4610      	mov	r0, r2
		buf[i] = "0123456789abcdef"[num % base];
    c59e:	4698      	mov	r8, r3
{
    c5a0:	f89d b044 	ldrb.w	fp, [sp, #68]	; 0x44
    c5a4:	f89d a048 	ldrb.w	sl, [sp, #72]	; 0x48
		buf[i] = "0123456789abcdef"[num % base];
    c5a8:	4c1e      	ldr	r4, [pc, #120]	; (c624 <print_digits+0x98>)
    c5aa:	ea4f 79e3 	mov.w	r9, r3, asr #31
	for (i = DIGITS_BUFLEN - 1; num != 0; i--) {
    c5ae:	ea50 0301 	orrs.w	r3, r0, r1
    c5b2:	d11a      	bne.n	c5ea <print_digits+0x5e>
		num /= base;
	}

	if (i == DIGITS_BUFLEN - 1) {
    c5b4:	2d14      	cmp	r5, #20
		buf[i] = '0';
    c5b6:	bf08      	it	eq
    c5b8:	2330      	moveq	r3, #48	; 0x30
	} else {
		i++;
	}

	int pad = MAX(min_width - (DIGITS_BUFLEN - i), 0);
    c5ba:	9c13      	ldr	r4, [sp, #76]	; 0x4c
		i++;
    c5bc:	bf18      	it	ne
    c5be:	3501      	addne	r5, #1
	int pad = MAX(min_width - (DIGITS_BUFLEN - i), 0);
    c5c0:	442c      	add	r4, r5
		buf[i] = '0';
    c5c2:	bf08      	it	eq
    c5c4:	f88d 3014 	strbeq.w	r3, [sp, #20]
	int pad = MAX(min_width - (DIGITS_BUFLEN - i), 0);
    c5c8:	2c15      	cmp	r4, #21
    c5ca:	d01b      	beq.n	c604 <print_digits+0x78>
    c5cc:	3c15      	subs	r4, #21

	for (/**/; pad > 0 && pad_before; pad--) {
    c5ce:	2c00      	cmp	r4, #0
    c5d0:	dc1a      	bgt.n	c608 <print_digits+0x7c>
		out(pad_char, ctx);
	}
	for (/**/; i < DIGITS_BUFLEN; i++) {
		out(buf[i], ctx);
    c5d2:	f81d 0005 	ldrb.w	r0, [sp, r5]
    c5d6:	4639      	mov	r1, r7
	for (/**/; i < DIGITS_BUFLEN; i++) {
    c5d8:	3501      	adds	r5, #1
		out(buf[i], ctx);
    c5da:	47b0      	blx	r6
	for (/**/; i < DIGITS_BUFLEN; i++) {
    c5dc:	2d15      	cmp	r5, #21
    c5de:	d1f8      	bne.n	c5d2 <print_digits+0x46>
	}
	for (/**/; pad > 0; pad--) {
    c5e0:	2c00      	cmp	r4, #0
    c5e2:	dc19      	bgt.n	c618 <print_digits+0x8c>
		out(pad_char, ctx);
	}
}
    c5e4:	b007      	add	sp, #28
    c5e6:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
		buf[i] = "0123456789abcdef"[num % base];
    c5ea:	4642      	mov	r2, r8
    c5ec:	464b      	mov	r3, r9
    c5ee:	f7ff fe25 	bl	c23c <__aeabi_uldivmod>
    c5f2:	4684      	mov	ip, r0
    c5f4:	460b      	mov	r3, r1
    c5f6:	5ca2      	ldrb	r2, [r4, r2]
		num /= base;
    c5f8:	4660      	mov	r0, ip
		buf[i] = "0123456789abcdef"[num % base];
    c5fa:	f80d 2005 	strb.w	r2, [sp, r5]
		num /= base;
    c5fe:	4619      	mov	r1, r3
	for (i = DIGITS_BUFLEN - 1; num != 0; i--) {
    c600:	3d01      	subs	r5, #1
    c602:	e7d4      	b.n	c5ae <print_digits+0x22>
	int pad = MAX(min_width - (DIGITS_BUFLEN - i), 0);
    c604:	2400      	movs	r4, #0
	for (/**/; i < DIGITS_BUFLEN; i++) {
    c606:	e7e4      	b.n	c5d2 <print_digits+0x46>
	for (/**/; pad > 0 && pad_before; pad--) {
    c608:	f1bb 0f00 	cmp.w	fp, #0
    c60c:	d0e1      	beq.n	c5d2 <print_digits+0x46>
		out(pad_char, ctx);
    c60e:	4639      	mov	r1, r7
    c610:	4650      	mov	r0, sl
    c612:	47b0      	blx	r6
	for (/**/; pad > 0 && pad_before; pad--) {
    c614:	3c01      	subs	r4, #1
    c616:	e7da      	b.n	c5ce <print_digits+0x42>
		out(pad_char, ctx);
    c618:	4639      	mov	r1, r7
    c61a:	4650      	mov	r0, sl
    c61c:	47b0      	blx	r6
	for (/**/; pad > 0; pad--) {
    c61e:	3c01      	subs	r4, #1
    c620:	e7de      	b.n	c5e0 <print_digits+0x54>
    c622:	bf00      	nop
    c624:	0000fae3 	.word	0x0000fae3

0000c628 <char_out>:

static int char_out(int c, void *ctx_p)
{
	struct out_context *ctx = ctx_p;

	ctx->count++;
    c628:	680b      	ldr	r3, [r1, #0]
    c62a:	3301      	adds	r3, #1
    c62c:	600b      	str	r3, [r1, #0]
	return _char_out(c);
    c62e:	4b01      	ldr	r3, [pc, #4]	; (c634 <char_out+0xc>)
    c630:	681b      	ldr	r3, [r3, #0]
    c632:	4718      	bx	r3
    c634:	20010000 	.word	0x20010000

0000c638 <__printk_hook_install>:
	_char_out = fn;
    c638:	4b01      	ldr	r3, [pc, #4]	; (c640 <__printk_hook_install+0x8>)
    c63a:	6018      	str	r0, [r3, #0]
}
    c63c:	4770      	bx	lr
    c63e:	bf00      	nop
    c640:	20010000 	.word	0x20010000

0000c644 <z_vprintk>:
{
    c644:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
	char length_mod = 0;
    c648:	2600      	movs	r6, #0
{
    c64a:	4605      	mov	r5, r0
    c64c:	468b      	mov	fp, r1
    c64e:	461c      	mov	r4, r3
	int min_width = -1;
    c650:	f04f 38ff 	mov.w	r8, #4294967295
	enum pad_type padding = PAD_NONE;
    c654:	4637      	mov	r7, r6
{
    c656:	b087      	sub	sp, #28
    c658:	f102 3aff 	add.w	sl, r2, #4294967295
			might_format = 0;
    c65c:	f04f 0900 	mov.w	r9, #0
					break;
    c660:	e007      	b.n	c672 <z_vprintk+0x2e>
		if (!might_format) {
    c662:	f1b9 0f00 	cmp.w	r9, #0
    c666:	d10b      	bne.n	c680 <z_vprintk+0x3c>
			if (*fmt != '%') {
    c668:	2825      	cmp	r0, #37	; 0x25
    c66a:	f000 810a 	beq.w	c882 <z_vprintk+0x23e>
				out((int)*fmt, ctx);
    c66e:	4659      	mov	r1, fp
    c670:	47a8      	blx	r5
	while (*fmt) {
    c672:	f81a 0f01 	ldrb.w	r0, [sl, #1]!
    c676:	2800      	cmp	r0, #0
    c678:	d1f3      	bne.n	c662 <z_vprintk+0x1e>
}
    c67a:	b007      	add	sp, #28
    c67c:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
			switch (*fmt) {
    c680:	287a      	cmp	r0, #122	; 0x7a
    c682:	d80a      	bhi.n	c69a <z_vprintk+0x56>
    c684:	2862      	cmp	r0, #98	; 0x62
    c686:	d810      	bhi.n	c6aa <z_vprintk+0x66>
    c688:	2830      	cmp	r0, #48	; 0x30
    c68a:	d051      	beq.n	c730 <z_vprintk+0xec>
    c68c:	d844      	bhi.n	c718 <z_vprintk+0xd4>
    c68e:	2825      	cmp	r0, #37	; 0x25
    c690:	f000 80f5 	beq.w	c87e <z_vprintk+0x23a>
    c694:	282d      	cmp	r0, #45	; 0x2d
    c696:	f000 80fb 	beq.w	c890 <z_vprintk+0x24c>
					out((int)'%', ctx);
    c69a:	4659      	mov	r1, fp
    c69c:	2025      	movs	r0, #37	; 0x25
    c69e:	47a8      	blx	r5
					out((int)*fmt, ctx);
    c6a0:	4659      	mov	r1, fp
    c6a2:	f89a 0000 	ldrb.w	r0, [sl]
    c6a6:	47a8      	blx	r5
    c6a8:	e7d8      	b.n	c65c <z_vprintk+0x18>
    c6aa:	f1a0 0363 	sub.w	r3, r0, #99	; 0x63
    c6ae:	2b17      	cmp	r3, #23
    c6b0:	d8f3      	bhi.n	c69a <z_vprintk+0x56>
    c6b2:	a201      	add	r2, pc, #4	; (adr r2, c6b8 <z_vprintk+0x74>)
    c6b4:	f852 f023 	ldr.w	pc, [r2, r3, lsl #2]
    c6b8:	0000c877 	.word	0x0000c877
    c6bc:	0000c779 	.word	0x0000c779
    c6c0:	0000c69b 	.word	0x0000c69b
    c6c4:	0000c69b 	.word	0x0000c69b
    c6c8:	0000c69b 	.word	0x0000c69b
    c6cc:	0000c75b 	.word	0x0000c75b
    c6d0:	0000c779 	.word	0x0000c779
    c6d4:	0000c69b 	.word	0x0000c69b
    c6d8:	0000c69b 	.word	0x0000c69b
    c6dc:	0000c75b 	.word	0x0000c75b
    c6e0:	0000c69b 	.word	0x0000c69b
    c6e4:	0000c69b 	.word	0x0000c69b
    c6e8:	0000c69b 	.word	0x0000c69b
    c6ec:	0000c7f3 	.word	0x0000c7f3
    c6f0:	0000c69b 	.word	0x0000c69b
    c6f4:	0000c69b 	.word	0x0000c69b
    c6f8:	0000c83f 	.word	0x0000c83f
    c6fc:	0000c69b 	.word	0x0000c69b
    c700:	0000c779 	.word	0x0000c779
    c704:	0000c69b 	.word	0x0000c69b
    c708:	0000c69b 	.word	0x0000c69b
    c70c:	0000c721 	.word	0x0000c721
    c710:	0000c69b 	.word	0x0000c69b
    c714:	0000c75b 	.word	0x0000c75b
			switch (*fmt) {
    c718:	2839      	cmp	r0, #57	; 0x39
    c71a:	d915      	bls.n	c748 <z_vprintk+0x104>
    c71c:	2858      	cmp	r0, #88	; 0x58
    c71e:	d1bc      	bne.n	c69a <z_vprintk+0x56>
				if (*fmt == 'p') {
    c720:	f89a 3000 	ldrb.w	r3, [sl]
    c724:	2b70      	cmp	r3, #112	; 0x70
    c726:	d16e      	bne.n	c806 <z_vprintk+0x1c2>
					x = va_arg(ap, unsigned int);
    c728:	2300      	movs	r3, #0
    c72a:	f854 2b04 	ldr.w	r2, [r4], #4
    c72e:	e075      	b.n	c81c <z_vprintk+0x1d8>
				if (min_width < 0 && padding == PAD_NONE) {
    c730:	f1b8 0f00 	cmp.w	r8, #0
    c734:	da0b      	bge.n	c74e <z_vprintk+0x10a>
    c736:	2f00      	cmp	r7, #0
    c738:	f000 80ac 	beq.w	c894 <z_vprintk+0x250>
					min_width = *fmt - '0';
    c73c:	f1a0 0830 	sub.w	r8, r0, #48	; 0x30
					padding = PAD_SPACE_BEFORE;
    c740:	2f00      	cmp	r7, #0
    c742:	bf08      	it	eq
    c744:	2702      	moveq	r7, #2
    c746:	e794      	b.n	c672 <z_vprintk+0x2e>
				if (min_width < 0) {
    c748:	f1b8 0f00 	cmp.w	r8, #0
    c74c:	dbf6      	blt.n	c73c <z_vprintk+0xf8>
					min_width = 10 * min_width + *fmt - '0';
    c74e:	230a      	movs	r3, #10
    c750:	fb03 0808 	mla	r8, r3, r8, r0
    c754:	f1a8 0830 	sub.w	r8, r8, #48	; 0x30
    c758:	e7f2      	b.n	c740 <z_vprintk+0xfc>
				if (*fmt == 'h' && length_mod == 'h') {
    c75a:	2868      	cmp	r0, #104	; 0x68
    c75c:	d103      	bne.n	c766 <z_vprintk+0x122>
    c75e:	2e68      	cmp	r6, #104	; 0x68
    c760:	d106      	bne.n	c770 <z_vprintk+0x12c>
					length_mod = 'H';
    c762:	2648      	movs	r6, #72	; 0x48
    c764:	e785      	b.n	c672 <z_vprintk+0x2e>
				} else if (*fmt == 'l' && length_mod == 'l') {
    c766:	286c      	cmp	r0, #108	; 0x6c
    c768:	d102      	bne.n	c770 <z_vprintk+0x12c>
    c76a:	2e6c      	cmp	r6, #108	; 0x6c
    c76c:	f000 8094 	beq.w	c898 <z_vprintk+0x254>
				} else if (length_mod == 0) {
    c770:	2e00      	cmp	r6, #0
    c772:	d192      	bne.n	c69a <z_vprintk+0x56>
    c774:	4606      	mov	r6, r0
    c776:	e77c      	b.n	c672 <z_vprintk+0x2e>
				if (length_mod == 'z') {
    c778:	2e7a      	cmp	r6, #122	; 0x7a
    c77a:	d106      	bne.n	c78a <z_vprintk+0x146>
					d = va_arg(ap, long);
    c77c:	46a1      	mov	r9, r4
    c77e:	f859 2b04 	ldr.w	r2, [r9], #4
    c782:	17d3      	asrs	r3, r2, #31
				if (*fmt != 'u' && negative(d)) {
    c784:	2875      	cmp	r0, #117	; 0x75
    c786:	d123      	bne.n	c7d0 <z_vprintk+0x18c>
    c788:	e00f      	b.n	c7aa <z_vprintk+0x166>
				} else if (length_mod == 'l') {
    c78a:	2e6c      	cmp	r6, #108	; 0x6c
    c78c:	d0f6      	beq.n	c77c <z_vprintk+0x138>
				} else if (length_mod == 'L') {
    c78e:	2e4c      	cmp	r6, #76	; 0x4c
    c790:	d105      	bne.n	c79e <z_vprintk+0x15a>
					long long lld = va_arg(ap, long long);
    c792:	3407      	adds	r4, #7
    c794:	f024 0907 	bic.w	r9, r4, #7
					d = (printk_val_t) lld;
    c798:	e8f9 2302 	ldrd	r2, r3, [r9], #8
    c79c:	e7f2      	b.n	c784 <z_vprintk+0x140>
				} else if (*fmt == 'u') {
    c79e:	2875      	cmp	r0, #117	; 0x75
					d = va_arg(ap, unsigned int);
    c7a0:	6822      	ldr	r2, [r4, #0]
    c7a2:	f104 0904 	add.w	r9, r4, #4
				} else if (*fmt == 'u') {
    c7a6:	d112      	bne.n	c7ce <z_vprintk+0x18a>
					d = va_arg(ap, unsigned int);
    c7a8:	2300      	movs	r3, #0
	print_digits(out, ctx, num, 10, padding != PAD_SPACE_AFTER,
    c7aa:	1ef8      	subs	r0, r7, #3
    c7ac:	bf18      	it	ne
    c7ae:	2001      	movne	r0, #1
    c7b0:	2f01      	cmp	r7, #1
    c7b2:	bf0c      	ite	eq
    c7b4:	2430      	moveq	r4, #48	; 0x30
    c7b6:	2420      	movne	r4, #32
    c7b8:	9001      	str	r0, [sp, #4]
    c7ba:	200a      	movs	r0, #10
    c7bc:	e9cd 4802 	strd	r4, r8, [sp, #8]
    c7c0:	9000      	str	r0, [sp, #0]
    c7c2:	4659      	mov	r1, fp
    c7c4:	4628      	mov	r0, r5
    c7c6:	f7ff fee1 	bl	c58c <print_digits>
}
    c7ca:	464c      	mov	r4, r9
    c7cc:	e746      	b.n	c65c <z_vprintk+0x18>
					d = va_arg(ap, int);
    c7ce:	17d3      	asrs	r3, r2, #31
				if (*fmt != 'u' && negative(d)) {
    c7d0:	2a00      	cmp	r2, #0
    c7d2:	f173 0100 	sbcs.w	r1, r3, #0
    c7d6:	dae8      	bge.n	c7aa <z_vprintk+0x166>
					out((int)'-', ctx);
    c7d8:	4659      	mov	r1, fp
    c7da:	202d      	movs	r0, #45	; 0x2d
    c7dc:	e9cd 2304 	strd	r2, r3, [sp, #16]
    c7e0:	47a8      	blx	r5
					d = -d;
    c7e2:	e9dd 2304 	ldrd	r2, r3, [sp, #16]
    c7e6:	4252      	negs	r2, r2
    c7e8:	eb63 0343 	sbc.w	r3, r3, r3, lsl #1
					min_width--;
    c7ec:	f108 38ff 	add.w	r8, r8, #4294967295
    c7f0:	e7db      	b.n	c7aa <z_vprintk+0x166>
				out('0', ctx);
    c7f2:	4659      	mov	r1, fp
    c7f4:	2030      	movs	r0, #48	; 0x30
    c7f6:	47a8      	blx	r5
				out('x', ctx);
    c7f8:	4659      	mov	r1, fp
    c7fa:	2078      	movs	r0, #120	; 0x78
    c7fc:	47a8      	blx	r5
				min_width = sizeof(void *) * 2;
    c7fe:	f04f 0808 	mov.w	r8, #8
				padding = PAD_ZERO_BEFORE;
    c802:	2701      	movs	r7, #1
    c804:	e78c      	b.n	c720 <z_vprintk+0xdc>
				} else if (length_mod == 'l') {
    c806:	2e6c      	cmp	r6, #108	; 0x6c
    c808:	d08e      	beq.n	c728 <z_vprintk+0xe4>
				} else if (length_mod == 'L') {
    c80a:	2e4c      	cmp	r6, #76	; 0x4c
    c80c:	d18c      	bne.n	c728 <z_vprintk+0xe4>
					x = va_arg(ap, unsigned long long);
    c80e:	1de3      	adds	r3, r4, #7
    c810:	f023 0307 	bic.w	r3, r3, #7
    c814:	461c      	mov	r4, r3
    c816:	685b      	ldr	r3, [r3, #4]
    c818:	f854 2b08 	ldr.w	r2, [r4], #8
	print_digits(out, ctx, num, 16, padding != PAD_SPACE_AFTER,
    c81c:	1ef8      	subs	r0, r7, #3
    c81e:	bf18      	it	ne
    c820:	2001      	movne	r0, #1
    c822:	2f01      	cmp	r7, #1
    c824:	bf0c      	ite	eq
    c826:	2130      	moveq	r1, #48	; 0x30
    c828:	2120      	movne	r1, #32
    c82a:	e9cd 1802 	strd	r1, r8, [sp, #8]
    c82e:	2110      	movs	r1, #16
    c830:	9001      	str	r0, [sp, #4]
    c832:	9100      	str	r1, [sp, #0]
    c834:	4628      	mov	r0, r5
    c836:	4659      	mov	r1, fp
    c838:	f7ff fea8 	bl	c58c <print_digits>
    c83c:	e70e      	b.n	c65c <z_vprintk+0x18>
				char *s = va_arg(ap, char *);
    c83e:	f854 3b04 	ldr.w	r3, [r4], #4
				while (*s) {
    c842:	4699      	mov	r9, r3
    c844:	464a      	mov	r2, r9
    c846:	f819 0b01 	ldrb.w	r0, [r9], #1
    c84a:	b978      	cbnz	r0, c86c <z_vprintk+0x228>
				if (padding == PAD_SPACE_AFTER) {
    c84c:	2f03      	cmp	r7, #3
    c84e:	d125      	bne.n	c89c <z_vprintk+0x258>
					int remaining = min_width - (s - start);
    c850:	eba2 0903 	sub.w	r9, r2, r3
    c854:	eba8 0909 	sub.w	r9, r8, r9
					while (remaining-- > 0) {
    c858:	f1b9 0f00 	cmp.w	r9, #0
    c85c:	f77f aefe 	ble.w	c65c <z_vprintk+0x18>
						out(' ', ctx);
    c860:	4659      	mov	r1, fp
    c862:	2020      	movs	r0, #32
    c864:	47a8      	blx	r5
    c866:	f109 39ff 	add.w	r9, r9, #4294967295
    c86a:	e7f5      	b.n	c858 <z_vprintk+0x214>
					out((int)(*s++), ctx);
    c86c:	4659      	mov	r1, fp
    c86e:	9304      	str	r3, [sp, #16]
    c870:	47a8      	blx	r5
    c872:	9b04      	ldr	r3, [sp, #16]
    c874:	e7e6      	b.n	c844 <z_vprintk+0x200>
				out(c, ctx);
    c876:	4659      	mov	r1, fp
    c878:	f854 0b04 	ldr.w	r0, [r4], #4
    c87c:	e713      	b.n	c6a6 <z_vprintk+0x62>
				out((int)'%', ctx);
    c87e:	4659      	mov	r1, fp
    c880:	e711      	b.n	c6a6 <z_vprintk+0x62>
				length_mod = 0;
    c882:	464e      	mov	r6, r9
				padding = PAD_NONE;
    c884:	464f      	mov	r7, r9
				min_width = -1;
    c886:	f04f 38ff 	mov.w	r8, #4294967295
				might_format = 1;
    c88a:	f04f 0901 	mov.w	r9, #1
    c88e:	e6f0      	b.n	c672 <z_vprintk+0x2e>
			switch (*fmt) {
    c890:	2703      	movs	r7, #3
    c892:	e6ee      	b.n	c672 <z_vprintk+0x2e>
					padding = PAD_ZERO_BEFORE;
    c894:	2701      	movs	r7, #1
    c896:	e6ec      	b.n	c672 <z_vprintk+0x2e>
					length_mod = 'L';
    c898:	264c      	movs	r6, #76	; 0x4c
    c89a:	e6ea      	b.n	c672 <z_vprintk+0x2e>
			might_format = 0;
    c89c:	4681      	mov	r9, r0
    c89e:	e6e8      	b.n	c672 <z_vprintk+0x2e>

0000c8a0 <vprintk>:
#endif
	}
}
#else
void vprintk(const char *fmt, va_list ap)
{
    c8a0:	b507      	push	{r0, r1, r2, lr}
    c8a2:	460b      	mov	r3, r1
	struct out_context ctx = { 0 };
    c8a4:	2100      	movs	r1, #0
{
    c8a6:	4602      	mov	r2, r0
	struct out_context ctx = { 0 };
    c8a8:	9101      	str	r1, [sp, #4]
#ifdef CONFIG_PRINTK_SYNC
	k_spinlock_key_t key = k_spin_lock(&lock);
#endif

	z_vprintk(char_out, &ctx, fmt, ap);
    c8aa:	4803      	ldr	r0, [pc, #12]	; (c8b8 <vprintk+0x18>)
    c8ac:	a901      	add	r1, sp, #4
    c8ae:	f7ff fec9 	bl	c644 <z_vprintk>

#ifdef CONFIG_PRINTK_SYNC
	k_spin_unlock(&lock, key);
#endif
}
    c8b2:	b003      	add	sp, #12
    c8b4:	f85d fb04 	ldr.w	pc, [sp], #4
    c8b8:	0000c629 	.word	0x0000c629

0000c8bc <process_event>:
 * regions.
 */
static void process_event(struct onoff_manager *mgr,
			  int evt,
			  k_spinlock_key_t key)
{
    c8bc:	e92d 4ff8 	stmdb	sp!, {r3, r4, r5, r6, r7, r8, r9, sl, fp, lr}
	sys_slist_t clients;
	uint32_t state = mgr->flags & ONOFF_STATE_MASK;
    c8c0:	f8b0 9018 	ldrh.w	r9, [r0, #24]
{
    c8c4:	4604      	mov	r4, r0
	__ASSERT_NO_MSG(evt != EVT_NOP);

	/* If this is a nested call record the event for processing in
	 * the top invocation.
	 */
	if (processing) {
    c8c6:	f019 0808 	ands.w	r8, r9, #8
{
    c8ca:	4693      	mov	fp, r2
	if (processing) {
    c8cc:	d00d      	beq.n	c8ea <process_event+0x2e>
		if (evt == EVT_COMPLETE) {
    c8ce:	2901      	cmp	r1, #1
			mgr->flags |= ONOFF_FLAG_COMPLETE;
    c8d0:	bf0c      	ite	eq
    c8d2:	f049 0910 	orreq.w	r9, r9, #16
		} else {
			__ASSERT_NO_MSG(evt == EVT_RECHECK);

			mgr->flags |= ONOFF_FLAG_RECHECK;
    c8d6:	f049 0920 	orrne.w	r9, r9, #32
    c8da:	f8a0 9018 	strh.w	r9, [r0, #24]
	__asm__ volatile(
		"cpsie i;"
		"isb"
		: : : "memory");
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
	__asm__ volatile(
    c8de:	f38b 8811 	msr	BASEPRI, fp
    c8e2:	f3bf 8f6f 	isb	sy
		state = mgr->flags & ONOFF_STATE_MASK;
	} while (evt != EVT_NOP);

out:
	k_spin_unlock(&mgr->lock, key);
}
    c8e6:	e8bd 8ff8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, sl, fp, pc}
	uint32_t state = mgr->flags & ONOFF_STATE_MASK;
    c8ea:	f009 0907 	and.w	r9, r9, #7
		if (evt == EVT_RECHECK) {
    c8ee:	2902      	cmp	r1, #2
    c8f0:	d107      	bne.n	c902 <process_event+0x46>
			evt = process_recheck(mgr);
    c8f2:	4620      	mov	r0, r4
    c8f4:	f002 fa85 	bl	ee02 <process_recheck>
		if (evt == EVT_NOP) {
    c8f8:	2800      	cmp	r0, #0
    c8fa:	d0f0      	beq.n	c8de <process_event+0x22>
		if (evt == EVT_COMPLETE) {
    c8fc:	2801      	cmp	r0, #1
    c8fe:	8b23      	ldrh	r3, [r4, #24]
    c900:	d150      	bne.n	c9a4 <process_event+0xe8>
			res = mgr->last_res;
    c902:	6967      	ldr	r7, [r4, #20]
	uint32_t state = mgr->flags & ONOFF_STATE_MASK;
    c904:	8b21      	ldrh	r1, [r4, #24]
	if (res < 0) {
    c906:	2f00      	cmp	r7, #0
    c908:	da15      	bge.n	c936 <process_event+0x7a>
		*clients = mgr->clients;
    c90a:	6825      	ldr	r5, [r4, #0]
		     | (mgr->flags & ~ONOFF_STATE_MASK);
    c90c:	f021 0107 	bic.w	r1, r1, #7
 * @param list A pointer on the list to initialize
 */
static inline void sys_slist_init(sys_slist_t *list)
{
	list->head = NULL;
	list->tail = NULL;
    c910:	e9c4 8800 	strd	r8, r8, [r4]
    c914:	f041 0101 	orr.w	r1, r1, #1
	mgr->flags = (state & ONOFF_STATE_MASK)
    c918:	8321      	strh	r1, [r4, #24]
		onoff_transition_fn transit = NULL;
    c91a:	2600      	movs	r6, #0
		bool do_monitors = (state != (mgr->flags & ONOFF_STATE_MASK))
    c91c:	8b21      	ldrh	r1, [r4, #24]
    c91e:	f001 0a07 	and.w	sl, r1, #7
				   && !sys_slist_is_empty(&mgr->monitors);
    c922:	45ca      	cmp	sl, r9
    c924:	d002      	beq.n	c92c <process_event+0x70>
		if (do_monitors
    c926:	68a3      	ldr	r3, [r4, #8]
    c928:	2b00      	cmp	r3, #0
    c92a:	d15c      	bne.n	c9e6 <process_event+0x12a>
		    || !sys_slist_is_empty(&clients)
    c92c:	b90d      	cbnz	r5, c932 <process_event+0x76>
		    || (transit != NULL)) {
    c92e:	2e00      	cmp	r6, #0
    c930:	d074      	beq.n	ca1c <process_event+0x160>
    c932:	2300      	movs	r3, #0
    c934:	e058      	b.n	c9e8 <process_event+0x12c>
	uint32_t state = mgr->flags & ONOFF_STATE_MASK;
    c936:	f001 0307 	and.w	r3, r1, #7
		   || (state == ONOFF_STATE_RESETTING)) {
    c93a:	1f5a      	subs	r2, r3, #5
	} else if ((state == ONOFF_STATE_TO_ON)
    c93c:	2a01      	cmp	r2, #1
    c93e:	d820      	bhi.n	c982 <process_event+0xc6>
		*clients = mgr->clients;
    c940:	f021 0107 	bic.w	r1, r1, #7
		if (state == ONOFF_STATE_TO_ON) {
    c944:	2b06      	cmp	r3, #6
		*clients = mgr->clients;
    c946:	6825      	ldr	r5, [r4, #0]
	list->head = NULL;
    c948:	b289      	uxth	r1, r1
	list->tail = NULL;
    c94a:	e9c4 8800 	strd	r8, r8, [r4]
		if (state == ONOFF_STATE_TO_ON) {
    c94e:	d10c      	bne.n	c96a <process_event+0xae>
 *
 * @return A pointer on the first node of the list (or NULL if none)
 */
static inline sys_snode_t *sys_slist_peek_head(sys_slist_t *list)
{
	return list->head;
    c950:	2d00      	cmp	r5, #0
    c952:	462b      	mov	r3, r5
    c954:	bf38      	it	cc
    c956:	2300      	movcc	r3, #0
			SYS_SLIST_FOR_EACH_CONTAINER(clients, cp, node) {
    c958:	b12b      	cbz	r3, c966 <process_event+0xaa>
				mgr->refs += 1U;
    c95a:	8b62      	ldrh	r2, [r4, #26]
 *
 * @return a pointer on the next node (or NULL if none)
 */
static inline sys_snode_t *sys_slist_peek_next_no_check(sys_snode_t *node);

Z_GENLIST_PEEK_NEXT_NO_CHECK(slist, snode)
    c95c:	681b      	ldr	r3, [r3, #0]
    c95e:	3201      	adds	r2, #1
    c960:	8362      	strh	r2, [r4, #26]
			SYS_SLIST_FOR_EACH_CONTAINER(clients, cp, node) {
    c962:	2b00      	cmp	r3, #0
    c964:	d1f8      	bne.n	c958 <process_event+0x9c>
		     | (mgr->flags & ~ONOFF_STATE_MASK);
    c966:	f041 0102 	orr.w	r1, r1, #2
		if (process_recheck(mgr) != EVT_NOP) {
    c96a:	4620      	mov	r0, r4
	mgr->flags = (state & ONOFF_STATE_MASK)
    c96c:	8321      	strh	r1, [r4, #24]
		if (process_recheck(mgr) != EVT_NOP) {
    c96e:	f002 fa48 	bl	ee02 <process_recheck>
    c972:	4606      	mov	r6, r0
    c974:	2800      	cmp	r0, #0
    c976:	d0d1      	beq.n	c91c <process_event+0x60>
			mgr->flags |= ONOFF_FLAG_RECHECK;
    c978:	8b23      	ldrh	r3, [r4, #24]
    c97a:	f043 0320 	orr.w	r3, r3, #32
    c97e:	8323      	strh	r3, [r4, #24]
    c980:	e7cb      	b.n	c91a <process_event+0x5e>
	} else if (state == ONOFF_STATE_TO_OFF) {
    c982:	2b04      	cmp	r3, #4
    c984:	d10c      	bne.n	c9a0 <process_event+0xe4>
		     | (mgr->flags & ~ONOFF_STATE_MASK);
    c986:	f021 0107 	bic.w	r1, r1, #7
    c98a:	b289      	uxth	r1, r1
		if (process_recheck(mgr) != EVT_NOP) {
    c98c:	4620      	mov	r0, r4
	mgr->flags = (state & ONOFF_STATE_MASK)
    c98e:	8321      	strh	r1, [r4, #24]
		if (process_recheck(mgr) != EVT_NOP) {
    c990:	f002 fa37 	bl	ee02 <process_recheck>
    c994:	4605      	mov	r5, r0
    c996:	2800      	cmp	r0, #0
    c998:	d0bf      	beq.n	c91a <process_event+0x5e>
			mgr->flags |= ONOFF_FLAG_RECHECK;
    c99a:	f041 0120 	orr.w	r1, r1, #32
    c99e:	8321      	strh	r1, [r4, #24]
    c9a0:	2500      	movs	r5, #0
    c9a2:	e7ba      	b.n	c91a <process_event+0x5e>
		} else if (evt == EVT_START) {
    c9a4:	2803      	cmp	r0, #3
    c9a6:	d109      	bne.n	c9bc <process_event+0x100>
			transit = mgr->transitions->start;
    c9a8:	6922      	ldr	r2, [r4, #16]
		     | (mgr->flags & ~ONOFF_STATE_MASK);
    c9aa:	f023 0307 	bic.w	r3, r3, #7
			transit = mgr->transitions->start;
    c9ae:	6816      	ldr	r6, [r2, #0]
		     | (mgr->flags & ~ONOFF_STATE_MASK);
    c9b0:	f043 0306 	orr.w	r3, r3, #6
}
    c9b4:	2500      	movs	r5, #0
	mgr->flags = (state & ONOFF_STATE_MASK)
    c9b6:	8323      	strh	r3, [r4, #24]
		res = 0;
    c9b8:	462f      	mov	r7, r5
    c9ba:	e7af      	b.n	c91c <process_event+0x60>
		} else if (evt == EVT_STOP) {
    c9bc:	2804      	cmp	r0, #4
    c9be:	d106      	bne.n	c9ce <process_event+0x112>
			transit = mgr->transitions->stop;
    c9c0:	6922      	ldr	r2, [r4, #16]
		     | (mgr->flags & ~ONOFF_STATE_MASK);
    c9c2:	f023 0307 	bic.w	r3, r3, #7
			transit = mgr->transitions->stop;
    c9c6:	6856      	ldr	r6, [r2, #4]
		     | (mgr->flags & ~ONOFF_STATE_MASK);
    c9c8:	f043 0304 	orr.w	r3, r3, #4
    c9cc:	e7f2      	b.n	c9b4 <process_event+0xf8>
		} else if (evt == EVT_RESET) {
    c9ce:	2805      	cmp	r0, #5
    c9d0:	d106      	bne.n	c9e0 <process_event+0x124>
			transit = mgr->transitions->reset;
    c9d2:	6922      	ldr	r2, [r4, #16]
		     | (mgr->flags & ~ONOFF_STATE_MASK);
    c9d4:	f023 0307 	bic.w	r3, r3, #7
			transit = mgr->transitions->reset;
    c9d8:	6896      	ldr	r6, [r2, #8]
		     | (mgr->flags & ~ONOFF_STATE_MASK);
    c9da:	f043 0305 	orr.w	r3, r3, #5
    c9de:	e7e9      	b.n	c9b4 <process_event+0xf8>
    c9e0:	2500      	movs	r5, #0
		onoff_transition_fn transit = NULL;
    c9e2:	462e      	mov	r6, r5
    c9e4:	e7e8      	b.n	c9b8 <process_event+0xfc>
				   && !sys_slist_is_empty(&mgr->monitors);
    c9e6:	2301      	movs	r3, #1
			uint32_t flags = mgr->flags | ONOFF_FLAG_PROCESSING;
    c9e8:	f041 0108 	orr.w	r1, r1, #8
			mgr->flags = flags;
    c9ec:	8321      	strh	r1, [r4, #24]
    c9ee:	f38b 8811 	msr	BASEPRI, fp
    c9f2:	f3bf 8f6f 	isb	sy
			if (do_monitors) {
    c9f6:	bb03      	cbnz	r3, ca3a <process_event+0x17e>
	while (!sys_slist_is_empty(list)) {
    c9f8:	2d00      	cmp	r5, #0
    c9fa:	d133      	bne.n	ca64 <process_event+0x1a8>
			if (transit != NULL) {
    c9fc:	b116      	cbz	r6, ca04 <process_event+0x148>
				transit(mgr, transition_complete);
    c9fe:	4620      	mov	r0, r4
    ca00:	4920      	ldr	r1, [pc, #128]	; (ca84 <process_event+0x1c8>)
    ca02:	47b0      	blx	r6
	__asm__ volatile(
    ca04:	f04f 0320 	mov.w	r3, #32
    ca08:	f3ef 8b11 	mrs	fp, BASEPRI
    ca0c:	f383 8811 	msr	BASEPRI, r3
    ca10:	f3bf 8f6f 	isb	sy
			mgr->flags &= ~ONOFF_FLAG_PROCESSING;
    ca14:	8b23      	ldrh	r3, [r4, #24]
    ca16:	f023 0308 	bic.w	r3, r3, #8
    ca1a:	8323      	strh	r3, [r4, #24]
		if ((mgr->flags & ONOFF_FLAG_COMPLETE) != 0) {
    ca1c:	8b23      	ldrh	r3, [r4, #24]
    ca1e:	06da      	lsls	r2, r3, #27
    ca20:	d528      	bpl.n	ca74 <process_event+0x1b8>
			evt = EVT_COMPLETE;
    ca22:	2101      	movs	r1, #1
			mgr->flags &= ~ONOFF_FLAG_COMPLETE;
    ca24:	f023 0310 	bic.w	r3, r3, #16
    ca28:	8323      	strh	r3, [r4, #24]
		state = mgr->flags & ONOFF_STATE_MASK;
    ca2a:	f8b4 9018 	ldrh.w	r9, [r4, #24]
    ca2e:	f009 0907 	and.w	r9, r9, #7
	} while (evt != EVT_NOP);
    ca32:	2900      	cmp	r1, #0
    ca34:	f47f af5b 	bne.w	c8ee <process_event+0x32>
out:
    ca38:	e751      	b.n	c8de <process_event+0x22>
	SYS_SLIST_FOR_EACH_CONTAINER_SAFE(mlist, mon, tmp, node) {
    ca3a:	68a1      	ldr	r1, [r4, #8]
    ca3c:	2900      	cmp	r1, #0
    ca3e:	d0db      	beq.n	c9f8 <process_event+0x13c>
	return node->next;
    ca40:	680b      	ldr	r3, [r1, #0]
    ca42:	2b00      	cmp	r3, #0
    ca44:	bf38      	it	cc
    ca46:	2300      	movcc	r3, #0
    ca48:	4699      	mov	r9, r3
		mon->callback(mgr, mon, state, res);
    ca4a:	4652      	mov	r2, sl
    ca4c:	463b      	mov	r3, r7
    ca4e:	4620      	mov	r0, r4
    ca50:	f8d1 b004 	ldr.w	fp, [r1, #4]
    ca54:	47d8      	blx	fp
	SYS_SLIST_FOR_EACH_CONTAINER_SAFE(mlist, mon, tmp, node) {
    ca56:	f1b9 0f00 	cmp.w	r9, #0
    ca5a:	d0cd      	beq.n	c9f8 <process_event+0x13c>
Z_GENLIST_PEEK_NEXT_NO_CHECK(slist, snode)
    ca5c:	4649      	mov	r1, r9
    ca5e:	f8d9 3000 	ldr.w	r3, [r9]
    ca62:	e7ee      	b.n	ca42 <process_event+0x186>
 *
 * @return A pointer to the first node of the list
 */
static inline sys_snode_t *sys_slist_get_not_empty(sys_slist_t *list);

Z_GENLIST_GET_NOT_EMPTY(slist, snode)
    ca64:	4629      	mov	r1, r5
		notify_one(mgr, cli, state, res);
    ca66:	463b      	mov	r3, r7
    ca68:	4652      	mov	r2, sl
    ca6a:	4620      	mov	r0, r4
    ca6c:	682d      	ldr	r5, [r5, #0]
    ca6e:	f002 f9e4 	bl	ee3a <notify_one>
    ca72:	e7c1      	b.n	c9f8 <process_event+0x13c>
		} else if ((mgr->flags & ONOFF_FLAG_RECHECK) != 0) {
    ca74:	f013 0120 	ands.w	r1, r3, #32
			mgr->flags &= ~ONOFF_FLAG_RECHECK;
    ca78:	bf1e      	ittt	ne
    ca7a:	f023 0320 	bicne.w	r3, r3, #32
			evt = EVT_RECHECK;
    ca7e:	2102      	movne	r1, #2
			mgr->flags &= ~ONOFF_FLAG_RECHECK;
    ca80:	8323      	strhne	r3, [r4, #24]
			evt = EVT_RECHECK;
    ca82:	e7d2      	b.n	ca2a <process_event+0x16e>
    ca84:	0000ee67 	.word	0x0000ee67

0000ca88 <nordicsemi_nrf91_init>:
    ca88:	f04f 0220 	mov.w	r2, #32
    ca8c:	f3ef 8311 	mrs	r3, BASEPRI
    ca90:	f382 8811 	msr	BASEPRI, r2
    ca94:	f3bf 8f6f 	isb	sy

	key = irq_lock();

#ifdef CONFIG_NRF_ENABLE_ICACHE
	/* Enable the instruction cache */
	NRF_NVMC->ICACHECNF = NVMC_ICACHECNF_CACHEEN_Msk;
    ca98:	2101      	movs	r1, #1
    ca9a:	4a04      	ldr	r2, [pc, #16]	; (caac <nordicsemi_nrf91_init+0x24>)
    ca9c:	f8c2 1540 	str.w	r1, [r2, #1344]	; 0x540
	__asm__ volatile(
    caa0:	f383 8811 	msr	BASEPRI, r3
    caa4:	f3bf 8f6f 	isb	sy
	NMI_INIT();

	irq_unlock(key);

	return 0;
}
    caa8:	2000      	movs	r0, #0
    caaa:	4770      	bx	lr
    caac:	40039000 	.word	0x40039000

0000cab0 <arch_busy_wait>:

#else // NRFX_CHECK(NRFX_DELAY_DWT_BASED)

NRF_STATIC_INLINE void nrfx_coredep_delay_us(uint32_t time_us)
{
    if (time_us == 0)
    cab0:	b120      	cbz	r0, cabc <arch_busy_wait+0xc>
    };

    typedef void (* delay_func_t)(uint32_t);
    const delay_func_t delay_cycles =
        // Set LSB to 1 to execute the code in the Thumb mode.
        (delay_func_t)((((uint32_t)delay_machine_code) | 1));
    cab2:	4b03      	ldr	r3, [pc, #12]	; (cac0 <arch_busy_wait+0x10>)
    uint32_t cycles = time_us * NRFX_DELAY_CPU_FREQ_MHZ;
    delay_cycles(cycles);
    cab4:	0180      	lsls	r0, r0, #6
    cab6:	f043 0301 	orr.w	r3, r3, #1
    caba:	4718      	bx	r3

void arch_busy_wait(uint32_t time_us)
{
	nrfx_coredep_delay_us(time_us);
}
    cabc:	4770      	bx	lr
    cabe:	bf00      	nop
    cac0:	0000fa10 	.word	0x0000fa10

0000cac4 <uart_console_init>:
 * @brief Initialize one UART as the console/debug port
 *
 * @return 0 if successful, otherwise failed.
 */
static int uart_console_init(const struct device *arg)
{
    cac4:	b510      	push	{r4, lr}
    cac6:	4807      	ldr	r0, [pc, #28]	; (cae4 <uart_console_init+0x20>)
    cac8:	f001 faf0 	bl	e0ac <z_impl_device_get_binding>
	__stdout_hook_install(console_out);
    cacc:	4c06      	ldr	r4, [pc, #24]	; (cae8 <uart_console_init+0x24>)

	ARG_UNUSED(arg);

	/* Claim console device */
	uart_console_dev = device_get_binding(CONFIG_UART_CONSOLE_ON_DEV_NAME);
    cace:	4b07      	ldr	r3, [pc, #28]	; (caec <uart_console_init+0x28>)
    cad0:	6018      	str	r0, [r3, #0]
	__stdout_hook_install(console_out);
    cad2:	4620      	mov	r0, r4
    cad4:	f000 fe6a 	bl	d7ac <__stdout_hook_install>
	__printk_hook_install(console_out);
    cad8:	4620      	mov	r0, r4
    cada:	f7ff fdad 	bl	c638 <__printk_hook_install>

	uart_console_hook_install();

	return 0;
}
    cade:	2000      	movs	r0, #0
    cae0:	bd10      	pop	{r4, pc}
    cae2:	bf00      	nop
    cae4:	0000faf4 	.word	0x0000faf4
    cae8:	0000caf1 	.word	0x0000caf1
    caec:	20010198 	.word	0x20010198

0000caf0 <console_out>:
	if ('\n' == c) {
    caf0:	280a      	cmp	r0, #10
{
    caf2:	b538      	push	{r3, r4, r5, lr}
    caf4:	4604      	mov	r4, r0
    caf6:	4d07      	ldr	r5, [pc, #28]	; (cb14 <console_out+0x24>)
	if ('\n' == c) {
    caf8:	d104      	bne.n	cb04 <console_out+0x14>
    cafa:	6828      	ldr	r0, [r5, #0]
						unsigned char out_char)
{
	const struct uart_driver_api *api =
		(const struct uart_driver_api *)dev->api;

	api->poll_out(dev, out_char);
    cafc:	6883      	ldr	r3, [r0, #8]
    cafe:	210d      	movs	r1, #13
    cb00:	685b      	ldr	r3, [r3, #4]
    cb02:	4798      	blx	r3
	uart_poll_out(uart_console_dev, c);
    cb04:	6828      	ldr	r0, [r5, #0]
    cb06:	6883      	ldr	r3, [r0, #8]
    cb08:	b2e1      	uxtb	r1, r4
    cb0a:	685b      	ldr	r3, [r3, #4]
    cb0c:	4798      	blx	r3
}
    cb0e:	4620      	mov	r0, r4
    cb10:	bd38      	pop	{r3, r4, r5, pc}
    cb12:	bf00      	nop
    cb14:	20010198 	.word	0x20010198

0000cb18 <onoff_stop>:
}

static clock_control_subsys_t get_subsys(struct onoff_manager *mgr)
{
	struct nrf_clock_control_data *data = DEVICE_GET(clock_nrf)->data;
	size_t offset = (size_t)(mgr - data->mgr);
    cb18:	4a0e      	ldr	r2, [pc, #56]	; (cb54 <onoff_stop+0x3c>)
	return (clock_control_subsys_t)offset;
}

static void onoff_stop(struct onoff_manager *mgr,
			onoff_notify_fn notify)
{
    cb1a:	b570      	push	{r4, r5, r6, lr}
	size_t offset = (size_t)(mgr - data->mgr);
    cb1c:	1a84      	subs	r4, r0, r2
{
    cb1e:	4605      	mov	r5, r0
	err = set_off_state(&subdata->flags, ctx);
    cb20:	200c      	movs	r0, #12
{
    cb22:	460e      	mov	r6, r1
	err = set_off_state(&subdata->flags, ctx);
    cb24:	2140      	movs	r1, #64	; 0x40
	size_t offset = (size_t)(mgr - data->mgr);
    cb26:	10a3      	asrs	r3, r4, #2
    cb28:	4c0b      	ldr	r4, [pc, #44]	; (cb58 <onoff_stop+0x40>)
    cb2a:	435c      	muls	r4, r3
    cb2c:	b2e4      	uxtb	r4, r4
	err = set_off_state(&subdata->flags, ctx);
    cb2e:	fb00 2004 	mla	r0, r0, r4, r2
    cb32:	4408      	add	r0, r1
    cb34:	f002 fb02 	bl	f13c <set_off_state>
	if (err < 0) {
    cb38:	1e01      	subs	r1, r0, #0
    cb3a:	db05      	blt.n	cb48 <onoff_stop+0x30>
	get_sub_config(dev, type)->stop();
    cb3c:	4b07      	ldr	r3, [pc, #28]	; (cb5c <onoff_stop+0x44>)
    cb3e:	eb03 04c4 	add.w	r4, r3, r4, lsl #3
    cb42:	6863      	ldr	r3, [r4, #4]
    cb44:	4798      	blx	r3
	return 0;
    cb46:	2100      	movs	r1, #0
	int res;

	res = stop(DEVICE_GET(clock_nrf), get_subsys(mgr), CTX_ONOFF);
	notify(mgr, res);
    cb48:	4628      	mov	r0, r5
    cb4a:	4633      	mov	r3, r6
}
    cb4c:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
	notify(mgr, res);
    cb50:	4718      	bx	r3
    cb52:	bf00      	nop
    cb54:	200101ac 	.word	0x200101ac
    cb58:	b6db6db7 	.word	0xb6db6db7
    cb5c:	0000fa2c 	.word	0x0000fa2c

0000cb60 <onoff_start>:
	notify(mgr, 0);
}

static void onoff_start(struct onoff_manager *mgr,
			onoff_notify_fn notify)
{
    cb60:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	err = set_starting_state(&subdata->flags, ctx);
    cb64:	250c      	movs	r5, #12
	size_t offset = (size_t)(mgr - data->mgr);
    cb66:	4e10      	ldr	r6, [pc, #64]	; (cba8 <onoff_start+0x48>)
{
    cb68:	4680      	mov	r8, r0
	size_t offset = (size_t)(mgr - data->mgr);
    cb6a:	1b84      	subs	r4, r0, r6
    cb6c:	10a3      	asrs	r3, r4, #2
    cb6e:	4c0f      	ldr	r4, [pc, #60]	; (cbac <onoff_start+0x4c>)
{
    cb70:	460f      	mov	r7, r1
	size_t offset = (size_t)(mgr - data->mgr);
    cb72:	435c      	muls	r4, r3
    cb74:	b2e4      	uxtb	r4, r4
	err = set_starting_state(&subdata->flags, ctx);
    cb76:	4365      	muls	r5, r4
    cb78:	f105 0040 	add.w	r0, r5, #64	; 0x40
    cb7c:	2140      	movs	r1, #64	; 0x40
    cb7e:	4430      	add	r0, r6
    cb80:	f002 faf5 	bl	f16e <set_starting_state>
	if (err < 0) {
    cb84:	1e01      	subs	r1, r0, #0
    cb86:	db09      	blt.n	cb9c <onoff_start+0x3c>
	subdata->cb = data->cb;
    cb88:	4a09      	ldr	r2, [pc, #36]	; (cbb0 <onoff_start+0x50>)
    cb8a:	1973      	adds	r3, r6, r5
	subdata->user_data = data->user_data;
    cb8c:	e9c3 270e 	strd	r2, r7, [r3, #56]	; 0x38
	 get_sub_config(dev, type)->start();
    cb90:	4b08      	ldr	r3, [pc, #32]	; (cbb4 <onoff_start+0x54>)
    cb92:	f853 3034 	ldr.w	r3, [r3, r4, lsl #3]
	err = async_start(DEVICE_GET(clock_nrf), get_subsys(mgr),
			  &data, CTX_ONOFF);
	if (err < 0) {
		notify(mgr, err);
	}
}
    cb96:	e8bd 41f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
	 get_sub_config(dev, type)->start();
    cb9a:	4718      	bx	r3
		notify(mgr, err);
    cb9c:	4640      	mov	r0, r8
    cb9e:	463b      	mov	r3, r7
}
    cba0:	e8bd 41f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
		notify(mgr, err);
    cba4:	4718      	bx	r3
    cba6:	bf00      	nop
    cba8:	200101ac 	.word	0x200101ac
    cbac:	b6db6db7 	.word	0xb6db6db7
    cbb0:	0000f1d1 	.word	0x0000f1d1
    cbb4:	0000fa2c 	.word	0x0000fa2c

0000cbb8 <clk_init>:
		break;
	}
}

static int clk_init(const struct device *dev)
{
    cbb8:	b570      	push	{r4, r5, r6, lr}
	static const struct onoff_transitions transitions = {
		.start = onoff_start,
		.stop = onoff_stop
	};

	IRQ_CONNECT(DT_INST_IRQN(0), DT_INST_IRQ(0, priority),
    cbba:	2200      	movs	r2, #0
    cbbc:	2101      	movs	r1, #1
{
    cbbe:	4604      	mov	r4, r0
	IRQ_CONNECT(DT_INST_IRQN(0), DT_INST_IRQ(0, priority),
    cbc0:	2005      	movs	r0, #5
    cbc2:	f000 fa7b 	bl	d0bc <z_arm_irq_priority_set>
		    nrfx_isr, nrfx_power_clock_irq_handler, 0);
	irq_enable(DT_INST_IRQN(0));
    cbc6:	2005      	movs	r0, #5
    cbc8:	f000 fa5a 	bl	d080 <arch_irq_enable>
					NRF_GPIO_PIN_MCUSEL_PERIPHERAL);
		nrf_gpio_pin_mcu_select(PIN_XL2,
					NRF_GPIO_PIN_MCUSEL_PERIPHERAL);
	}
#endif
	nrfx_err = nrfx_clock_init(clock_event_handler);
    cbcc:	480f      	ldr	r0, [pc, #60]	; (cc0c <clk_init+0x54>)
    cbce:	f001 f979 	bl	dec4 <nrfx_clock_init>
	if (nrfx_err != NRFX_SUCCESS) {
    cbd2:	4b0f      	ldr	r3, [pc, #60]	; (cc10 <clk_init+0x58>)
    cbd4:	4298      	cmp	r0, r3
    cbd6:	d115      	bne.n	cc04 <clk_init+0x4c>
		struct nrf_clock_control_data *data = dev->data;

		z_nrf_clock_calibration_init(data->mgr);
	}

	nrfx_clock_enable();
    cbd8:	f002 fca0 	bl	f51c <nrfx_clock_enable>

	for (enum clock_control_nrf_type i = 0;
		i < CLOCK_CONTROL_NRF_TYPE_COUNT; i++) {
		struct nrf_clock_control_sub_data *subdata =
						get_sub_data(dev, i);
    cbdc:	68e6      	ldr	r6, [r4, #12]

		err = onoff_manager_init(get_onoff_manager(dev, i),
    cbde:	490d      	ldr	r1, [pc, #52]	; (cc14 <clk_init+0x5c>)
    cbe0:	4630      	mov	r0, r6
    cbe2:	f002 f95d 	bl	eea0 <onoff_manager_init>
					 &transitions);
		if (err < 0) {
    cbe6:	2800      	cmp	r0, #0
    cbe8:	db0b      	blt.n	cc02 <clk_init+0x4a>
			return err;
		}

		subdata->flags = CLOCK_CONTROL_STATUS_OFF;
    cbea:	2501      	movs	r5, #1
    cbec:	6435      	str	r5, [r6, #64]	; 0x40
						get_sub_data(dev, i);
    cbee:	68e4      	ldr	r4, [r4, #12]
		err = onoff_manager_init(get_onoff_manager(dev, i),
    cbf0:	4908      	ldr	r1, [pc, #32]	; (cc14 <clk_init+0x5c>)
    cbf2:	f104 001c 	add.w	r0, r4, #28
    cbf6:	f002 f953 	bl	eea0 <onoff_manager_init>
		if (err < 0) {
    cbfa:	2800      	cmp	r0, #0
    cbfc:	db01      	blt.n	cc02 <clk_init+0x4a>
	}

	return 0;
    cbfe:	2000      	movs	r0, #0
		subdata->flags = CLOCK_CONTROL_STATUS_OFF;
    cc00:	64e5      	str	r5, [r4, #76]	; 0x4c
}
    cc02:	bd70      	pop	{r4, r5, r6, pc}
		return -EIO;
    cc04:	f06f 0004 	mvn.w	r0, #4
    cc08:	e7fb      	b.n	cc02 <clk_init+0x4a>
    cc0a:	bf00      	nop
    cc0c:	0000cc4d 	.word	0x0000cc4d
    cc10:	0bad0000 	.word	0x0bad0000
    cc14:	0000fa3c 	.word	0x0000fa3c

0000cc18 <clkstarted_handle.constprop.0>:
static void clkstarted_handle(const struct device *dev,
    cc18:	4601      	mov	r1, r0
	clock_control_cb_t callback = sub_data->cb;
    cc1a:	230c      	movs	r3, #12
	sub_data->cb = NULL;
    cc1c:	2200      	movs	r2, #0
	clock_control_cb_t callback = sub_data->cb;
    cc1e:	434b      	muls	r3, r1
    cc20:	4808      	ldr	r0, [pc, #32]	; (cc44 <clkstarted_handle.constprop.0+0x2c>)
static void clkstarted_handle(const struct device *dev,
    cc22:	b570      	push	{r4, r5, r6, lr}
	clock_control_cb_t callback = sub_data->cb;
    cc24:	18c4      	adds	r4, r0, r3
	set_on_state(&sub_data->flags);
    cc26:	3340      	adds	r3, #64	; 0x40
	void *user_data = sub_data->user_data;
    cc28:	e9d4 560e 	ldrd	r5, r6, [r4, #56]	; 0x38
	set_on_state(&sub_data->flags);
    cc2c:	4418      	add	r0, r3
	sub_data->cb = NULL;
    cc2e:	63a2      	str	r2, [r4, #56]	; 0x38
	set_on_state(&sub_data->flags);
    cc30:	f002 fabb 	bl	f1aa <set_on_state>
	if (callback) {
    cc34:	b12d      	cbz	r5, cc42 <clkstarted_handle.constprop.0+0x2a>
		callback(dev, (clock_control_subsys_t)type, user_data);
    cc36:	4632      	mov	r2, r6
    cc38:	462b      	mov	r3, r5
}
    cc3a:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
		callback(dev, (clock_control_subsys_t)type, user_data);
    cc3e:	4802      	ldr	r0, [pc, #8]	; (cc48 <clkstarted_handle.constprop.0+0x30>)
    cc40:	4718      	bx	r3
}
    cc42:	bd70      	pop	{r4, r5, r6, pc}
    cc44:	200101ac 	.word	0x200101ac
    cc48:	2001003c 	.word	0x2001003c

0000cc4c <clock_event_handler>:
	switch (event) {
    cc4c:	b110      	cbz	r0, cc54 <clock_event_handler+0x8>
    cc4e:	2801      	cmp	r0, #1
    cc50:	d004      	beq.n	cc5c <clock_event_handler+0x10>
    cc52:	4770      	bx	lr
		if (GET_STATUS(data->flags) == CLOCK_CONTROL_STATUS_STARTING) {
    cc54:	4b03      	ldr	r3, [pc, #12]	; (cc64 <clock_event_handler+0x18>)
    cc56:	6c1b      	ldr	r3, [r3, #64]	; 0x40
    cc58:	075b      	lsls	r3, r3, #29
    cc5a:	d101      	bne.n	cc60 <clock_event_handler+0x14>
		clkstarted_handle(dev, CLOCK_CONTROL_NRF_TYPE_LFCLK);
    cc5c:	f7ff bfdc 	b.w	cc18 <clkstarted_handle.constprop.0>
}
    cc60:	4770      	bx	lr
    cc62:	bf00      	nop
    cc64:	200101ac 	.word	0x200101ac

0000cc68 <generic_hfclk_start>:
{
    cc68:	b508      	push	{r3, lr}
	__asm__ volatile(
    cc6a:	f04f 0320 	mov.w	r3, #32
    cc6e:	f3ef 8111 	mrs	r1, BASEPRI
    cc72:	f383 8811 	msr	BASEPRI, r3
    cc76:	f3bf 8f6f 	isb	sy
	hfclk_users |= HF_USER_GENERIC;
    cc7a:	4a11      	ldr	r2, [pc, #68]	; (ccc0 <generic_hfclk_start+0x58>)
    cc7c:	6813      	ldr	r3, [r2, #0]
    cc7e:	f043 0002 	orr.w	r0, r3, #2
	if (hfclk_users & HF_USER_BT) {
    cc82:	f013 0301 	ands.w	r3, r3, #1
	hfclk_users |= HF_USER_GENERIC;
    cc86:	6010      	str	r0, [r2, #0]
	if (hfclk_users & HF_USER_BT) {
    cc88:	d00b      	beq.n	cca2 <generic_hfclk_start+0x3a>
            break;
        case NRF_CLOCK_DOMAIN_HFCLK:
            if (p_clk_src != NULL)
            {
                (*(nrf_clock_hfclk_t *)p_clk_src) =
                    (nrf_clock_hfclk_t)((p_reg->HFCLKSTAT & CLOCK_HFCLKSTAT_SRC_Msk)
    cc8a:	4a0e      	ldr	r2, [pc, #56]	; (ccc4 <generic_hfclk_start+0x5c>)
    cc8c:	f8d2 340c 	ldr.w	r3, [r2, #1036]	; 0x40c
                                        >> CLOCK_HFCLKSTAT_SRC_Pos);
            }
            if ((p_reg->HFCLKSTAT & CLOCK_HFCLKSTAT_STATE_Msk)
    cc90:	f8d2 240c 	ldr.w	r2, [r2, #1036]	; 0x40c
		if (type == NRF_CLOCK_HFCLK_HIGH_ACCURACY) {
    cc94:	f013 0301 	ands.w	r3, r3, #1
    cc98:	d003      	beq.n	cca2 <generic_hfclk_start+0x3a>
			set_on_state(get_hf_flags());
    cc9a:	480b      	ldr	r0, [pc, #44]	; (ccc8 <generic_hfclk_start+0x60>)
    cc9c:	f002 fa85 	bl	f1aa <set_on_state>
			already_started = true;
    cca0:	2301      	movs	r3, #1
	__asm__ volatile(
    cca2:	f381 8811 	msr	BASEPRI, r1
    cca6:	f3bf 8f6f 	isb	sy
	if (already_started) {
    ccaa:	b123      	cbz	r3, ccb6 <generic_hfclk_start+0x4e>
}
    ccac:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
		clkstarted_handle(DEVICE_GET(clock_nrf),
    ccb0:	2000      	movs	r0, #0
    ccb2:	f7ff bfb1 	b.w	cc18 <clkstarted_handle.constprop.0>
    nrfx_clock_stop(NRF_CLOCK_DOMAIN_LFCLK);
}

NRFX_STATIC_INLINE void nrfx_clock_hfclk_start(void)
{
    nrfx_clock_start(NRF_CLOCK_DOMAIN_HFCLK);
    ccb6:	2001      	movs	r0, #1
}
    ccb8:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
    ccbc:	f001 b912 	b.w	dee4 <nrfx_clock_start>
    ccc0:	200101fc 	.word	0x200101fc
    ccc4:	40005000 	.word	0x40005000
    ccc8:	200101ec 	.word	0x200101ec

0000cccc <generic_hfclk_stop>:
 * @return Previous value of @a target.
 */
#ifdef CONFIG_ATOMIC_OPERATIONS_BUILTIN
static inline atomic_val_t atomic_and(atomic_t *target, atomic_val_t value)
{
	return __atomic_fetch_and(target, value, __ATOMIC_SEQ_CST);
    cccc:	4b07      	ldr	r3, [pc, #28]	; (ccec <generic_hfclk_stop+0x20>)
    ccce:	e8d3 2fef 	ldaex	r2, [r3]
    ccd2:	f022 0102 	bic.w	r1, r2, #2
    ccd6:	e8c3 1fe0 	stlex	r0, r1, [r3]
    ccda:	2800      	cmp	r0, #0
    ccdc:	d1f7      	bne.n	ccce <generic_hfclk_stop+0x2>
	if (atomic_and(&hfclk_users, ~HF_USER_GENERIC) & HF_USER_BT) {
    ccde:	07d3      	lsls	r3, r2, #31
    cce0:	d402      	bmi.n	cce8 <generic_hfclk_stop+0x1c>
}

NRFX_STATIC_INLINE void nrfx_clock_hfclk_stop(void)
{
    nrfx_clock_stop(NRF_CLOCK_DOMAIN_HFCLK);
    cce2:	2001      	movs	r0, #1
    cce4:	f001 b930 	b.w	df48 <nrfx_clock_stop>
}
    cce8:	4770      	bx	lr
    ccea:	bf00      	nop
    ccec:	200101fc 	.word	0x200101fc

0000ccf0 <api_blocking_start>:
	struct k_sem sem = Z_SEM_INITIALIZER(sem, 0, 1);
    ccf0:	2300      	movs	r3, #0
    ccf2:	2201      	movs	r2, #1
{
    ccf4:	b510      	push	{r4, lr}
    ccf6:	b088      	sub	sp, #32
	struct k_sem sem = Z_SEM_INITIALIZER(sem, 0, 1);
    ccf8:	e9cd 3206 	strd	r3, r2, [sp, #24]
	struct clock_control_async_data data = {
    ccfc:	9301      	str	r3, [sp, #4]
    ccfe:	4b09      	ldr	r3, [pc, #36]	; (cd24 <api_blocking_start+0x34>)
	struct k_sem sem = Z_SEM_INITIALIZER(sem, 0, 1);
    cd00:	ac04      	add	r4, sp, #16
	err = api_start(dev, subsys, &data);
    cd02:	aa01      	add	r2, sp, #4
	struct k_sem sem = Z_SEM_INITIALIZER(sem, 0, 1);
    cd04:	e9cd 4404 	strd	r4, r4, [sp, #16]
	struct clock_control_async_data data = {
    cd08:	e9cd 3402 	strd	r3, r4, [sp, #8]
	err = api_start(dev, subsys, &data);
    cd0c:	f002 fa86 	bl	f21c <api_start>
	if (err < 0) {
    cd10:	2800      	cmp	r0, #0
    cd12:	db05      	blt.n	cd20 <api_blocking_start+0x30>
		parm0.val = timeout;
		return (int) arch_syscall_invoke3(*(uintptr_t *)&sem, parm0.split.lo, parm0.split.hi, K_SYSCALL_K_SEM_TAKE);
	}
#endif
	compiler_barrier();
	return z_impl_k_sem_take(sem, timeout);
    cd14:	f44f 4280 	mov.w	r2, #16384	; 0x4000
    cd18:	2300      	movs	r3, #0
    cd1a:	4620      	mov	r0, r4
    cd1c:	f001 fe0e 	bl	e93c <z_impl_k_sem_take>
}
    cd20:	b008      	add	sp, #32
    cd22:	bd10      	pop	{r4, pc}
    cd24:	0000f1e3 	.word	0x0000f1e3

0000cd28 <z_nrf_clock_control_lf_on>:
{
    cd28:	e92d 43f8 	stmdb	sp!, {r3, r4, r5, r6, r7, r8, r9, lr}
	return __atomic_exchange_n(target, value, __ATOMIC_SEQ_CST);
    cd2c:	2201      	movs	r2, #1
    cd2e:	4607      	mov	r7, r0
    cd30:	4936      	ldr	r1, [pc, #216]	; (ce0c <z_nrf_clock_control_lf_on+0xe4>)
    cd32:	e8d1 3fef 	ldaex	r3, [r1]
    cd36:	e8c1 2fe0 	stlex	r0, r2, [r1]
    cd3a:	2800      	cmp	r0, #0
    cd3c:	d1f9      	bne.n	cd32 <z_nrf_clock_control_lf_on+0xa>
	if (atomic_set(&on, 1) == 0) {
    cd3e:	b933      	cbnz	r3, cd4e <z_nrf_clock_control_lf_on+0x26>
 */
static inline void sys_notify_init_spinwait(struct sys_notify *notify)
{
	__ASSERT_NO_MSG(notify != NULL);

	*notify = (struct sys_notify){
    cd40:	4933      	ldr	r1, [pc, #204]	; (ce10 <z_nrf_clock_control_lf_on+0xe8>)
		err = onoff_request(mgr, &cli);
    cd42:	4834      	ldr	r0, [pc, #208]	; (ce14 <z_nrf_clock_control_lf_on+0xec>)
    cd44:	604b      	str	r3, [r1, #4]
    cd46:	60cb      	str	r3, [r1, #12]
    cd48:	608a      	str	r2, [r1, #8]
    cd4a:	f002 f8bc 	bl	eec6 <onoff_request>
	switch (start_mode) {
    cd4e:	1e7b      	subs	r3, r7, #1
    cd50:	2b01      	cmp	r3, #1
    cd52:	d82e      	bhi.n	cdb2 <z_nrf_clock_control_lf_on+0x8a>
	if ((mode == CLOCK_CONTROL_NRF_LF_START_AVAILABLE) &&
    cd54:	2f01      	cmp	r7, #1
    cd56:	d106      	bne.n	cd66 <z_nrf_clock_control_lf_on+0x3e>
    return clk_src;
}

NRF_STATIC_INLINE nrf_clock_lfclk_t nrf_clock_lf_srccopy_get(NRF_CLOCK_Type const * p_reg)
{
    return (nrf_clock_lfclk_t)((p_reg->LFCLKSRCCOPY & CLOCK_LFCLKSRCCOPY_SRC_Msk)
    cd58:	4b2f      	ldr	r3, [pc, #188]	; (ce18 <z_nrf_clock_control_lf_on+0xf0>)
    cd5a:	f8d3 341c 	ldr.w	r3, [r3, #1052]	; 0x41c
	    (target_type == NRF_CLOCK_LFCLK_Xtal) &&
    cd5e:	f003 0303 	and.w	r3, r3, #3
    cd62:	2b02      	cmp	r3, #2
    cd64:	d025      	beq.n	cdb2 <z_nrf_clock_control_lf_on+0x8a>
	bool isr_mode = k_is_in_isr() || k_is_pre_kernel();
    cd66:	f002 fcad 	bl	f6c4 <k_is_in_isr>
    cd6a:	4604      	mov	r4, r0
    cd6c:	b918      	cbnz	r0, cd76 <z_nrf_clock_control_lf_on+0x4e>
 */
static inline bool k_is_pre_kernel(void)
{
	extern bool z_sys_post_kernel; /* in init.c */

	return !z_sys_post_kernel;
    cd6e:	4b2b      	ldr	r3, [pc, #172]	; (ce1c <z_nrf_clock_control_lf_on+0xf4>)
	int key = isr_mode ? irq_lock() : 0;
    cd70:	781b      	ldrb	r3, [r3, #0]
    cd72:	2b00      	cmp	r3, #0
    cd74:	d144      	bne.n	ce00 <z_nrf_clock_control_lf_on+0xd8>
	__asm__ volatile(
    cd76:	f04f 0320 	mov.w	r3, #32
    cd7a:	f3ef 8611 	mrs	r6, BASEPRI
    cd7e:	f383 8811 	msr	BASEPRI, r3
    cd82:	f3bf 8f6f 	isb	sy
    cd86:	2401      	movs	r4, #1
                    (nrf_clock_lfclk_t)((p_reg->LFCLKSTAT & CLOCK_LFCLKSTAT_SRC_Msk)
    cd88:	4d23      	ldr	r5, [pc, #140]	; (ce18 <z_nrf_clock_control_lf_on+0xf0>)
    return (bool)*((volatile uint32_t *)((uint8_t *)p_reg + event));
    cd8a:	f8df 809c 	ldr.w	r8, [pc, #156]	; ce28 <z_nrf_clock_control_lf_on+0x100>
    cd8e:	46a9      	mov	r9, r5
                    (nrf_clock_lfclk_t)((p_reg->LFCLKSTAT & CLOCK_LFCLKSTAT_SRC_Msk)
    cd90:	f8d5 3418 	ldr.w	r3, [r5, #1048]	; 0x418
            if ((p_reg->LFCLKSTAT & CLOCK_LFCLKSTAT_STATE_Msk)
    cd94:	f8d5 2418 	ldr.w	r2, [r5, #1048]	; 0x418
    cd98:	03d2      	lsls	r2, r2, #15
    cd9a:	d50c      	bpl.n	cdb6 <z_nrf_clock_control_lf_on+0x8e>
	while (!(nrfx_clock_is_running(d, (void *)&type)
    cd9c:	f003 0303 	and.w	r3, r3, #3
    cda0:	2b02      	cmp	r3, #2
    cda2:	d001      	beq.n	cda8 <z_nrf_clock_control_lf_on+0x80>
		     || (mode == CLOCK_CONTROL_NRF_LF_START_AVAILABLE)))) {
    cda4:	2f01      	cmp	r7, #1
    cda6:	d106      	bne.n	cdb6 <z_nrf_clock_control_lf_on+0x8e>
	if (isr_mode) {
    cda8:	b334      	cbz	r4, cdf8 <z_nrf_clock_control_lf_on+0xd0>
	__asm__ volatile(
    cdaa:	f386 8811 	msr	BASEPRI, r6
    cdae:	f3bf 8f6f 	isb	sy
}
    cdb2:	e8bd 83f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, pc}
			if (isr_mode) {
    cdb6:	b1d4      	cbz	r4, cdee <z_nrf_clock_control_lf_on+0xc6>
 *
 * @return N/A
 */
static inline void k_cpu_atomic_idle(unsigned int key)
{
	arch_cpu_atomic_idle(key);
    cdb8:	4630      	mov	r0, r6
    cdba:	f000 f9df 	bl	d17c <arch_cpu_atomic_idle>
    return (nrf_clock_lfclk_t)(p_reg->LFCLKSRC);
    cdbe:	f8d5 3518 	ldr.w	r3, [r5, #1304]	; 0x518
		if ((target_type ==  NRF_CLOCK_LFCLK_Xtal)
    cdc2:	b2db      	uxtb	r3, r3
    cdc4:	2b01      	cmp	r3, #1
    cdc6:	d1e3      	bne.n	cd90 <z_nrf_clock_control_lf_on+0x68>
    return (bool)*((volatile uint32_t *)((uint8_t *)p_reg + event));
    cdc8:	f8d8 2000 	ldr.w	r2, [r8]
		    && nrf_clock_event_check(NRF_CLOCK,
    cdcc:	2a00      	cmp	r2, #0
    cdce:	d0df      	beq.n	cd90 <z_nrf_clock_control_lf_on+0x68>
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0x0UL;
    cdd0:	2200      	movs	r2, #0
    cdd2:	f8c8 2000 	str.w	r2, [r8]
#ifndef NRF_DECLARE_ONLY

NRF_STATIC_INLINE void nrf_event_readback(void * p_event_reg)
{
#if NRFX_CHECK(NRFX_EVENT_READBACK_ENABLED) && !defined(NRF51)
    (void)*((volatile uint32_t *)(p_event_reg));
    cdd6:	f8d8 2000 	ldr.w	r2, [r8]
    p_reg->LFCLKSRC = (uint32_t)(source);
    cdda:	2202      	movs	r2, #2
 */
__STATIC_INLINE void __NVIC_ClearPendingIRQ(IRQn_Type IRQn)
{
  if ((int32_t)(IRQn) >= 0)
  {
    NVIC->ICPR[(((uint32_t)IRQn) >> 5UL)] = (uint32_t)(1UL << (((uint32_t)IRQn) & 0x1FUL));
    cddc:	2120      	movs	r1, #32
    cdde:	f8c5 2518 	str.w	r2, [r5, #1304]	; 0x518
    cde2:	4a0f      	ldr	r2, [pc, #60]	; (ce20 <z_nrf_clock_control_lf_on+0xf8>)
    cde4:	f8c2 1180 	str.w	r1, [r2, #384]	; 0x180
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)task)) = 0x1UL;
    cde8:	4a0e      	ldr	r2, [pc, #56]	; (ce24 <z_nrf_clock_control_lf_on+0xfc>)
    cdea:	6013      	str	r3, [r2, #0]
}
    cdec:	e7d0      	b.n	cd90 <z_nrf_clock_control_lf_on+0x68>
	return z_impl_k_sleep(timeout);
    cdee:	2100      	movs	r1, #0
    cdf0:	2021      	movs	r0, #33	; 0x21
    cdf2:	f001 fd5d 	bl	e8b0 <z_impl_k_sleep>
	return k_sleep(Z_TIMEOUT_MS(ms));
    cdf6:	e7e2      	b.n	cdbe <z_nrf_clock_control_lf_on+0x96>
    p_reg->INTENSET = mask;
    cdf8:	2302      	movs	r3, #2
    cdfa:	f8c9 3304 	str.w	r3, [r9, #772]	; 0x304
}
    cdfe:	e7d8      	b.n	cdb2 <z_nrf_clock_control_lf_on+0x8a>
    p_reg->INTENCLR = mask;
    ce00:	2202      	movs	r2, #2
    ce02:	4b05      	ldr	r3, [pc, #20]	; (ce18 <z_nrf_clock_control_lf_on+0xf0>)
	int key = isr_mode ? irq_lock() : 0;
    ce04:	4606      	mov	r6, r0
    ce06:	f8c3 2308 	str.w	r2, [r3, #776]	; 0x308
}
    ce0a:	e7bd      	b.n	cd88 <z_nrf_clock_control_lf_on+0x60>
    ce0c:	20010200 	.word	0x20010200
    ce10:	2001019c 	.word	0x2001019c
    ce14:	200101c8 	.word	0x200101c8
    ce18:	40005000 	.word	0x40005000
    ce1c:	20010286 	.word	0x20010286
    ce20:	e000e100 	.word	0xe000e100
    ce24:	40005008 	.word	0x40005008
    ce28:	40005104 	.word	0x40005104

0000ce2c <handle_next_cycle_case>:
 * counter progresses during that time it means that 1 cycle elapsed and
 * interrupt is set pending.
 */
static void handle_next_cycle_case(uint32_t t)
{
	set_comparator(t + 2);
    ce2c:	1c82      	adds	r2, r0, #2

#ifndef NRF_DECLARE_ONLY

NRF_STATIC_INLINE  void nrf_rtc_cc_set(NRF_RTC_Type * p_reg, uint32_t ch, uint32_t cc_val)
{
    p_reg->CC[ch] = cc_val;
    ce2e:	4b08      	ldr	r3, [pc, #32]	; (ce50 <handle_next_cycle_case+0x24>)
	nrf_rtc_cc_set(RTC, 0, cyc & COUNTER_MAX);
    ce30:	f022 427f 	bic.w	r2, r2, #4278190080	; 0xff000000
    ce34:	f8c3 2540 	str.w	r2, [r3, #1344]	; 0x540
    nrf_event_readback((uint8_t *)p_reg + (uint32_t)event);
}

NRF_STATIC_INLINE uint32_t nrf_rtc_counter_get(NRF_RTC_Type const * p_reg)
{
     return p_reg->COUNTER;
    ce38:	f8d3 2504 	ldr.w	r2, [r3, #1284]	; 0x504
	while (t != counter()) {
    ce3c:	4290      	cmp	r0, r2
    ce3e:	d100      	bne.n	ce42 <handle_next_cycle_case+0x16>
		 * generated. Trigger interrupt.
		 */
		t = counter();
		set_comparator(t + 2);
	}
}
    ce40:	4770      	bx	lr
    ce42:	f8d3 0504 	ldr.w	r0, [r3, #1284]	; 0x504
		set_comparator(t + 2);
    ce46:	1c82      	adds	r2, r0, #2
	nrf_rtc_cc_set(RTC, 0, cyc & COUNTER_MAX);
    ce48:	f022 427f 	bic.w	r2, r2, #4278190080	; 0xff000000
    ce4c:	e7f2      	b.n	ce34 <handle_next_cycle_case+0x8>
    ce4e:	bf00      	nop
    ce50:	40015000 	.word	0x40015000

0000ce54 <rtc_nrf_isr>:
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0;
    ce54:	2200      	movs	r2, #0
    ce56:	4b07      	ldr	r3, [pc, #28]	; (ce74 <rtc_nrf_isr+0x20>)
    ce58:	601a      	str	r2, [r3, #0]
    ce5a:	681b      	ldr	r3, [r3, #0]
{
	ARG_UNUSED(arg);
	event_clear();

	uint32_t t = get_comparator();
	uint32_t dticks = counter_sub(t, last_count) / CYC_PER_TICK;
    ce5c:	4a06      	ldr	r2, [pc, #24]	; (ce78 <rtc_nrf_isr+0x24>)
    return p_reg->CC[ch];
    ce5e:	4b07      	ldr	r3, [pc, #28]	; (ce7c <rtc_nrf_isr+0x28>)
    ce60:	f8d3 0540 	ldr.w	r0, [r3, #1344]	; 0x540
    ce64:	6813      	ldr	r3, [r2, #0]
	return (a - b) & COUNTER_MAX;
    ce66:	1ac0      	subs	r0, r0, r3
    ce68:	f020 407f 	bic.w	r0, r0, #4278190080	; 0xff000000

	last_count += dticks * CYC_PER_TICK;
    ce6c:	4403      	add	r3, r0
    ce6e:	6013      	str	r3, [r2, #0]
		 * so it won't get preempted by the interrupt.
		 */
		set_absolute_alarm(last_count + CYC_PER_TICK);
	}

	z_clock_announce(IS_ENABLED(CONFIG_TICKLESS_KERNEL) ? dticks : (dticks > 0));
    ce70:	f001 bef0 	b.w	ec54 <z_clock_announce>
    ce74:	40015140 	.word	0x40015140
    ce78:	20010204 	.word	0x20010204
    ce7c:	40015000 	.word	0x40015000

0000ce80 <z_clock_driver_init>:
}

int z_clock_driver_init(const struct device *device)
{
    ce80:	b538      	push	{r3, r4, r5, lr}
}

NRF_STATIC_INLINE void nrf_rtc_prescaler_set(NRF_RTC_Type * p_reg, uint32_t val)
{
    NRFX_ASSERT(val <= (RTC_PRESCALER_PRESCALER_Msk >> RTC_PRESCALER_PRESCALER_Pos));
    p_reg->PRESCALER = val;
    ce82:	2400      	movs	r4, #0
    ce84:	f44f 1200 	mov.w	r2, #2097152	; 0x200000
    ce88:	4d0e      	ldr	r5, [pc, #56]	; (cec4 <z_clock_driver_init+0x44>)
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0;
    ce8a:	4b0f      	ldr	r3, [pc, #60]	; (cec8 <z_clock_driver_init+0x48>)
    p_reg->PRESCALER = val;
    ce8c:	f8c5 4508 	str.w	r4, [r5, #1288]	; 0x508
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0;
    ce90:	601c      	str	r4, [r3, #0]
    ce92:	681b      	ldr	r3, [r3, #0]
    ce94:	4b0d      	ldr	r3, [pc, #52]	; (cecc <z_clock_driver_init+0x4c>)
	nrf_rtc_prescaler_set(RTC, 0);
	event_clear();
	NVIC_ClearPendingIRQ(RTC_IRQn);
	int_enable();

	IRQ_CONNECT(RTC_IRQn, 1, rtc_nrf_isr, 0, 0);
    ce96:	2101      	movs	r1, #1
    ce98:	f8c3 2180 	str.w	r2, [r3, #384]	; 0x180
    p_reg->INTENSET = mask;
    ce9c:	f44f 3380 	mov.w	r3, #65536	; 0x10000
    cea0:	4622      	mov	r2, r4
    cea2:	f8c5 3304 	str.w	r3, [r5, #772]	; 0x304
    cea6:	2015      	movs	r0, #21
    cea8:	f000 f908 	bl	d0bc <z_arm_irq_priority_set>
	irq_enable(RTC_IRQn);
    ceac:	2015      	movs	r0, #21
    ceae:	f000 f8e7 	bl	d080 <arch_irq_enable>
    return (uint32_t)p_reg + task;
}

NRF_STATIC_INLINE void nrf_rtc_task_trigger(NRF_RTC_Type * p_reg, nrf_rtc_task_t task)
{
    *(__IO uint32_t *)((uint32_t)p_reg + task) = 1;
    ceb2:	2301      	movs	r3, #1
    ceb4:	4a06      	ldr	r2, [pc, #24]	; (ced0 <z_clock_driver_init+0x50>)

	if (!IS_ENABLED(CONFIG_TICKLESS_KERNEL)) {
		set_comparator(counter() + CYC_PER_TICK);
	}

	z_nrf_clock_control_lf_on(mode);
    ceb6:	2002      	movs	r0, #2
    ceb8:	6013      	str	r3, [r2, #0]
    ceba:	602b      	str	r3, [r5, #0]
    cebc:	f7ff ff34 	bl	cd28 <z_nrf_clock_control_lf_on>

	return 0;
}
    cec0:	4620      	mov	r0, r4
    cec2:	bd38      	pop	{r3, r4, r5, pc}
    cec4:	40015000 	.word	0x40015000
    cec8:	40015140 	.word	0x40015140
    cecc:	e000e100 	.word	0xe000e100
    ced0:	40015008 	.word	0x40015008

0000ced4 <z_clock_set_timeout>:

void z_clock_set_timeout(int32_t ticks, bool idle)
{
    ced4:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
     return p_reg->COUNTER;
    ced6:	4b2d      	ldr	r3, [pc, #180]	; (cf8c <z_clock_set_timeout+0xb8>)

	if (!IS_ENABLED(CONFIG_TICKLESS_KERNEL)) {
		return;
	}

	ticks = (ticks == K_TICKS_FOREVER) ? MAX_TICKS : ticks;
    ced8:	4c2d      	ldr	r4, [pc, #180]	; (cf90 <z_clock_set_timeout+0xbc>)
    ceda:	f8d3 2504 	ldr.w	r2, [r3, #1284]	; 0x504
	ticks = MAX(MIN(ticks - 1, (int32_t)MAX_TICKS), 0);

	uint32_t unannounced = counter_sub(counter(), last_count);
    cede:	4b2d      	ldr	r3, [pc, #180]	; (cf94 <z_clock_set_timeout+0xc0>)
	ticks = (ticks == K_TICKS_FOREVER) ? MAX_TICKS : ticks;
    cee0:	f1b0 3fff 	cmp.w	r0, #4294967295
    cee4:	bf08      	it	eq
    cee6:	4620      	moveq	r0, r4
	uint32_t unannounced = counter_sub(counter(), last_count);
    cee8:	6819      	ldr	r1, [r3, #0]
	return (a - b) & COUNTER_MAX;
    ceea:	1a52      	subs	r2, r2, r1
    ceec:	f022 437f 	bic.w	r3, r2, #4278190080	; 0xff000000
	/* If we haven't announced for more than half the 24-bit wrap
	 * duration, then force an announce to avoid loss of a wrap
	 * event.  This can happen if new timeouts keep being set
	 * before the existing one triggers the interrupt.
	 */
	if (unannounced >= COUNTER_HALF_SPAN) {
    cef0:	0212      	lsls	r2, r2, #8
    cef2:	d438      	bmi.n	cf66 <z_clock_set_timeout+0x92>
	ticks = MAX(MIN(ticks - 1, (int32_t)MAX_TICKS), 0);
    cef4:	3801      	subs	r0, #1
    cef6:	ea20 70e0 	bic.w	r0, r0, r0, asr #31
    cefa:	42a0      	cmp	r0, r4
    cefc:	bfa8      	it	ge
    cefe:	4620      	movge	r0, r4
	}

	/* Get the cycles from last_count to the tick boundary after
	 * the requested ticks have passed starting now.
	 */
	cyc = ticks * CYC_PER_TICK + 1 + unannounced;
    cf00:	3301      	adds	r3, #1
    cf02:	4418      	add	r0, r3
	 */
	if (cyc > MAX_CYCLES) {
		cyc = MAX_CYCLES;
	}

	cyc += last_count;
    cf04:	42a0      	cmp	r0, r4
    cf06:	bf94      	ite	ls
    cf08:	180c      	addls	r4, r1, r0
    cf0a:	190c      	addhi	r4, r1, r4
    p_reg->INTENCLR = mask;
    cf0c:	f44f 3080 	mov.w	r0, #65536	; 0x10000
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0;
    cf10:	2600      	movs	r6, #0
    p_reg->INTENCLR = mask;
    cf12:	4a1e      	ldr	r2, [pc, #120]	; (cf8c <z_clock_set_timeout+0xb8>)
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0;
    cf14:	4d20      	ldr	r5, [pc, #128]	; (cf98 <z_clock_set_timeout+0xc4>)
    p_reg->INTENCLR = mask;
    cf16:	f8c2 0308 	str.w	r0, [r2, #776]	; 0x308
     return p_reg->COUNTER;
    cf1a:	f8d2 1504 	ldr.w	r1, [r2, #1284]	; 0x504
    return p_reg->CC[ch];
    cf1e:	f8d2 3540 	ldr.w	r3, [r2, #1344]	; 0x540
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0;
    cf22:	602e      	str	r6, [r5, #0]
	return (a - b) & COUNTER_MAX;
    cf24:	1a5b      	subs	r3, r3, r1
    cf26:	f023 437f 	bic.w	r3, r3, #4278190080	; 0xff000000
    cf2a:	682f      	ldr	r7, [r5, #0]
	if (counter_sub(prev_val, now) == 1) {
    cf2c:	2b01      	cmp	r3, #1
	nrf_rtc_cc_set(RTC, 0, cyc & COUNTER_MAX);
    cf2e:	f021 477f 	bic.w	r7, r1, #4278190080	; 0xff000000
    p_reg->CC[ch] = cc_val;
    cf32:	f8c2 7540 	str.w	r7, [r2, #1344]	; 0x540
}

NRF_STATIC_INLINE void nrf_rtc_event_enable(NRF_RTC_Type * p_reg, uint32_t mask)
{
    p_reg->EVTENSET = mask;
    cf36:	f8c2 0344 	str.w	r0, [r2, #836]	; 0x344
	if (counter_sub(prev_val, now) == 1) {
    cf3a:	d104      	bne.n	cf46 <z_clock_set_timeout+0x72>
	z_impl_k_busy_wait(usec_to_wait);
    cf3c:	200f      	movs	r0, #15
    cf3e:	f002 fbc7 	bl	f6d0 <z_impl_k_busy_wait>
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0;
    cf42:	602e      	str	r6, [r5, #0]
    cf44:	682b      	ldr	r3, [r5, #0]
    cf46:	f44f 1200 	mov.w	r2, #2097152	; 0x200000
    cf4a:	4b14      	ldr	r3, [pc, #80]	; (cf9c <z_clock_set_timeout+0xc8>)
    cf4c:	f8c3 2180 	str.w	r2, [r3, #384]	; 0x180
     return p_reg->COUNTER;
    cf50:	4b0e      	ldr	r3, [pc, #56]	; (cf8c <z_clock_set_timeout+0xb8>)
    cf52:	f8d3 0504 	ldr.w	r0, [r3, #1284]	; 0x504
	return (a - b) & COUNTER_MAX;
    cf56:	1a22      	subs	r2, r4, r0
    cf58:	f022 427f 	bic.w	r2, r2, #4278190080	; 0xff000000
	if (diff == 1) {
    cf5c:	2a01      	cmp	r2, #1
    cf5e:	d104      	bne.n	cf6a <z_clock_set_timeout+0x96>
		handle_next_cycle_case(t);
    cf60:	f7ff ff64 	bl	ce2c <handle_next_cycle_case>
    cf64:	e00b      	b.n	cf7e <z_clock_set_timeout+0xaa>
		ticks = 0;
    cf66:	2000      	movs	r0, #0
    cf68:	e7ca      	b.n	cf00 <z_clock_set_timeout+0x2c>
	nrf_rtc_cc_set(RTC, 0, cyc & COUNTER_MAX);
    cf6a:	f024 427f 	bic.w	r2, r4, #4278190080	; 0xff000000
    p_reg->CC[ch] = cc_val;
    cf6e:	f8c3 2540 	str.w	r2, [r3, #1344]	; 0x540
     return p_reg->COUNTER;
    cf72:	f8d3 0504 	ldr.w	r0, [r3, #1284]	; 0x504
	return (a - b) & COUNTER_MAX;
    cf76:	1a24      	subs	r4, r4, r0
    cf78:	3c02      	subs	r4, #2
	if (diff > MAX_CYCLES) {
    cf7a:	0223      	lsls	r3, r4, #8
    cf7c:	d4f0      	bmi.n	cf60 <z_clock_set_timeout+0x8c>
    p_reg->INTENSET = mask;
    cf7e:	f44f 3280 	mov.w	r2, #65536	; 0x10000
    cf82:	4b02      	ldr	r3, [pc, #8]	; (cf8c <z_clock_set_timeout+0xb8>)
    cf84:	f8c3 2304 	str.w	r2, [r3, #772]	; 0x304
	set_protected_absolute_alarm(cyc);
}
    cf88:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    cf8a:	bf00      	nop
    cf8c:	40015000 	.word	0x40015000
    cf90:	007fffff 	.word	0x007fffff
    cf94:	20010204 	.word	0x20010204
    cf98:	40015140 	.word	0x40015140
    cf9c:	e000e100 	.word	0xe000e100

0000cfa0 <z_clock_elapsed>:
	__asm__ volatile(
    cfa0:	f04f 0220 	mov.w	r2, #32
    cfa4:	f3ef 8311 	mrs	r3, BASEPRI
    cfa8:	f382 8811 	msr	BASEPRI, r2
    cfac:	f3bf 8f6f 	isb	sy
     return p_reg->COUNTER;
    cfb0:	4a06      	ldr	r2, [pc, #24]	; (cfcc <z_clock_elapsed+0x2c>)
    cfb2:	f8d2 0504 	ldr.w	r0, [r2, #1284]	; 0x504
	if (!IS_ENABLED(CONFIG_TICKLESS_KERNEL)) {
		return 0;
	}

	k_spinlock_key_t key = k_spin_lock(&lock);
	uint32_t ret = counter_sub(counter(), last_count) / CYC_PER_TICK;
    cfb6:	4a06      	ldr	r2, [pc, #24]	; (cfd0 <z_clock_elapsed+0x30>)
	return (a - b) & COUNTER_MAX;
    cfb8:	6812      	ldr	r2, [r2, #0]
    cfba:	1a80      	subs	r0, r0, r2
    cfbc:	f020 407f 	bic.w	r0, r0, #4278190080	; 0xff000000
	__asm__ volatile(
    cfc0:	f383 8811 	msr	BASEPRI, r3
    cfc4:	f3bf 8f6f 	isb	sy

	k_spin_unlock(&lock, key);
	return ret;
}
    cfc8:	4770      	bx	lr
    cfca:	bf00      	nop
    cfcc:	40015000 	.word	0x40015000
    cfd0:	20010204 	.word	0x20010204

0000cfd4 <arch_swap>:
 * as BASEPRI is not available.
 */
int arch_swap(unsigned int key)
{
	/* store off key and return value */
	_current->arch.basepri = key;
    cfd4:	4a09      	ldr	r2, [pc, #36]	; (cffc <arch_swap+0x28>)
	_current->arch.swap_return_value = _k_neg_eagain;
    cfd6:	490a      	ldr	r1, [pc, #40]	; (d000 <arch_swap+0x2c>)
	_current->arch.basepri = key;
    cfd8:	6893      	ldr	r3, [r2, #8]
	_current->arch.swap_return_value = _k_neg_eagain;
    cfda:	6809      	ldr	r1, [r1, #0]
	_current->arch.basepri = key;
    cfdc:	6798      	str	r0, [r3, #120]	; 0x78
	_current->arch.swap_return_value = _k_neg_eagain;
    cfde:	67d9      	str	r1, [r3, #124]	; 0x7c

#if defined(CONFIG_CPU_CORTEX_M)
	/* set pending bit to make sure we will take a PendSV exception */
	SCB->ICSR |= SCB_ICSR_PENDSVSET_Msk;
    cfe0:	4908      	ldr	r1, [pc, #32]	; (d004 <arch_swap+0x30>)
    cfe2:	684b      	ldr	r3, [r1, #4]
    cfe4:	f043 5380 	orr.w	r3, r3, #268435456	; 0x10000000
    cfe8:	604b      	str	r3, [r1, #4]
    cfea:	2300      	movs	r3, #0
    cfec:	f383 8811 	msr	BASEPRI, r3
    cff0:	f3bf 8f6f 	isb	sy
#endif

	/* Context switch is performed here. Returning implies the
	 * thread has been context-switched-in again.
	 */
	return _current->arch.swap_return_value;
    cff4:	6893      	ldr	r3, [r2, #8]
}
    cff6:	6fd8      	ldr	r0, [r3, #124]	; 0x7c
    cff8:	4770      	bx	lr
    cffa:	bf00      	nop
    cffc:	20010244 	.word	0x20010244
    d000:	0000fad8 	.word	0x0000fad8
    d004:	e000ed00 	.word	0xe000ed00

0000d008 <z_arm_pendsv>:
    pop {r0, lr}
#endif /* CONFIG_ARMV6_M_ARMV8_M_BASELINE */
#endif /* CONFIG_TRACING */

    /* load _kernel into r1 and current k_thread into r2 */
    ldr r1, =_kernel
    d008:	4913      	ldr	r1, [pc, #76]	; (d058 <z_arm_pendsv+0x50>)
    ldr r2, [r1, #_kernel_offset_to_current]
    d00a:	688a      	ldr	r2, [r1, #8]

    /* addr of callee-saved regs in thread in r0 */
    ldr r0, =_thread_offset_to_callee_saved
    d00c:	f04f 0038 	mov.w	r0, #56	; 0x38
    add r0, r2
    d010:	4410      	add	r0, r2

    /* save callee-saved + psp in thread */
#if defined(CONFIG_CPU_CORTEX_M)
    mrs ip, PSP
    d012:	f3ef 8c09 	mrs	ip, PSP
    mov r6, r11
    mov r7, ip
    /* store r8-12 */
    stmea r0!, {r3-r7}
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    stmia r0, {v1-v8, ip}
    d016:	e880 1ff0 	stmia.w	r0, {r4, r5, r6, r7, r8, r9, sl, fp, ip}

    /* Protect the kernel state while we play with the thread lists */
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
    cpsid i
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    movs.n r0, #_EXC_IRQ_DEFAULT_PRIO
    d01a:	2020      	movs	r0, #32
    msr BASEPRI, r0
    d01c:	f380 8811 	msr	BASEPRI, r0
    isb /* Make the effect of disabling interrupts be realized immediately */
    d020:	f3bf 8f6f 	isb	sy
     * the new thread is context-switched in since all decisions
     * to pend PendSV have been taken with the current kernel
     * state and this is what we're handling currently.
     */
#if defined(CONFIG_CPU_CORTEX_M)
    ldr v4, =_SCS_ICSR
    d024:	4f0d      	ldr	r7, [pc, #52]	; (d05c <z_arm_pendsv+0x54>)
    ldr v3, =_SCS_ICSR_UNPENDSV
    d026:	f04f 6600 	mov.w	r6, #134217728	; 0x8000000
#endif

    /* _kernel is still in r1 */

    /* fetch the thread to run from the ready queue cache */
    ldr r2, [r1, #_kernel_offset_to_ready_q_cache]
    d02a:	6a4a      	ldr	r2, [r1, #36]	; 0x24

    str r2, [r1, #_kernel_offset_to_current]
    d02c:	608a      	str	r2, [r1, #8]
     * has been handled.
     */

    /* _SCS_ICSR is still in v4 and _SCS_ICSR_UNPENDSV in v3 */
#if defined(CONFIG_CPU_CORTEX_M)
    str v3, [v4, #0]
    d02e:	603e      	str	r6, [r7, #0]

    ldr r0, [r4]
    movs.n r3, #0
    str r3, [r4]
#else
    ldr r0, [r2, #_thread_offset_to_basepri]
    d030:	6f90      	ldr	r0, [r2, #120]	; 0x78
    movs r3, #0
    d032:	2300      	movs	r3, #0
    str r3, [r2, #_thread_offset_to_basepri]
    d034:	6793      	str	r3, [r2, #120]	; 0x78
    /* restore r4-r7, go back 9*4 bytes to the start of the stored block */
    subs r0, #36
    ldmia r0!, {r4-r7}
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    /* restore BASEPRI for the incoming thread */
    msr BASEPRI, r0
    d036:	f380 8811 	msr	BASEPRI, r0
    isb

#endif

    /* load callee-saved + psp from thread */
    add r0, r2, #_thread_offset_to_callee_saved
    d03a:	f102 0038 	add.w	r0, r2, #56	; 0x38
    ldmia r0, {v1-v8, ip}
    d03e:	e890 1ff0 	ldmia.w	r0, {r4, r5, r6, r7, r8, r9, sl, fp, ip}
#else
#error Unknown ARM architecture
#endif /* CONFIG_ARMV6_M_ARMV8_M_BASELINE */

#if defined(CONFIG_CPU_CORTEX_M)
    msr PSP, ip
    d042:	f38c 8809 	msr	PSP, ip
#endif

#ifdef CONFIG_BUILTIN_STACK_GUARD
    /* r2 contains k_thread */
    add r0, r2, #0
    d046:	f102 0000 	add.w	r0, r2, #0
    push {r2, lr}
    d04a:	b504      	push	{r2, lr}
    bl configure_builtin_stack_guard
    d04c:	f002 f90a 	bl	f264 <configure_builtin_stack_guard>
    pop {r2, lr}
    d050:	e8bd 4004 	ldmia.w	sp!, {r2, lr}

    /*
     * Cortex-M: return from PendSV exception
     * Cortex-R: return to the caller (_IntExit or z_arm_svc)
     */
    bx lr
    d054:	4770      	bx	lr
    d056:	0000      	.short	0x0000
    ldr r1, =_kernel
    d058:	20010244 	.word	0x20010244
    ldr v4, =_SCS_ICSR
    d05c:	e000ed04 	.word	0xe000ed04

0000d060 <z_arm_svc>:
  bne _stack_frame_endif
_stack_frame_msp:
  mrs r0, MSP
_stack_frame_endif:
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    tst lr, #0x4    /* did we come from thread mode ? */
    d060:	f01e 0f04 	tst.w	lr, #4
    ite eq  /* if zero (equal), came from handler mode */
    d064:	bf0c      	ite	eq
        mrseq r0, MSP   /* handler mode, stack frame is on MSP */
    d066:	f3ef 8008 	mrseq	r0, MSP
        mrsne r0, PSP   /* thread mode, stack frame is on PSP */
    d06a:	f3ef 8009 	mrsne	r0, PSP
#endif


    /* Figure out what SVC call number was invoked */

    ldr r1, [r0, #24]   /* grab address of PC from stack frame */
    d06e:	6981      	ldr	r1, [r0, #24]
     */
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
    subs r1, r1, #2
    ldrb r1, [r1]
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    ldrb r1, [r1, #-2]
    d070:	f811 1c02 	ldrb.w	r1, [r1, #-2]
#endif
    bne _oops

#endif /* CONFIG_USERSPACE */

    cmp r1, #2
    d074:	2902      	cmp	r1, #2
    beq _oops
    d076:	d0ff      	beq.n	d078 <_oops>

0000d078 <_oops>:
    /* exception return is done in z_arm_int_exit() */
    b z_arm_int_exit
#endif

_oops:
    push {r0, lr}
    d078:	b501      	push	{r0, lr}
    bl z_do_kernel_oops
    d07a:	f002 f8f9 	bl	f270 <z_do_kernel_oops>
    /* return from SVC exception is done here */
    pop {r0, pc}
    d07e:	bd01      	pop	{r0, pc}

0000d080 <arch_irq_enable>:
#define REG_FROM_IRQ(irq) (irq / NUM_IRQS_PER_REG)
#define BIT_FROM_IRQ(irq) (irq % NUM_IRQS_PER_REG)

void arch_irq_enable(unsigned int irq)
{
	NVIC_EnableIRQ((IRQn_Type)irq);
    d080:	b243      	sxtb	r3, r0
  if ((int32_t)(IRQn) >= 0)
    d082:	2b00      	cmp	r3, #0
    d084:	db08      	blt.n	d098 <arch_irq_enable+0x18>
    NVIC->ISER[(((uint32_t)IRQn) >> 5UL)] = (uint32_t)(1UL << (((uint32_t)IRQn) & 0x1FUL));
    d086:	2201      	movs	r2, #1
    d088:	f000 001f 	and.w	r0, r0, #31
    d08c:	fa02 f000 	lsl.w	r0, r2, r0
    d090:	4a02      	ldr	r2, [pc, #8]	; (d09c <arch_irq_enable+0x1c>)
    d092:	095b      	lsrs	r3, r3, #5
    d094:	f842 0023 	str.w	r0, [r2, r3, lsl #2]
}
    d098:	4770      	bx	lr
    d09a:	bf00      	nop
    d09c:	e000e100 	.word	0xe000e100

0000d0a0 <arch_irq_is_enabled>:
	NVIC_DisableIRQ((IRQn_Type)irq);
}

int arch_irq_is_enabled(unsigned int irq)
{
	return NVIC->ISER[REG_FROM_IRQ(irq)] & BIT(BIT_FROM_IRQ(irq));
    d0a0:	4b05      	ldr	r3, [pc, #20]	; (d0b8 <arch_irq_is_enabled+0x18>)
    d0a2:	0942      	lsrs	r2, r0, #5
    d0a4:	f853 2022 	ldr.w	r2, [r3, r2, lsl #2]
    d0a8:	2301      	movs	r3, #1
    d0aa:	f000 001f 	and.w	r0, r0, #31
    d0ae:	fa03 f000 	lsl.w	r0, r3, r0
}
    d0b2:	4010      	ands	r0, r2
    d0b4:	4770      	bx	lr
    d0b6:	bf00      	nop
    d0b8:	e000e100 	.word	0xe000e100

0000d0bc <z_arm_irq_priority_set>:
	 */
	__ASSERT(prio <= (BIT(NUM_IRQ_PRIO_BITS) - 1),
		 "invalid priority %d! values must be less than %lu\n",
		 prio - _IRQ_PRIO_OFFSET,
		 BIT(NUM_IRQ_PRIO_BITS) - (_IRQ_PRIO_OFFSET));
	NVIC_SetPriority((IRQn_Type)irq, prio);
    d0bc:	b243      	sxtb	r3, r0
  \param [in]  priority  Priority to set.
  \note    The priority cannot be set for every processor exception.
 */
__STATIC_INLINE void __NVIC_SetPriority(IRQn_Type IRQn, uint32_t priority)
{
  if ((int32_t)(IRQn) >= 0)
    d0be:	2b00      	cmp	r3, #0
	prio += _IRQ_PRIO_OFFSET;
    d0c0:	f101 0101 	add.w	r1, r1, #1
  {
    NVIC->IPR[((uint32_t)IRQn)]               = (uint8_t)((priority << (8U - __NVIC_PRIO_BITS)) & (uint32_t)0xFFUL);
    d0c4:	bfac      	ite	ge
    d0c6:	f103 4360 	addge.w	r3, r3, #3758096384	; 0xe0000000
  }
  else
  {
    SCB->SHPR[(((uint32_t)IRQn) & 0xFUL)-4UL] = (uint8_t)((priority << (8U - __NVIC_PRIO_BITS)) & (uint32_t)0xFFUL);
    d0ca:	4b06      	ldrlt	r3, [pc, #24]	; (d0e4 <z_arm_irq_priority_set+0x28>)
    d0cc:	ea4f 1141 	mov.w	r1, r1, lsl #5
    d0d0:	b2c9      	uxtb	r1, r1
    NVIC->IPR[((uint32_t)IRQn)]               = (uint8_t)((priority << (8U - __NVIC_PRIO_BITS)) & (uint32_t)0xFFUL);
    d0d2:	bfab      	itete	ge
    d0d4:	f503 4361 	addge.w	r3, r3, #57600	; 0xe100
    SCB->SHPR[(((uint32_t)IRQn) & 0xFUL)-4UL] = (uint8_t)((priority << (8U - __NVIC_PRIO_BITS)) & (uint32_t)0xFFUL);
    d0d8:	f000 000f 	andlt.w	r0, r0, #15
    NVIC->IPR[((uint32_t)IRQn)]               = (uint8_t)((priority << (8U - __NVIC_PRIO_BITS)) & (uint32_t)0xFFUL);
    d0dc:	f883 1300 	strbge.w	r1, [r3, #768]	; 0x300
    SCB->SHPR[(((uint32_t)IRQn) & 0xFUL)-4UL] = (uint8_t)((priority << (8U - __NVIC_PRIO_BITS)) & (uint32_t)0xFFUL);
    d0e0:	5419      	strblt	r1, [r3, r0]
}
    d0e2:	4770      	bx	lr
    d0e4:	e000ed14 	.word	0xe000ed14

0000d0e8 <arch_new_thread>:

#if defined(CONFIG_CPU_CORTEX_M)
	/* force ARM mode by clearing LSB of address */
	iframe->pc &= 0xfffffffe;
#endif
	iframe->a1 = (uint32_t)entry;
    d0e8:	f842 3c20 	str.w	r3, [r2, #-32]
	iframe->a2 = (uint32_t)p1;
    d0ec:	9b00      	ldr	r3, [sp, #0]
	iframe->pc &= 0xfffffffe;
    d0ee:	490b      	ldr	r1, [pc, #44]	; (d11c <arch_new_thread+0x34>)
	iframe->a2 = (uint32_t)p1;
    d0f0:	f842 3c1c 	str.w	r3, [r2, #-28]
	iframe->a3 = (uint32_t)p2;
    d0f4:	9b01      	ldr	r3, [sp, #4]
	iframe->pc &= 0xfffffffe;
    d0f6:	f021 0101 	bic.w	r1, r1, #1
	iframe->a3 = (uint32_t)p2;
    d0fa:	f842 3c18 	str.w	r3, [r2, #-24]
	iframe->a4 = (uint32_t)p3;
    d0fe:	9b02      	ldr	r3, [sp, #8]
	iframe->pc &= 0xfffffffe;
    d100:	f842 1c08 	str.w	r1, [r2, #-8]
	iframe->a4 = (uint32_t)p3;
    d104:	f842 3c14 	str.w	r3, [r2, #-20]

#if defined(CONFIG_CPU_CORTEX_M)
	iframe->xpsr =
    d108:	f04f 7380 	mov.w	r3, #16777216	; 0x1000000
    d10c:	f842 3c04 	str.w	r3, [r2, #-4]
	iframe->xpsr |= T_BIT;
#endif /* CONFIG_COMPILER_ISA_THUMB2 */
#endif /* CONFIG_CPU_CORTEX_M */

	thread->callee_saved.psp = (uint32_t)iframe;
	thread->arch.basepri = 0;
    d110:	2300      	movs	r3, #0
	iframe = Z_STACK_PTR_TO_FRAME(struct __basic_sf, stack_ptr);
    d112:	3a20      	subs	r2, #32
	thread->callee_saved.psp = (uint32_t)iframe;
    d114:	6582      	str	r2, [r0, #88]	; 0x58
	thread->arch.basepri = 0;
    d116:	6783      	str	r3, [r0, #120]	; 0x78
#endif
	/*
	 * initial values in all other registers/thread entries are
	 * irrelevant.
	 */
}
    d118:	4770      	bx	lr
    d11a:	bf00      	nop
    d11c:	0000ef59 	.word	0x0000ef59

0000d120 <arch_switch_to_main_thread>:
#endif
}

void arch_switch_to_main_thread(struct k_thread *main_thread, char *stack_ptr,
				k_thread_entry_t _main)
{
    d120:	4604      	mov	r4, r0
    d122:	b508      	push	{r3, lr}
    d124:	460e      	mov	r6, r1
    d126:	4615      	mov	r5, r2
	z_arm_configure_static_mpu_regions();
    d128:	f000 f9c8 	bl	d4bc <z_arm_configure_static_mpu_regions>
	z_arm_prepare_switch_to_main();

	_current = main_thread;
    d12c:	4b08      	ldr	r3, [pc, #32]	; (d150 <arch_switch_to_main_thread+0x30>)
    d12e:	609c      	str	r4, [r3, #8]
#if (!(defined (__ARM_ARCH_8M_MAIN__ ) && (__ARM_ARCH_8M_MAIN__ == 1)) && \
    (!defined (__ARM_FEATURE_CMSE) || (__ARM_FEATURE_CMSE < 3)))
  // without main extensions, the non-secure PSPLIM is RAZ/WI
  (void)ProcStackPtrLimit;
#else
  __ASM volatile ("MSR psplim, %0" : : "r" (ProcStackPtrLimit));
    d130:	6ea3      	ldr	r3, [r4, #104]	; 0x68
    d132:	f383 880b 	msr	PSPLIM, r3

	/*
	 * Set PSP to the highest address of the main stack
	 * before enabling interrupts and jumping to main.
	 */
	__asm__ volatile (
    d136:	4628      	mov	r0, r5
    d138:	f386 8809 	msr	PSP, r6
    d13c:	2100      	movs	r1, #0
    d13e:	b663      	cpsie	if
    d140:	f381 8811 	msr	BASEPRI, r1
    d144:	f3bf 8f6f 	isb	sy
    d148:	2200      	movs	r2, #0
    d14a:	2300      	movs	r3, #0
    d14c:	f001 ff04 	bl	ef58 <z_thread_entry>
	:
	: "r" (_main), "r" (stack_ptr)
	: "r0" /* not to be overwritten by msr PSP, %1 */
	);

	CODE_UNREACHABLE;
    d150:	20010244 	.word	0x20010244

0000d154 <z_arm_cpu_idle_init>:
 * void z_arm_cpu_idle_init(void);
 */

SECTION_FUNC(TEXT, z_arm_cpu_idle_init)
#if defined(CONFIG_CPU_CORTEX_M)
	ldr	r1, =_SCB_SCR
    d154:	4901      	ldr	r1, [pc, #4]	; (d15c <z_arm_cpu_idle_init+0x8>)
	movs.n	r2, #_SCR_INIT_BITS
    d156:	2210      	movs	r2, #16
	str	r2, [r1]
    d158:	600a      	str	r2, [r1, #0]
#endif
	bx	lr
    d15a:	4770      	bx	lr
	ldr	r1, =_SCB_SCR
    d15c:	e000ed10 	.word	0xe000ed10

0000d160 <arch_cpu_idle>:
	 * before entering low power state.
	 *
	 * Set PRIMASK before configuring BASEPRI to prevent interruption
	 * before wake-up.
	 */
	cpsid	i
    d160:	b672      	cpsid	i

	/*
	 * Set wake-up interrupt priority to the lowest and synchronise to
	 * ensure that this is visible to the WFI instruction.
	 */
	eors.n	r0, r0
    d162:	4040      	eors	r0, r0
	msr	BASEPRI, r0
    d164:	f380 8811 	msr	BASEPRI, r0
	isb
    d168:	f3bf 8f6f 	isb	sy

	/*
	 * Wait for all memory transactions to complete before entering low
	 * power state.
	 */
	dsb
    d16c:	f3bf 8f4f 	dsb	sy

	/* Enter low power state */
	wfi
    d170:	bf30      	wfi

	/*
	 * Clear PRIMASK and flush instruction buffer to immediately service
	 * the wake-up interrupt.
	 */
	cpsie	i
    d172:	b662      	cpsie	i
	isb
    d174:	f3bf 8f6f 	isb	sy

	bx	lr
    d178:	4770      	bx	lr
    d17a:	bf00      	nop

0000d17c <arch_cpu_atomic_idle>:

	/*
	 * Lock PRIMASK while sleeping: wfe will still get interrupted by
	 * incoming interrupts but the CPU will not service them right away.
	 */
	cpsid	i
    d17c:	b672      	cpsid	i
	cpsie	i
_irq_disabled:

#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
	/* r1: zero, for setting BASEPRI (needs a register) */
	eors.n	r1, r1
    d17e:	4049      	eors	r1, r1

	/* unlock BASEPRI so wfe gets interrupted by incoming interrupts */
	msr	BASEPRI, r1
    d180:	f381 8811 	msr	BASEPRI, r1

	wfe
    d184:	bf20      	wfe

	msr	BASEPRI, r0
    d186:	f380 8811 	msr	BASEPRI, r0
	cpsie	i
    d18a:	b662      	cpsie	i
#else
#error Unknown ARM architecture
#endif /* CONFIG_ARMV6_M_ARMV8_M_BASELINE */
	bx	lr
    d18c:	4770      	bx	lr
    d18e:	bf00      	nop

0000d190 <z_SysNmiOnReset>:
_ASM_FILE_PROLOGUE

GTEXT(z_SysNmiOnReset)

SECTION_FUNC(TEXT, z_SysNmiOnReset)
    wfi
    d190:	bf30      	wfi
    b z_SysNmiOnReset
    d192:	f7ff bffd 	b.w	d190 <z_SysNmiOnReset>
    d196:	bf00      	nop

0000d198 <z_arm_prep_c>:
#else
#define VECTOR_ADDRESS CONFIG_SRAM_BASE_ADDRESS
#endif
static inline void relocate_vector_table(void)
{
	SCB->VTOR = VECTOR_ADDRESS & SCB_VTOR_TBLOFF_Msk;
    d198:	4a0e      	ldr	r2, [pc, #56]	; (d1d4 <z_arm_prep_c+0x3c>)
 * This routine prepares for the execution of and runs C code.
 *
 * @return N/A
 */
void z_arm_prep_c(void)
{
    d19a:	b508      	push	{r3, lr}
	SCB->VTOR = VECTOR_ADDRESS & SCB_VTOR_TBLOFF_Msk;
    d19c:	4b0e      	ldr	r3, [pc, #56]	; (d1d8 <z_arm_prep_c+0x40>)
    d19e:	f022 027f 	bic.w	r2, r2, #127	; 0x7f
    d1a2:	609a      	str	r2, [r3, #8]
  \details Acts as a special kind of Data Memory Barrier.
           It completes when all explicit memory accesses before this instruction complete.
 */
__STATIC_FORCEINLINE void __DSB(void)
{
  __ASM volatile ("dsb 0xF":::"memory");
    d1a4:	f3bf 8f4f 	dsb	sy
  __ASM volatile ("isb 0xF":::"memory");
    d1a8:	f3bf 8f6f 	isb	sy
	SCB->CPACR &= (~(CPACR_CP10_Msk | CPACR_CP11_Msk));
    d1ac:	f8d3 2088 	ldr.w	r2, [r3, #136]	; 0x88
    d1b0:	f422 0270 	bic.w	r2, r2, #15728640	; 0xf00000
    d1b4:	f8c3 2088 	str.w	r2, [r3, #136]	; 0x88
  __ASM volatile ("MRS %0, control" : "=r" (result) );
    d1b8:	f3ef 8314 	mrs	r3, CONTROL
	__set_CONTROL(__get_CONTROL() & (~(CONTROL_FPCA_Msk)));
    d1bc:	f023 0304 	bic.w	r3, r3, #4
  __ASM volatile ("MSR control, %0" : : "r" (control) : "memory");
    d1c0:	f383 8814 	msr	CONTROL, r3
	relocate_vector_table();
#if defined(CONFIG_CPU_HAS_FPU)
	z_arm_floating_point_init();
#endif
	z_bss_zero();
    d1c4:	f000 ffb4 	bl	e130 <z_bss_zero>
	z_data_copy();
    d1c8:	f000 ffbc 	bl	e144 <z_data_copy>
#if defined(CONFIG_ARMV7_R) && defined(CONFIG_INIT_STACKS)
	z_arm_init_stacks();
#endif
	z_arm_interrupt_init();
    d1cc:	f000 f93e 	bl	d44c <z_arm_interrupt_init>
	z_cstart();
    d1d0:	f000 fff6 	bl	e1c0 <z_cstart>
    d1d4:	0000c000 	.word	0x0000c000
    d1d8:	e000ed00 	.word	0xe000ed00

0000d1dc <_isr_wrapper>:
 * @return N/A
 */
SECTION_FUNC(TEXT, _isr_wrapper)

#if defined(CONFIG_CPU_CORTEX_M)
	push {r0,lr}		/* r0, lr are now the first items on the stack */
    d1dc:	b501      	push	{r0, lr}
	 * Disable interrupts to prevent nesting while exiting idle state. This
	 * is only necessary for the Cortex-M because it is the only ARM
	 * architecture variant that automatically enables interrupts when
	 * entering an ISR.
	 */
	cpsid i  /* PRIMASK = 1 */
    d1de:	b672      	cpsid	i
#endif

	/* is this a wakeup from idle ? */
	ldr r2, =_kernel
    d1e0:	4a0b      	ldr	r2, [pc, #44]	; (d210 <_isr_wrapper+0x34>)
	/* requested idle duration, in ticks */
	ldr r0, [r2, #_kernel_offset_to_idle]
    d1e2:	6a10      	ldr	r0, [r2, #32]
	cmp r0, #0
    d1e4:	2800      	cmp	r0, #0
	str r1, [r2, #_kernel_offset_to_idle]
	bl z_sys_power_save_idle_exit
_idle_state_cleared:

#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
	ittt ne
    d1e6:	bf1e      	ittt	ne
	movne	r1, #0
    d1e8:	2100      	movne	r1, #0
		/* clear kernel idle state */
		strne	r1, [r2, #_kernel_offset_to_idle]
    d1ea:	6211      	strne	r1, [r2, #32]
		blne	z_sys_power_save_idle_exit
    d1ec:	f002 f9bc 	blne	f568 <z_sys_power_save_idle_exit>
#else
#error Unknown ARM architecture
#endif /* CONFIG_ARMV6_M_ARMV8_M_BASELINE */

#if defined(CONFIG_CPU_CORTEX_M)
	cpsie i		/* re-enable interrupts (PRIMASK = 0) */
    d1f0:	b662      	cpsie	i
#endif

#endif /* CONFIG_SYS_POWER_MANAGEMENT */

#if defined(CONFIG_CPU_CORTEX_M)
	mrs r0, IPSR	/* get exception number */
    d1f2:	f3ef 8005 	mrs	r0, IPSR
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
	ldr r1, =16
	subs r0, r1	/* get IRQ number */
	lsls r0, #3	/* table is 8-byte wide */
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
	sub r0, r0, #16	/* get IRQ number */
    d1f6:	f1a0 0010 	sub.w	r0, r0, #16
	lsl r0, r0, #3	/* table is 8-byte wide */
    d1fa:	ea4f 00c0 	mov.w	r0, r0, lsl #3
	 * interface function.
	 */
	cpsie i
#endif /* !CONFIG_CPU_CORTEX_M */

	ldr r1, =_sw_isr_table
    d1fe:	4905      	ldr	r1, [pc, #20]	; (d214 <_isr_wrapper+0x38>)
	add r1, r1, r0	/* table entry: ISRs must have their MSB set to stay
    d200:	4401      	add	r1, r0
			 * in thumb mode */

	ldm r1!,{r0,r3}	/* arg in r0, ISR in r3 */
    d202:	c909      	ldmia	r1!, {r0, r3}
	blx r3		/* call ISR */
    d204:	4798      	blx	r3

#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
	pop {r0, r3}
	mov lr, r3
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
	pop {r0, lr}
    d206:	e8bd 4001 	ldmia.w	sp!, {r0, lr}
#endif /* CONFIG_ARMV6_M_ARMV8_M_BASELINE */

	/* Use 'bx' instead of 'b' because 'bx' can jump further, and use
	 * 'bx' instead of 'blx' because exception return is done in
	 * z_arm_int_exit() */
	ldr r1, =z_arm_int_exit
    d20a:	4903      	ldr	r1, [pc, #12]	; (d218 <_isr_wrapper+0x3c>)
	bx r1
    d20c:	4708      	bx	r1
    d20e:	0000      	.short	0x0000
	ldr r2, =_kernel
    d210:	20010244 	.word	0x20010244
	ldr r1, =_sw_isr_table
    d214:	0000f7c8 	.word	0x0000f7c8
	ldr r1, =z_arm_int_exit
    d218:	0000d40d 	.word	0x0000d40d

0000d21c <__start>:
 * search for a __start symbol instead, so create that alias here.
 */
SECTION_SUBSEC_FUNC(TEXT,_reset_section,__start)

#if defined(CONFIG_PLATFORM_SPECIFIC_INIT)
    bl z_platform_init
    d21c:	f001 ff83 	bl	f126 <z_platform_init>

    /* lock interrupts: will get unlocked when switch to main task */
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
    cpsid i
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    movs.n r0, #_EXC_IRQ_DEFAULT_PRIO
    d220:	2020      	movs	r0, #32
    msr BASEPRI, r0
    d222:	f380 8811 	msr	BASEPRI, r0

    /*
     * Set PSP and use it to boot without using MSP, so that it
     * gets set to z_interrupt_stacks during initialization.
     */
    ldr r0, =z_interrupt_stacks
    d226:	4808      	ldr	r0, [pc, #32]	; (d248 <__start+0x2c>)
    ldr r1, =CONFIG_ISR_STACK_SIZE + MPU_GUARD_ALIGN_AND_SIZE
    d228:	f44f 6100 	mov.w	r1, #2048	; 0x800
    adds r0, r0, r1
    d22c:	1840      	adds	r0, r0, r1
    msr PSP, r0
    d22e:	f380 8809 	msr	PSP, r0
    mrs r0, CONTROL
    d232:	f3ef 8014 	mrs	r0, CONTROL
    movs r1, #2
    d236:	2102      	movs	r1, #2
    orrs r0, r1 /* CONTROL_SPSEL_Msk */
    d238:	4308      	orrs	r0, r1
    msr CONTROL, r0
    d23a:	f380 8814 	msr	CONTROL, r0
    /*
     * When changing the stack pointer, software must use an ISB instruction
     * immediately after the MSR instruction. This ensures that instructions
     * after the ISB instruction execute using the new stack pointer.
     */
    isb
    d23e:	f3bf 8f6f 	isb	sy
    /*
     * 'bl' jumps the furthest of the branch instructions that are
     * supported on all platforms. So it is used when jumping to z_arm_prep_c
     * (even though we do not intend to return).
     */
    bl z_arm_prep_c
    d242:	f7ff ffa9 	bl	d198 <z_arm_prep_c>
    d246:	0000      	.short	0x0000
    ldr r0, =z_interrupt_stacks
    d248:	200107c8 	.word	0x200107c8

0000d24c <z_arm_bus_fault>:
#else
#error Unknown ARM architecture
#endif /* CONFIG_ARMV6_M_ARMV8_M_BASELINE */
SECTION_SUBSEC_FUNC(TEXT,__fault,z_arm_exc_spurious)

	mrs r0, MSP
    d24c:	f3ef 8008 	mrs	r0, MSP
	mrs r1, PSP
    d250:	f3ef 8109 	mrs	r1, PSP
	push {r0, lr}
    d254:	b501      	push	{r0, lr}
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
	push {r4-r11}
#endif
	mov  r3, sp /* pointer to _callee_saved_t */
#endif /* CONFIG_EXTRA_EXCEPTION_INFO */
	mov r2, lr /* EXC_RETURN */
    d256:	4672      	mov	r2, lr
	bl z_arm_fault
    d258:	f000 f852 	bl	d300 <z_arm_fault>
	 * in this routine. Therefore, we can just reset
	 * the MSP to its value prior to entering the function
	 */
	add sp, #40
#endif
	pop {r0, pc}
    d25c:	bd01      	pop	{r0, pc}
    d25e:	bf00      	nop

0000d260 <mem_manage_fault.isra.0>:
	uint32_t reason = K_ERR_CPU_EXCEPTION;
	uint32_t mmfar = -EINVAL;

	PR_FAULT_INFO("***** MPU FAULT *****");

	if ((SCB->CFSR & SCB_CFSR_MSTKERR_Msk) != 0) {
    d260:	4b0c      	ldr	r3, [pc, #48]	; (d294 <mem_manage_fault.isra.0+0x34>)
    d262:	6a9a      	ldr	r2, [r3, #40]	; 0x28
		PR_FAULT_INFO("  Stacking error (context area might be"
			" not valid)");
	}
	if ((SCB->CFSR & SCB_CFSR_MUNSTKERR_Msk) != 0) {
    d264:	6a9a      	ldr	r2, [r3, #40]	; 0x28
		PR_FAULT_INFO("  Unstacking error");
	}
	if ((SCB->CFSR & SCB_CFSR_DACCVIOL_Msk) != 0) {
    d266:	6a9a      	ldr	r2, [r3, #40]	; 0x28
    d268:	0792      	lsls	r2, r2, #30
    d26a:	d508      	bpl.n	d27e <mem_manage_fault.isra.0+0x1e>
		 * The MMFAR address is valid only if this bit is 1.
		 *
		 * Software must follow this sequence because another higher
		 * priority exception might change the MMFAR value.
		 */
		mmfar = SCB->MMFAR;
    d26c:	6b5a      	ldr	r2, [r3, #52]	; 0x34

		if ((SCB->CFSR & SCB_CFSR_MMARVALID_Msk) != 0) {
    d26e:	6a9a      	ldr	r2, [r3, #40]	; 0x28
    d270:	0612      	lsls	r2, r2, #24
    d272:	d504      	bpl.n	d27e <mem_manage_fault.isra.0+0x1e>
			PR_EXC("  MMFAR Address: 0x%x", mmfar);
			if (from_hard_fault) {
    d274:	b118      	cbz	r0, d27e <mem_manage_fault.isra.0+0x1e>
				/* clear SCB_MMAR[VALID] to reset */
				SCB->CFSR &= ~SCB_CFSR_MMARVALID_Msk;
    d276:	6a9a      	ldr	r2, [r3, #40]	; 0x28
    d278:	f022 0280 	bic.w	r2, r2, #128	; 0x80
    d27c:	629a      	str	r2, [r3, #40]	; 0x28

	/* clear MMFSR sticky bits */
	SCB->CFSR |= SCB_CFSR_MEMFAULTSR_Msk;

	/* Assess whether system shall ignore/recover from this MPU fault. */
	*recoverable = memory_fault_recoverable(esf);
    d27e:	2000      	movs	r0, #0
	if ((SCB->CFSR & SCB_CFSR_IACCVIOL_Msk) != 0) {
    d280:	4b04      	ldr	r3, [pc, #16]	; (d294 <mem_manage_fault.isra.0+0x34>)
    d282:	6a9a      	ldr	r2, [r3, #40]	; 0x28
	if ((SCB->CFSR & SCB_CFSR_MLSPERR_Msk) != 0) {
    d284:	6a9a      	ldr	r2, [r3, #40]	; 0x28
	if (SCB->CFSR & SCB_CFSR_MSTKERR_Msk) {
    d286:	6a9a      	ldr	r2, [r3, #40]	; 0x28
	SCB->CFSR |= SCB_CFSR_MEMFAULTSR_Msk;
    d288:	6a9a      	ldr	r2, [r3, #40]	; 0x28
    d28a:	f042 02ff 	orr.w	r2, r2, #255	; 0xff
    d28e:	629a      	str	r2, [r3, #40]	; 0x28
	*recoverable = memory_fault_recoverable(esf);
    d290:	7008      	strb	r0, [r1, #0]

	return reason;
}
    d292:	4770      	bx	lr
    d294:	e000ed00 	.word	0xe000ed00

0000d298 <bus_fault.isra.0>:
{
	uint32_t reason = K_ERR_CPU_EXCEPTION;

	PR_FAULT_INFO("***** BUS FAULT *****");

	if (SCB->CFSR & SCB_CFSR_STKERR_Msk) {
    d298:	4b0d      	ldr	r3, [pc, #52]	; (d2d0 <bus_fault.isra.0+0x38>)
    d29a:	6a9a      	ldr	r2, [r3, #40]	; 0x28
		PR_FAULT_INFO("  Stacking error");
	}
	if (SCB->CFSR & SCB_CFSR_UNSTKERR_Msk) {
    d29c:	6a9a      	ldr	r2, [r3, #40]	; 0x28
		PR_FAULT_INFO("  Unstacking error");
	}
	if (SCB->CFSR & SCB_CFSR_PRECISERR_Msk) {
    d29e:	6a9a      	ldr	r2, [r3, #40]	; 0x28
    d2a0:	0592      	lsls	r2, r2, #22
    d2a2:	d508      	bpl.n	d2b6 <bus_fault.isra.0+0x1e>
		 * The BFAR address is valid only if this bit is 1.
		 *
		 * Software must follow this sequence because another
		 * higher priority exception might change the BFAR value.
		 */
		STORE_xFAR(bfar, SCB->BFAR);
    d2a4:	6b9a      	ldr	r2, [r3, #56]	; 0x38

		if ((SCB->CFSR & SCB_CFSR_BFARVALID_Msk) != 0) {
    d2a6:	6a9a      	ldr	r2, [r3, #40]	; 0x28
    d2a8:	0412      	lsls	r2, r2, #16
    d2aa:	d504      	bpl.n	d2b6 <bus_fault.isra.0+0x1e>
			PR_EXC("  BFAR Address: 0x%x", bfar);
			if (from_hard_fault) {
    d2ac:	b118      	cbz	r0, d2b6 <bus_fault.isra.0+0x1e>
				/* clear SCB_CFSR_BFAR[VALID] to reset */
				SCB->CFSR &= ~SCB_CFSR_BFARVALID_Msk;
    d2ae:	6a9a      	ldr	r2, [r3, #40]	; 0x28
    d2b0:	f422 4200 	bic.w	r2, r2, #32768	; 0x8000
    d2b4:	629a      	str	r2, [r3, #40]	; 0x28
#endif /* defined(CONFIG_ARM_MPU) && defined(CONFIG_CPU_HAS_NXP_MPU) */

	/* clear BFSR sticky bits */
	SCB->CFSR |= SCB_CFSR_BUSFAULTSR_Msk;

	*recoverable = memory_fault_recoverable(esf);
    d2b6:	2000      	movs	r0, #0
	if (SCB->CFSR & SCB_CFSR_IMPRECISERR_Msk) {
    d2b8:	4b05      	ldr	r3, [pc, #20]	; (d2d0 <bus_fault.isra.0+0x38>)
    d2ba:	6a9a      	ldr	r2, [r3, #40]	; 0x28
	if ((SCB->CFSR & SCB_CFSR_IBUSERR_Msk) != 0) {
    d2bc:	6a9a      	ldr	r2, [r3, #40]	; 0x28
    d2be:	05d2      	lsls	r2, r2, #23
	} else if (SCB->CFSR & SCB_CFSR_LSPERR_Msk) {
    d2c0:	bf58      	it	pl
    d2c2:	6a9a      	ldrpl	r2, [r3, #40]	; 0x28
	SCB->CFSR |= SCB_CFSR_BUSFAULTSR_Msk;
    d2c4:	6a9a      	ldr	r2, [r3, #40]	; 0x28
    d2c6:	f442 427f 	orr.w	r2, r2, #65280	; 0xff00
    d2ca:	629a      	str	r2, [r3, #40]	; 0x28
	*recoverable = memory_fault_recoverable(esf);
    d2cc:	7008      	strb	r0, [r1, #0]

	return reason;
}
    d2ce:	4770      	bx	lr
    d2d0:	e000ed00 	.word	0xe000ed00

0000d2d4 <usage_fault.isra.0>:
	uint32_t reason = K_ERR_CPU_EXCEPTION;

	PR_FAULT_INFO("***** USAGE FAULT *****");

	/* bits are sticky: they stack and must be reset */
	if ((SCB->CFSR & SCB_CFSR_DIVBYZERO_Msk) != 0) {
    d2d4:	4b09      	ldr	r3, [pc, #36]	; (d2fc <usage_fault.isra.0+0x28>)
    d2d6:	6a9a      	ldr	r2, [r3, #40]	; 0x28
		PR_FAULT_INFO("  Division by zero");
	}
	if ((SCB->CFSR & SCB_CFSR_UNALIGNED_Msk) != 0) {
    d2d8:	6a9a      	ldr	r2, [r3, #40]	; 0x28
		PR_FAULT_INFO("  Unaligned memory access");
	}
#if defined(CONFIG_ARMV8_M_MAINLINE)
	if ((SCB->CFSR & SCB_CFSR_STKOF_Msk) != 0) {
    d2da:	6a98      	ldr	r0, [r3, #40]	; 0x28
		 */
		reason = K_ERR_STACK_CHK_FAIL;
#endif /* CONFIG_BUILTIN_STACK_GUARD */
	}
#endif /* CONFIG_ARMV8_M_MAINLINE */
	if ((SCB->CFSR & SCB_CFSR_NOCP_Msk) != 0) {
    d2dc:	6a9a      	ldr	r2, [r3, #40]	; 0x28
		PR_FAULT_INFO("  No coprocessor instructions");
	}
	if ((SCB->CFSR & SCB_CFSR_INVPC_Msk) != 0) {
    d2de:	6a9a      	ldr	r2, [r3, #40]	; 0x28
		PR_FAULT_INFO("  Illegal load of EXC_RETURN into PC");
	}
	if ((SCB->CFSR & SCB_CFSR_INVSTATE_Msk) != 0) {
    d2e0:	6a9a      	ldr	r2, [r3, #40]	; 0x28
		PR_FAULT_INFO("  Illegal use of the EPSR");
	}
	if ((SCB->CFSR & SCB_CFSR_UNDEFINSTR_Msk) != 0) {
    d2e2:	6a9a      	ldr	r2, [r3, #40]	; 0x28
		PR_FAULT_INFO("  Attempt to execute undefined instruction");
	}

	/* clear UFSR sticky bits */
	SCB->CFSR |= SCB_CFSR_USGFAULTSR_Msk;
    d2e4:	6a9a      	ldr	r2, [r3, #40]	; 0x28
	if ((SCB->CFSR & SCB_CFSR_STKOF_Msk) != 0) {
    d2e6:	f410 1080 	ands.w	r0, r0, #1048576	; 0x100000
	SCB->CFSR |= SCB_CFSR_USGFAULTSR_Msk;
    d2ea:	ea6f 4202 	mvn.w	r2, r2, lsl #16
    d2ee:	ea6f 4212 	mvn.w	r2, r2, lsr #16

	return reason;
}
    d2f2:	bf18      	it	ne
    d2f4:	2002      	movne	r0, #2
	SCB->CFSR |= SCB_CFSR_USGFAULTSR_Msk;
    d2f6:	629a      	str	r2, [r3, #40]	; 0x28
}
    d2f8:	4770      	bx	lr
    d2fa:	bf00      	nop
    d2fc:	e000ed00 	.word	0xe000ed00

0000d300 <z_arm_fault>:
 * @param callee_regs Callee-saved registers (R4-R11, PSP)
 *
 */
void z_arm_fault(uint32_t msp, uint32_t psp, uint32_t exc_return,
	_callee_saved_t *callee_regs)
{
    d300:	b570      	push	{r4, r5, r6, lr}
	uint32_t reason = K_ERR_CPU_EXCEPTION;
	int fault = SCB->ICSR & SCB_ICSR_VECTACTIVE_Msk;
    d302:	4b39      	ldr	r3, [pc, #228]	; (d3e8 <z_arm_fault+0xe8>)
{
    d304:	4606      	mov	r6, r0
	int fault = SCB->ICSR & SCB_ICSR_VECTACTIVE_Msk;
    d306:	685b      	ldr	r3, [r3, #4]
    d308:	2500      	movs	r5, #0
{
    d30a:	b08a      	sub	sp, #40	; 0x28
	int fault = SCB->ICSR & SCB_ICSR_VECTACTIVE_Msk;
    d30c:	f3c3 0308 	ubfx	r3, r3, #0, #9
    d310:	f385 8811 	msr	BASEPRI, r5
    d314:	f3bf 8f6f 	isb	sy
	if ((exc_return & EXC_RETURN_INDICATOR_PREFIX) !=
    d318:	f002 407f 	and.w	r0, r2, #4278190080	; 0xff000000
    d31c:	f1b0 4f7f 	cmp.w	r0, #4278190080	; 0xff000000
    d320:	d116      	bne.n	d350 <z_arm_fault+0x50>
	if (exc_return & EXC_RETURN_EXCEPTION_SECURE_Secure) {
    d322:	07d0      	lsls	r0, r2, #31
    d324:	d414      	bmi.n	d350 <z_arm_fault+0x50>
	if (exc_return & EXC_RETURN_RETURN_STACK_Secure) {
    d326:	0654      	lsls	r4, r2, #25
    d328:	d403      	bmi.n	d332 <z_arm_fault+0x32>
		if (exc_return & EXC_RETURN_MODE_THREAD) {
    d32a:	0710      	lsls	r0, r2, #28
    d32c:	d404      	bmi.n	d338 <z_arm_fault+0x38>
			*nested_exc = true;
    d32e:	2501      	movs	r5, #1
    d330:	e004      	b.n	d33c <z_arm_fault+0x3c>
		if (exc_return & EXC_RETURN_SPSEL_PROCESS) {
    d332:	f012 0504 	ands.w	r5, r2, #4
    d336:	d001      	beq.n	d33c <z_arm_fault+0x3c>
			ptr_esf = (z_arch_esf_t *)psp;
    d338:	460e      	mov	r6, r1
	*nested_exc = false;
    d33a:	2500      	movs	r5, #0
	*recoverable = false;
    d33c:	2200      	movs	r2, #0
    d33e:	3b03      	subs	r3, #3
    d340:	f88d 2007 	strb.w	r2, [sp, #7]
	switch (fault) {
    d344:	2b03      	cmp	r3, #3
    d346:	d847      	bhi.n	d3d8 <z_arm_fault+0xd8>
    d348:	e8df f003 	tbb	[pc, r3]
    d34c:	3b423e04 	.word	0x3b423e04
		return NULL;
    d350:	462e      	mov	r6, r5
    d352:	e7f3      	b.n	d33c <z_arm_fault+0x3c>
	if ((SCB->HFSR & SCB_HFSR_VECTTBL_Msk) != 0) {
    d354:	4b24      	ldr	r3, [pc, #144]	; (d3e8 <z_arm_fault+0xe8>)
    d356:	6ada      	ldr	r2, [r3, #44]	; 0x2c
    d358:	0792      	lsls	r2, r2, #30
    d35a:	d43d      	bmi.n	d3d8 <z_arm_fault+0xd8>
	} else if ((SCB->HFSR & SCB_HFSR_FORCED_Msk) != 0) {
    d35c:	6adc      	ldr	r4, [r3, #44]	; 0x2c
    d35e:	f014 4480 	ands.w	r4, r4, #1073741824	; 0x40000000
    d362:	d008      	beq.n	d376 <z_arm_fault+0x76>
		if (SCB_MMFSR != 0) {
    d364:	3328      	adds	r3, #40	; 0x28
    d366:	781b      	ldrb	r3, [r3, #0]
    d368:	b1eb      	cbz	r3, d3a6 <z_arm_fault+0xa6>
			reason = mem_manage_fault(esf, 1, recoverable);
    d36a:	2001      	movs	r0, #1
    d36c:	f10d 0107 	add.w	r1, sp, #7
		reason = mem_manage_fault(esf, 0, recoverable);
    d370:	f7ff ff76 	bl	d260 <mem_manage_fault.isra.0>
		reason = usage_fault(esf);
    d374:	4604      	mov	r4, r0
#ifdef CONFIG_DEBUG_COREDUMP
	z_arm_coredump_fault_sp = POINTER_TO_UINT(esf);
#endif

	reason = fault_handle(esf, fault, &recoverable);
	if (recoverable) {
    d376:	f89d 3007 	ldrb.w	r3, [sp, #7]
    d37a:	b993      	cbnz	r3, d3a2 <z_arm_fault+0xa2>
		return;
	}

	/* Copy ESF */
#if !defined(CONFIG_EXTRA_EXCEPTION_INFO)
	memcpy(&esf_copy, esf, sizeof(z_arch_esf_t));
    d37c:	2220      	movs	r2, #32
    d37e:	4631      	mov	r1, r6
    d380:	a802      	add	r0, sp, #8
    d382:	f001 ffc5 	bl	f310 <memcpy>
	/* Overwrite stacked IPSR to mark a nested exception,
	 * or a return to Thread mode. Note that this may be
	 * required, if the retrieved ESF contents are invalid
	 * due to, for instance, a stacking error.
	 */
	if (nested_exc) {
    d386:	9b09      	ldr	r3, [sp, #36]	; 0x24
    d388:	b345      	cbz	r5, d3dc <z_arm_fault+0xdc>
		if ((esf_copy.basic.xpsr & IPSR_ISR_Msk) == 0) {
    d38a:	f3c3 0208 	ubfx	r2, r3, #0, #9
    d38e:	b922      	cbnz	r2, d39a <z_arm_fault+0x9a>
			esf_copy.basic.xpsr |= IPSR_ISR_Msk;
    d390:	ea6f 2353 	mvn.w	r3, r3, lsr #9
    d394:	ea6f 2343 	mvn.w	r3, r3, lsl #9
		}
	} else {
		esf_copy.basic.xpsr &= ~(IPSR_ISR_Msk);
    d398:	9309      	str	r3, [sp, #36]	; 0x24
	}

	z_arm_fatal_error(reason, &esf_copy);
    d39a:	4620      	mov	r0, r4
    d39c:	a902      	add	r1, sp, #8
    d39e:	f001 ff65 	bl	f26c <z_arm_fatal_error>
}
    d3a2:	b00a      	add	sp, #40	; 0x28
    d3a4:	bd70      	pop	{r4, r5, r6, pc}
		} else if (SCB_BFSR != 0) {
    d3a6:	4b11      	ldr	r3, [pc, #68]	; (d3ec <z_arm_fault+0xec>)
    d3a8:	781b      	ldrb	r3, [r3, #0]
    d3aa:	b12b      	cbz	r3, d3b8 <z_arm_fault+0xb8>
			reason = bus_fault(esf, 1, recoverable);
    d3ac:	2001      	movs	r0, #1
    d3ae:	f10d 0107 	add.w	r1, sp, #7
		reason = bus_fault(esf, 0, recoverable);
    d3b2:	f7ff ff71 	bl	d298 <bus_fault.isra.0>
    d3b6:	e7dd      	b.n	d374 <z_arm_fault+0x74>
		} else if (SCB_UFSR != 0) {
    d3b8:	4b0d      	ldr	r3, [pc, #52]	; (d3f0 <z_arm_fault+0xf0>)
    d3ba:	8818      	ldrh	r0, [r3, #0]
    d3bc:	b284      	uxth	r4, r0
    d3be:	2c00      	cmp	r4, #0
    d3c0:	d0d9      	beq.n	d376 <z_arm_fault+0x76>
		reason = usage_fault(esf);
    d3c2:	f7ff ff87 	bl	d2d4 <usage_fault.isra.0>
    d3c6:	e7d5      	b.n	d374 <z_arm_fault+0x74>
		reason = mem_manage_fault(esf, 0, recoverable);
    d3c8:	2000      	movs	r0, #0
    d3ca:	f10d 0107 	add.w	r1, sp, #7
    d3ce:	e7cf      	b.n	d370 <z_arm_fault+0x70>
		reason = bus_fault(esf, 0, recoverable);
    d3d0:	2000      	movs	r0, #0
    d3d2:	f10d 0107 	add.w	r1, sp, #7
    d3d6:	e7ec      	b.n	d3b2 <z_arm_fault+0xb2>
	uint32_t reason = K_ERR_CPU_EXCEPTION;
    d3d8:	2400      	movs	r4, #0
    d3da:	e7cc      	b.n	d376 <z_arm_fault+0x76>
		esf_copy.basic.xpsr &= ~(IPSR_ISR_Msk);
    d3dc:	f423 73ff 	bic.w	r3, r3, #510	; 0x1fe
    d3e0:	f023 0301 	bic.w	r3, r3, #1
    d3e4:	e7d8      	b.n	d398 <z_arm_fault+0x98>
    d3e6:	bf00      	nop
    d3e8:	e000ed00 	.word	0xe000ed00
    d3ec:	e000ed29 	.word	0xe000ed29
    d3f0:	e000ed2a 	.word	0xe000ed2a

0000d3f4 <z_arm_fault_init>:
 */
void z_arm_fault_init(void)
{
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
	SCB->CCR |= SCB_CCR_DIV_0_TRP_Msk;
    d3f4:	4b04      	ldr	r3, [pc, #16]	; (d408 <z_arm_fault_init+0x14>)
    d3f6:	695a      	ldr	r2, [r3, #20]
    d3f8:	f042 0210 	orr.w	r2, r2, #16
    d3fc:	615a      	str	r2, [r3, #20]
	 *
	 * For Non-Secure Firmware this could allow the Non-Secure Main
	 * Stack to attempt to descend into secure region, in which case a
	 * Secure Hard Fault will occur and we can track the fault from there.
	 */
	SCB->CCR |= SCB_CCR_STKOFHFNMIGN_Msk;
    d3fe:	695a      	ldr	r2, [r3, #20]
    d400:	f442 6280 	orr.w	r2, r2, #1024	; 0x400
    d404:	615a      	str	r2, [r3, #20]
#endif /* CONFIG_BUILTIN_STACK_GUARD */
}
    d406:	4770      	bx	lr
    d408:	e000ed00 	.word	0xe000ed00

0000d40c <z_arm_exc_exit>:
 */

SECTION_SUBSEC_FUNC(TEXT, _HandlerModeExit, z_arm_exc_exit)

#ifdef CONFIG_PREEMPT_ENABLED
	ldr r3, =_kernel
    d40c:	4b04      	ldr	r3, [pc, #16]	; (d420 <_EXIT_EXC+0x2>)

	ldr r1, [r3, #_kernel_offset_to_current]
    d40e:	6899      	ldr	r1, [r3, #8]
	ldr r0, [r3, #_kernel_offset_to_ready_q_cache]
    d410:	6a58      	ldr	r0, [r3, #36]	; 0x24
	cmp r0, r1
    d412:	4288      	cmp	r0, r1
	beq _EXIT_EXC
    d414:	d003      	beq.n	d41e <_EXIT_EXC>

	/* context switch required, pend the PendSV exception */
	ldr r1, =_SCS_ICSR
    d416:	4903      	ldr	r1, [pc, #12]	; (d424 <_EXIT_EXC+0x6>)
	ldr r2, =_SCS_ICSR_PENDSV
    d418:	f04f 5280 	mov.w	r2, #268435456	; 0x10000000
	str r2, [r1]
    d41c:	600a      	str	r2, [r1, #0]

0000d41e <_EXIT_EXC>:
#else
	pop {r0, lr}
#endif /* CONFIG_ARMV6_M_ARMV8_M_BASELINE */
#endif /* CONFIG_STACK_SENTINEL */

	bx lr
    d41e:	4770      	bx	lr
	ldr r3, =_kernel
    d420:	20010244 	.word	0x20010244
	ldr r1, =_SCS_ICSR
    d424:	e000ed04 	.word	0xe000ed04

0000d428 <sys_arch_reboot>:
  __ASM volatile ("dsb 0xF":::"memory");
    d428:	f3bf 8f4f 	dsb	sy
__NO_RETURN __STATIC_INLINE void __NVIC_SystemReset(void)
{
  __DSB();                                                          /* Ensure all outstanding memory accesses included
                                                                       buffered write are completed before reset */
  SCB->AIRCR  = (uint32_t)((0x5FAUL << SCB_AIRCR_VECTKEY_Pos)    |
                           (SCB->AIRCR & SCB_AIRCR_PRIGROUP_Msk) |
    d42c:	4905      	ldr	r1, [pc, #20]	; (d444 <sys_arch_reboot+0x1c>)
    d42e:	4b06      	ldr	r3, [pc, #24]	; (d448 <sys_arch_reboot+0x20>)
    d430:	68ca      	ldr	r2, [r1, #12]
    d432:	f402 62e0 	and.w	r2, r2, #1792	; 0x700
    d436:	4313      	orrs	r3, r2
  SCB->AIRCR  = (uint32_t)((0x5FAUL << SCB_AIRCR_VECTKEY_Pos)    |
    d438:	60cb      	str	r3, [r1, #12]
    d43a:	f3bf 8f4f 	dsb	sy
                            SCB_AIRCR_SYSRESETREQ_Msk    );         /* Keep priority group unchanged */
  __DSB();                                                          /* Ensure completion of memory access */

  for(;;)                                                           /* wait until reset */
  {
    __NOP();
    d43e:	bf00      	nop
  for(;;)                                                           /* wait until reset */
    d440:	e7fd      	b.n	d43e <sys_arch_reboot+0x16>
    d442:	bf00      	nop
    d444:	e000ed00 	.word	0xe000ed00
    d448:	05fa0004 	.word	0x05fa0004

0000d44c <z_arm_interrupt_init>:
 * @return N/A
 */

void z_arm_interrupt_init(void)
{
	int irq = 0;
    d44c:	2300      	movs	r3, #0
    NVIC->IPR[((uint32_t)IRQn)]               = (uint8_t)((priority << (8U - __NVIC_PRIO_BITS)) & (uint32_t)0xFFUL);
    d44e:	2120      	movs	r1, #32
    d450:	4803      	ldr	r0, [pc, #12]	; (d460 <z_arm_interrupt_init+0x14>)
    d452:	18c2      	adds	r2, r0, r3

	for (; irq < CONFIG_NUM_IRQS; irq++) {
    d454:	3301      	adds	r3, #1
    d456:	2b41      	cmp	r3, #65	; 0x41
    d458:	f882 1300 	strb.w	r1, [r2, #768]	; 0x300
    d45c:	d1f9      	bne.n	d452 <z_arm_interrupt_init+0x6>
		NVIC_SetPriority((IRQn_Type)irq, _IRQ_PRIO_OFFSET);
	}
}
    d45e:	4770      	bx	lr
    d460:	e000e100 	.word	0xe000e100

0000d464 <z_impl_k_thread_abort>:
#include <kswap.h>
#include <wait_q.h>
#include <sys/__assert.h>

void z_impl_k_thread_abort(k_tid_t thread)
{
    d464:	b510      	push	{r4, lr}
    d466:	4604      	mov	r4, r0
	z_thread_single_abort(thread);
    d468:	f001 f8ea 	bl	e640 <z_thread_single_abort>

	if (_current == thread) {
    d46c:	4b11      	ldr	r3, [pc, #68]	; (d4b4 <z_impl_k_thread_abort+0x50>)
    d46e:	689b      	ldr	r3, [r3, #8]
    d470:	42a3      	cmp	r3, r4
    d472:	d107      	bne.n	d484 <z_impl_k_thread_abort+0x20>
  __ASM volatile ("MRS %0, ipsr" : "=r" (result) );
    d474:	f3ef 8305 	mrs	r3, IPSR
		if (arch_is_in_isr()) {
    d478:	b183      	cbz	r3, d49c <z_impl_k_thread_abort+0x38>
			 * should no longer run after we return, so
			 * Trigger PendSV, in case we are in one of the
			 * situations where the isr check is true but there
			 * is not an implicit scheduler invocation.
			 */
			SCB->ICSR |= SCB_ICSR_PENDSVSET_Msk;
    d47a:	4a0f      	ldr	r2, [pc, #60]	; (d4b8 <z_impl_k_thread_abort+0x54>)
    d47c:	6853      	ldr	r3, [r2, #4]
    d47e:	f043 5380 	orr.w	r3, r3, #268435456	; 0x10000000
    d482:	6053      	str	r3, [r2, #4]
	__asm__ volatile(
    d484:	f04f 0320 	mov.w	r3, #32
    d488:	f3ef 8011 	mrs	r0, BASEPRI
    d48c:	f383 8811 	msr	BASEPRI, r3
    d490:	f3bf 8f6f 	isb	sy
		}
	}

	/* The abort handler might have altered the ready queue. */
	z_reschedule_unlocked();
}
    d494:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
	(void) z_pend_curr_irqlock(arch_irq_lock(), wait_q, timeout);
}

static inline void z_reschedule_unlocked(void)
{
	(void) z_reschedule_irqlock(arch_irq_lock());
    d498:	f002 b868 	b.w	f56c <z_reschedule_irqlock>
    d49c:	f04f 0320 	mov.w	r3, #32
    d4a0:	f3ef 8011 	mrs	r0, BASEPRI
    d4a4:	f383 8811 	msr	BASEPRI, r3
    d4a8:	f3bf 8f6f 	isb	sy

static inline int z_swap_irqlock(unsigned int key)
{
	int ret;
	z_check_stack_sentinel();
	ret = arch_swap(key);
    d4ac:	f7ff fd92 	bl	cfd4 <arch_swap>
	return ret;
    d4b0:	e7e8      	b.n	d484 <z_impl_k_thread_abort+0x20>
    d4b2:	bf00      	nop
    d4b4:	20010244 	.word	0x20010244
    d4b8:	e000ed00 	.word	0xe000ed00

0000d4bc <z_arm_configure_static_mpu_regions>:
 *
 * For some MPU architectures, such as the unmodified ARMv8-M MPU,
 * the function must execute with MPU enabled.
 */
void z_arm_configure_static_mpu_regions(void)
{
    d4bc:	b510      	push	{r4, lr}
		.size = (uint32_t)&_nocache_ram_size,
		.attr = K_MEM_PARTITION_P_RW_U_NA_NOCACHE,
		};
#endif /* CONFIG_NOCACHE_MEMORY */
#if defined(CONFIG_ARCH_HAS_RAMFUNC_SUPPORT)
		const struct k_mem_partition ramfunc_region =
    d4be:	4b0e      	ldr	r3, [pc, #56]	; (d4f8 <z_arm_configure_static_mpu_regions+0x3c>)
{
    d4c0:	b088      	sub	sp, #32
		const struct k_mem_partition ramfunc_region =
    d4c2:	9302      	str	r3, [sp, #8]
    d4c4:	4b0d      	ldr	r3, [pc, #52]	; (d4fc <z_arm_configure_static_mpu_regions+0x40>)
	/* Configure the static MPU regions within firmware SRAM boundaries.
	 * Start address of the image is given by _image_ram_start. The end
	 * of the firmware SRAM area is marked by __kernel_ram_end, taking
	 * into account the unused SRAM area, as well.
	 */
	arm_core_mpu_configure_static_mpu_regions(static_regions,
    d4c6:	4c0e      	ldr	r4, [pc, #56]	; (d500 <z_arm_configure_static_mpu_regions+0x44>)
		const struct k_mem_partition ramfunc_region =
    d4c8:	9303      	str	r3, [sp, #12]
    d4ca:	4b0e      	ldr	r3, [pc, #56]	; (d504 <z_arm_configure_static_mpu_regions+0x48>)
	arm_core_mpu_configure_static_mpu_regions(static_regions,
    d4cc:	4a0e      	ldr	r2, [pc, #56]	; (d508 <z_arm_configure_static_mpu_regions+0x4c>)
		const struct k_mem_partition ramfunc_region =
    d4ce:	9304      	str	r3, [sp, #16]
	const struct k_mem_partition *static_regions[] = {
    d4d0:	ab02      	add	r3, sp, #8
    d4d2:	9301      	str	r3, [sp, #4]
	arm_core_mpu_configure_static_mpu_regions(static_regions,
    d4d4:	a801      	add	r0, sp, #4
    d4d6:	4623      	mov	r3, r4
    d4d8:	2101      	movs	r1, #1
    d4da:	f000 f907 	bl	d6ec <arm_core_mpu_configure_static_mpu_regions>
	/* Define a constant array of k_mem_partition objects that holds the
	 * boundaries of the areas, inside which dynamic region programming
	 * is allowed. The information is passed to the underlying driver at
	 * initialization.
	 */
	const struct k_mem_partition dyn_region_areas[] = {
    d4de:	2300      	movs	r3, #0
    d4e0:	9307      	str	r3, [sp, #28]
		{
		.start = _MPU_DYNAMIC_REGIONS_AREA_START,
    d4e2:	4b0a      	ldr	r3, [pc, #40]	; (d50c <z_arm_configure_static_mpu_regions+0x50>)
		.size =  _MPU_DYNAMIC_REGIONS_AREA_SIZE,
		}
	};

	arm_core_mpu_mark_areas_for_dynamic_regions(dyn_region_areas,
    d4e4:	2101      	movs	r1, #1
		.size =  _MPU_DYNAMIC_REGIONS_AREA_SIZE,
    d4e6:	1ae4      	subs	r4, r4, r3
	arm_core_mpu_mark_areas_for_dynamic_regions(dyn_region_areas,
    d4e8:	a805      	add	r0, sp, #20
	const struct k_mem_partition dyn_region_areas[] = {
    d4ea:	9305      	str	r3, [sp, #20]
    d4ec:	9406      	str	r4, [sp, #24]
	arm_core_mpu_mark_areas_for_dynamic_regions(dyn_region_areas,
    d4ee:	f000 f907 	bl	d700 <arm_core_mpu_mark_areas_for_dynamic_regions>
		ARRAY_SIZE(dyn_region_areas));
#endif /* CONFIG_MPU_REQUIRES_NON_OVERLAPPING_REGIONS */
}
    d4f2:	b008      	add	sp, #32
    d4f4:	bd10      	pop	{r4, pc}
    d4f6:	bf00      	nop
    d4f8:	20010000 	.word	0x20010000
    d4fc:	00000000 	.word	0x00000000
    d500:	20040000 	.word	0x20040000
    d504:	00010006 	.word	0x00010006
    d508:	20010000 	.word	0x20010000
    d50c:	20010090 	.word	0x20010090

0000d510 <region_init>:
 * Note:
 *   The caller must provide a valid region index.
 */
static void region_init(const uint32_t index,
	const struct arm_mpu_region *region_conf)
{
    d510:	b510      	push	{r4, lr}
	ARM_MPU_SetRegion(
		/* RNR */
		index,
		/* RBAR */
		(region_conf->base & MPU_RBAR_BASE_Msk)
    d512:	680b      	ldr	r3, [r1, #0]
		| (region_conf->attr.rbar &
    d514:	7a0c      	ldrb	r4, [r1, #8]
		(region_conf->base & MPU_RBAR_BASE_Msk)
    d516:	f023 021f 	bic.w	r2, r3, #31
		| (region_conf->attr.rbar &
    d51a:	f004 031f 	and.w	r3, r4, #31
    d51e:	431a      	orrs	r2, r3
			(MPU_RBAR_XN_Msk | MPU_RBAR_AP_Msk | MPU_RBAR_SH_Msk)),
		/* RLAR */
		(region_conf->attr.r_limit & MPU_RLAR_LIMIT_Msk)
    d520:	68cb      	ldr	r3, [r1, #12]
		| ((region_conf->attr.mair_idx << MPU_RLAR_AttrIndx_Pos)
    d522:	0964      	lsrs	r4, r4, #5
		(region_conf->attr.r_limit & MPU_RLAR_LIMIT_Msk)
    d524:	f023 031f 	bic.w	r3, r3, #31
* \param rbar Value for RBAR register.
* \param rlar Value for RLAR register.
*/   
__STATIC_INLINE void ARM_MPU_SetRegionEx(MPU_Type* mpu, uint32_t rnr, uint32_t rbar, uint32_t rlar)
{
  mpu->RNR = rnr;
    d528:	4904      	ldr	r1, [pc, #16]	; (d53c <region_init+0x2c>)
		| ((region_conf->attr.mair_idx << MPU_RLAR_AttrIndx_Pos)
    d52a:	ea43 0344 	orr.w	r3, r3, r4, lsl #1
			& MPU_RLAR_AttrIndx_Msk)
		| MPU_RLAR_EN_Msk
    d52e:	f043 0301 	orr.w	r3, r3, #1
    d532:	6088      	str	r0, [r1, #8]
  mpu->RBAR = rbar;
    d534:	60ca      	str	r2, [r1, #12]
  mpu->RLAR = rlar;
    d536:	610b      	str	r3, [r1, #16]
	);

	LOG_DBG("[%d] 0x%08x 0x%08x 0x%08x 0x%08x",
			index, region_conf->base, region_conf->attr.rbar,
			region_conf->attr.mair_idx, region_conf->attr.r_limit);
}
    d538:	bd10      	pop	{r4, pc}
    d53a:	bf00      	nop
    d53c:	e000ed90 	.word	0xe000ed90

0000d540 <mpu_configure_regions_and_partition.constprop.0>:
 * sanity check of the memory regions to be programmed.
 *
 * The function performs a full partition of the background memory
 * area, effectively, leaving no space in this area uncovered by MPU.
 */
static int mpu_configure_regions_and_partition(const struct k_mem_partition
    d540:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
    d544:	4607      	mov	r7, r0
    d546:	4688      	mov	r8, r1
    d548:	4614      	mov	r4, r2
	bool do_sanity_check)
{
	int i;
	int reg_index = start_reg_index;

	for (i = 0; i < regions_num; i++) {
    d54a:	2600      	movs	r6, #0
	MPU->RNR = index;
    d54c:	4d4a      	ldr	r5, [pc, #296]	; (d678 <mpu_configure_regions_and_partition.constprop.0+0x138>)
static int mpu_configure_regions_and_partition(const struct k_mem_partition
    d54e:	b085      	sub	sp, #20
	for (i = 0; i < regions_num; i++) {
    d550:	4546      	cmp	r6, r8
    d552:	da0b      	bge.n	d56c <mpu_configure_regions_and_partition.constprop.0+0x2c>
		if (regions[i]->size == 0U) {
    d554:	f857 3026 	ldr.w	r3, [r7, r6, lsl #2]
    d558:	f8d3 9004 	ldr.w	r9, [r3, #4]
    d55c:	f1b9 0f00 	cmp.w	r9, #0
    d560:	d03a      	beq.n	d5d8 <mpu_configure_regions_and_partition.constprop.0+0x98>
		&&
    d562:	f1b9 0f1f 	cmp.w	r9, #31
    d566:	d805      	bhi.n	d574 <mpu_configure_regions_and_partition.constprop.0+0x34>

			reg_index =
				mpu_configure_region(reg_index, regions[i]);

			if (reg_index == -EINVAL) {
				return reg_index;
    d568:	f06f 0415 	mvn.w	r4, #21
			reg_index++;
		}
	}

	return reg_index;
}
    d56c:	4620      	mov	r0, r4
    d56e:	b005      	add	sp, #20
    d570:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
		&&
    d574:	f019 0f1f 	tst.w	r9, #31
    d578:	d1f6      	bne.n	d568 <mpu_configure_regions_and_partition.constprop.0+0x28>
		((part->start &
    d57a:	f8d3 a000 	ldr.w	sl, [r3]
		&&
    d57e:	f01a 0f1f 	tst.w	sl, #31
    d582:	d1f1      	bne.n	d568 <mpu_configure_regions_and_partition.constprop.0+0x28>
	uint32_t region_start_addr = arm_cmse_mpu_region_get(start);
    d584:	4650      	mov	r0, sl
    d586:	f001 fe9e 	bl	f2c6 <arm_cmse_mpu_region_get>
    d58a:	4683      	mov	fp, r0
	uint32_t region_end_addr = arm_cmse_mpu_region_get(start + size - 1);
    d58c:	eb09 000a 	add.w	r0, r9, sl
    d590:	3801      	subs	r0, #1
    d592:	f001 fe98 	bl	f2c6 <arm_cmse_mpu_region_get>
	if (region_start_addr == region_end_addr) {
    d596:	4583      	cmp	fp, r0
    d598:	d1e6      	bne.n	d568 <mpu_configure_regions_and_partition.constprop.0+0x28>
		if ((u_reg_index == -EINVAL) ||
    d59a:	f11b 0f16 	cmn.w	fp, #22
    d59e:	d0e3      	beq.n	d568 <mpu_configure_regions_and_partition.constprop.0+0x28>
			(u_reg_index > (reg_index - 1))) {
    d5a0:	1e63      	subs	r3, r4, #1
		if ((u_reg_index == -EINVAL) ||
    d5a2:	455b      	cmp	r3, fp
    d5a4:	dbe0      	blt.n	d568 <mpu_configure_regions_and_partition.constprop.0+0x28>
	MPU->RNR = index;
    d5a6:	f8c5 b008 	str.w	fp, [r5, #8]
	return MPU->RBAR & MPU_RBAR_BASE_Msk;
    d5aa:	68e8      	ldr	r0, [r5, #12]
	MPU->RNR = index;
    d5ac:	f8c5 b008 	str.w	fp, [r5, #8]
	return (MPU->RLAR & MPU_RLAR_LIMIT_Msk) | (~MPU_RLAR_LIMIT_Msk);
    d5b0:	692b      	ldr	r3, [r5, #16]
		uint32_t reg_last = regions[i]->start + regions[i]->size - 1;
    d5b2:	f857 1026 	ldr.w	r1, [r7, r6, lsl #2]
	return MPU->RBAR & MPU_RBAR_BASE_Msk;
    d5b6:	f020 001f 	bic.w	r0, r0, #31
	return (MPU->RLAR & MPU_RLAR_LIMIT_Msk) | (~MPU_RLAR_LIMIT_Msk);
    d5ba:	f043 0a1f 	orr.w	sl, r3, #31
		uint32_t reg_last = regions[i]->start + regions[i]->size - 1;
    d5be:	e9d1 3200 	ldrd	r3, r2, [r1]
    d5c2:	441a      	add	r2, r3
		if ((regions[i]->start == u_reg_base) &&
    d5c4:	4298      	cmp	r0, r3
		uint32_t reg_last = regions[i]->start + regions[i]->size - 1;
    d5c6:	f102 39ff 	add.w	r9, r2, #4294967295
		if ((regions[i]->start == u_reg_base) &&
    d5ca:	d118      	bne.n	d5fe <mpu_configure_regions_and_partition.constprop.0+0xbe>
    d5cc:	45ca      	cmp	sl, r9
    d5ce:	d105      	bne.n	d5dc <mpu_configure_regions_and_partition.constprop.0+0x9c>
			mpu_configure_region(u_reg_index, regions[i]);
    d5d0:	fa5f f08b 	uxtb.w	r0, fp
    d5d4:	f001 fe57 	bl	f286 <mpu_configure_region>
	for (i = 0; i < regions_num; i++) {
    d5d8:	3601      	adds	r6, #1
    d5da:	e7b9      	b.n	d550 <mpu_configure_regions_and_partition.constprop.0+0x10>
	MPU->RNR = index;
    d5dc:	f8c5 b008 	str.w	fp, [r5, #8]
	MPU->RBAR = (MPU->RBAR & (~MPU_RBAR_BASE_Msk))
    d5e0:	68eb      	ldr	r3, [r5, #12]
		| (base & MPU_RBAR_BASE_Msk);
    d5e2:	f022 021f 	bic.w	r2, r2, #31
	MPU->RBAR = (MPU->RBAR & (~MPU_RBAR_BASE_Msk))
    d5e6:	f003 031f 	and.w	r3, r3, #31
		| (base & MPU_RBAR_BASE_Msk);
    d5ea:	431a      	orrs	r2, r3
	MPU->RBAR = (MPU->RBAR & (~MPU_RBAR_BASE_Msk))
    d5ec:	60ea      	str	r2, [r5, #12]
				mpu_configure_region(reg_index, regions[i]);
    d5ee:	b2e0      	uxtb	r0, r4
				mpu_configure_region(reg_index, regions[i]);
    d5f0:	f001 fe49 	bl	f286 <mpu_configure_region>
			if (reg_index == -EINVAL) {
    d5f4:	f110 0f16 	cmn.w	r0, #22
    d5f8:	d0b6      	beq.n	d568 <mpu_configure_regions_and_partition.constprop.0+0x28>
			reg_index++;
    d5fa:	1c44      	adds	r4, r0, #1
    d5fc:	e7ec      	b.n	d5d8 <mpu_configure_regions_and_partition.constprop.0+0x98>
	MPU->RNR = index;
    d5fe:	f8c5 b008 	str.w	fp, [r5, #8]
	MPU->RLAR = (MPU->RLAR & (~MPU_RLAR_LIMIT_Msk))
    d602:	692a      	ldr	r2, [r5, #16]
    d604:	3b01      	subs	r3, #1
    d606:	f023 031f 	bic.w	r3, r3, #31
    d60a:	f002 021f 	and.w	r2, r2, #31
		| (limit & MPU_RLAR_LIMIT_Msk);
    d60e:	4313      	orrs	r3, r2
		} else if (reg_last == u_reg_last) {
    d610:	45ca      	cmp	sl, r9
    d612:	b2e0      	uxtb	r0, r4
	MPU->RLAR = (MPU->RLAR & (~MPU_RLAR_LIMIT_Msk))
    d614:	612b      	str	r3, [r5, #16]
		} else if (reg_last == u_reg_last) {
    d616:	d0eb      	beq.n	d5f0 <mpu_configure_regions_and_partition.constprop.0+0xb0>
				mpu_configure_region(reg_index, regions[i]);
    d618:	f001 fe35 	bl	f286 <mpu_configure_region>
			if (reg_index == -EINVAL) {
    d61c:	f110 0f16 	cmn.w	r0, #22
    d620:	d0a2      	beq.n	d568 <mpu_configure_regions_and_partition.constprop.0+0x28>
	MPU->RNR = index;
    d622:	f8c5 b008 	str.w	fp, [r5, #8]
	attr->rbar = MPU->RBAR &
    d626:	68ea      	ldr	r2, [r5, #12]
    d628:	f89d 3008 	ldrb.w	r3, [sp, #8]
			REGION_LIMIT_ADDR((regions[i]->start +
    d62c:	f10a 3aff 	add.w	sl, sl, #4294967295
	attr->rbar = MPU->RBAR &
    d630:	f362 0304 	bfi	r3, r2, #0, #5
    d634:	f88d 3008 	strb.w	r3, [sp, #8]
	attr->mair_idx = (MPU->RLAR & MPU_RLAR_AttrIndx_Msk) >>
    d638:	692b      	ldr	r3, [r5, #16]
    d63a:	f89d 2008 	ldrb.w	r2, [sp, #8]
    d63e:	085b      	lsrs	r3, r3, #1
    d640:	f363 1247 	bfi	r2, r3, #5, #3
			fill_region.base = regions[i]->start +
    d644:	f857 3026 	ldr.w	r3, [r7, r6, lsl #2]
	attr->mair_idx = (MPU->RLAR & MPU_RLAR_AttrIndx_Msk) >>
    d648:	f88d 2008 	strb.w	r2, [sp, #8]
			fill_region.base = regions[i]->start +
    d64c:	e9d3 1300 	ldrd	r1, r3, [r3]
    d650:	440b      	add	r3, r1
    d652:	9300      	str	r3, [sp, #0]
			REGION_LIMIT_ADDR((regions[i]->start +
    d654:	f023 031f 	bic.w	r3, r3, #31
			reg_index++;
    d658:	3001      	adds	r0, #1
			REGION_LIMIT_ADDR((regions[i]->start +
    d65a:	4453      	add	r3, sl
    d65c:	eba3 0309 	sub.w	r3, r3, r9
    d660:	b2c0      	uxtb	r0, r0
    d662:	f023 031f 	bic.w	r3, r3, #31

static int region_allocate_and_init(const uint8_t index,
	const struct arm_mpu_region *region_conf)
{
	/* Attempt to allocate new region index. */
	if (index > (get_num_regions() - 1)) {
    d666:	280f      	cmp	r0, #15
			fill_region.attr.r_limit =
    d668:	9303      	str	r3, [sp, #12]
    d66a:	f63f af7d 	bhi.w	d568 <mpu_configure_regions_and_partition.constprop.0+0x28>
	}

	LOG_DBG("Program MPU region at index 0x%x", index);

	/* Program region */
	region_init(index, region_conf);
    d66e:	4669      	mov	r1, sp
    d670:	f7ff ff4e 	bl	d510 <region_init>
    d674:	e7c1      	b.n	d5fa <mpu_configure_regions_and_partition.constprop.0+0xba>
    d676:	bf00      	nop
    d678:	e000ed90 	.word	0xe000ed90

0000d67c <arm_core_mpu_enable>:
void arm_core_mpu_enable(void)
{
	/* Enable MPU and use the default memory map as a
	 * background region for privileged software access.
	 */
	MPU->CTRL = MPU_CTRL_ENABLE_Msk | MPU_CTRL_PRIVDEFENA_Msk;
    d67c:	2205      	movs	r2, #5
    d67e:	4b03      	ldr	r3, [pc, #12]	; (d68c <arm_core_mpu_enable+0x10>)
    d680:	605a      	str	r2, [r3, #4]
  __ASM volatile ("dsb 0xF":::"memory");
    d682:	f3bf 8f4f 	dsb	sy
  __ASM volatile ("isb 0xF":::"memory");
    d686:	f3bf 8f6f 	isb	sy

	/* Make sure that all the registers are set before proceeding */
	__DSB();
	__ISB();
}
    d68a:	4770      	bx	lr
    d68c:	e000ed90 	.word	0xe000ed90

0000d690 <arm_core_mpu_disable>:
  \details Ensures the apparent order of the explicit memory operations before
           and after the instruction, without ensuring their completion.
 */
__STATIC_FORCEINLINE void __DMB(void)
{
  __ASM volatile ("dmb 0xF":::"memory");
    d690:	f3bf 8f5f 	dmb	sy
{
	/* Force any outstanding transfers to complete before disabling MPU */
	__DMB();

	/* Disable MPU */
	MPU->CTRL = 0;
    d694:	2200      	movs	r2, #0
    d696:	4b01      	ldr	r3, [pc, #4]	; (d69c <arm_core_mpu_disable+0xc>)
    d698:	605a      	str	r2, [r3, #4]
}
    d69a:	4770      	bx	lr
    d69c:	e000ed90 	.word	0xe000ed90

0000d6a0 <arm_mpu_init>:
 *
 * This function provides the default configuration mechanism for the Memory
 * Protection Unit (MPU).
 */
static int arm_mpu_init(const struct device *arg)
{
    d6a0:	b538      	push	{r3, r4, r5, lr}
	uint32_t r_index;

	if (mpu_config.num_regions > get_num_regions()) {
    d6a2:	4c0e      	ldr	r4, [pc, #56]	; (d6dc <arm_mpu_init+0x3c>)
    d6a4:	6825      	ldr	r5, [r4, #0]
    d6a6:	2d10      	cmp	r5, #16
    d6a8:	d814      	bhi.n	d6d4 <arm_mpu_init+0x34>
		return -1;
	}

	LOG_DBG("total region count: %d", get_num_regions());

	arm_core_mpu_disable();
    d6aa:	f7ff fff1 	bl	d690 <arm_core_mpu_disable>

	/* Architecture-specific configuration */
	mpu_init();

	/* Program fixed regions configured at SOC definition. */
	for (r_index = 0U; r_index < mpu_config.num_regions; r_index++) {
    d6ae:	2000      	movs	r0, #0
	MPU->MAIR0 =
    d6b0:	4b0b      	ldr	r3, [pc, #44]	; (d6e0 <arm_mpu_init+0x40>)
    d6b2:	4a0c      	ldr	r2, [pc, #48]	; (d6e4 <arm_mpu_init+0x44>)
    d6b4:	631a      	str	r2, [r3, #48]	; 0x30
    d6b6:	4285      	cmp	r5, r0
    d6b8:	d105      	bne.n	d6c6 <arm_mpu_init+0x26>
		region_init(r_index, &mpu_config.mpu_regions[r_index]);
	}

	/* Update the number of programmed MPU regions. */
	static_regions_num = mpu_config.num_regions;
    d6ba:	4b0b      	ldr	r3, [pc, #44]	; (d6e8 <arm_mpu_init+0x48>)
    d6bc:	701d      	strb	r5, [r3, #0]


	arm_core_mpu_enable();
    d6be:	f7ff ffdd 	bl	d67c <arm_core_mpu_enable>
	__ASSERT(
		(MPU->TYPE & MPU_TYPE_DREGION_Msk) >> MPU_TYPE_DREGION_Pos ==
		NUM_MPU_REGIONS,
		"Invalid number of MPU regions\n");
#endif /* CORTEX_M0PLUS || CPU_CORTEX_M3 || CPU_CORTEX_M4 */
	return 0;
    d6c2:	2000      	movs	r0, #0
}
    d6c4:	bd38      	pop	{r3, r4, r5, pc}
		region_init(r_index, &mpu_config.mpu_regions[r_index]);
    d6c6:	6861      	ldr	r1, [r4, #4]
    d6c8:	eb01 1100 	add.w	r1, r1, r0, lsl #4
    d6cc:	f7ff ff20 	bl	d510 <region_init>
	for (r_index = 0U; r_index < mpu_config.num_regions; r_index++) {
    d6d0:	3001      	adds	r0, #1
    d6d2:	e7f0      	b.n	d6b6 <arm_mpu_init+0x16>
		return -1;
    d6d4:	f04f 30ff 	mov.w	r0, #4294967295
    d6d8:	e7f4      	b.n	d6c4 <arm_mpu_init+0x24>
    d6da:	bf00      	nop
    d6dc:	0000fa48 	.word	0x0000fa48
    d6e0:	e000ed90 	.word	0xe000ed90
    d6e4:	0044ffaa 	.word	0x0044ffaa
    d6e8:	20010284 	.word	0x20010284

0000d6ec <arm_core_mpu_configure_static_mpu_regions>:
{
    d6ec:	b510      	push	{r4, lr}
static int mpu_configure_static_mpu_regions(const struct k_mem_partition
	*static_regions[], const uint8_t regions_num,
	const uint32_t background_area_base,
	const uint32_t background_area_end)
{
	int mpu_reg_index = static_regions_num;
    d6ee:	4c03      	ldr	r4, [pc, #12]	; (d6fc <arm_core_mpu_configure_static_mpu_regions+0x10>)
	 * given boundaries.
	 */
	ARG_UNUSED(background_area_base);
	ARG_UNUSED(background_area_end);

	mpu_reg_index = mpu_configure_regions_and_partition(static_regions,
    d6f0:	7822      	ldrb	r2, [r4, #0]
    d6f2:	f7ff ff25 	bl	d540 <mpu_configure_regions_and_partition.constprop.0>
		regions_num, mpu_reg_index, true);

	static_regions_num = mpu_reg_index;
    d6f6:	7020      	strb	r0, [r4, #0]
}
    d6f8:	bd10      	pop	{r4, pc}
    d6fa:	bf00      	nop
    d6fc:	20010284 	.word	0x20010284

0000d700 <arm_core_mpu_mark_areas_for_dynamic_regions>:
{
    d700:	e92d 4ff7 	stmdb	sp!, {r0, r1, r2, r4, r5, r6, r7, r8, r9, sl, fp, lr}
    d704:	4d26      	ldr	r5, [pc, #152]	; (d7a0 <arm_core_mpu_mark_areas_for_dynamic_regions+0xa0>)
    d706:	468a      	mov	sl, r1
{
	/* In ARMv8-M architecture we need to store the index values
	 * and the default configuration of the MPU regions, inside
	 * which dynamic memory regions may be programmed at run-time.
	 */
	for (int i = 0; i < dyn_region_areas_num; i++) {
    d708:	4606      	mov	r6, r0
    d70a:	f04f 0800 	mov.w	r8, #0
    d70e:	46ab      	mov	fp, r5
	MPU->RNR = index;
    d710:	4f24      	ldr	r7, [pc, #144]	; (d7a4 <arm_core_mpu_mark_areas_for_dynamic_regions+0xa4>)
	for (int i = 0; i < dyn_region_areas_num; i++) {
    d712:	45d0      	cmp	r8, sl
    d714:	da1b      	bge.n	d74e <arm_core_mpu_mark_areas_for_dynamic_regions+0x4e>
		if (dyn_region_areas[i].size == 0U) {
    d716:	f8d6 9004 	ldr.w	r9, [r6, #4]
    d71a:	f1b9 0f00 	cmp.w	r9, #0
    d71e:	d039      	beq.n	d794 <arm_core_mpu_mark_areas_for_dynamic_regions+0x94>
		}
		/* Non-empty area */

		/* Retrieve HW MPU region index */
		dyn_reg_info[i].index =
			get_region_index(dyn_region_areas[i].start,
    d720:	6831      	ldr	r1, [r6, #0]
	uint32_t region_start_addr = arm_cmse_mpu_region_get(start);
    d722:	4608      	mov	r0, r1
    d724:	9101      	str	r1, [sp, #4]
    d726:	f001 fdce 	bl	f2c6 <arm_cmse_mpu_region_get>
	uint32_t region_end_addr = arm_cmse_mpu_region_get(start + size - 1);
    d72a:	9901      	ldr	r1, [sp, #4]
	uint32_t region_start_addr = arm_cmse_mpu_region_get(start);
    d72c:	4604      	mov	r4, r0
	uint32_t region_end_addr = arm_cmse_mpu_region_get(start + size - 1);
    d72e:	eb09 0001 	add.w	r0, r9, r1
    d732:	3801      	subs	r0, #1
    d734:	f001 fdc7 	bl	f2c6 <arm_cmse_mpu_region_get>
	if (region_start_addr == region_end_addr) {
    d738:	4284      	cmp	r4, r0
    d73a:	f04f 0214 	mov.w	r2, #20
    d73e:	4b1a      	ldr	r3, [pc, #104]	; (d7a8 <arm_core_mpu_mark_areas_for_dynamic_regions+0xa8>)
    d740:	d008      	beq.n	d754 <arm_core_mpu_mark_areas_for_dynamic_regions+0x54>
		dyn_reg_info[i].index =
    d742:	f06f 0315 	mvn.w	r3, #21
    d746:	fb02 f808 	mul.w	r8, r2, r8
    d74a:	f84b 3008 	str.w	r3, [fp, r8]
}
    d74e:	b003      	add	sp, #12
    d750:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
					dyn_region_areas[i].size);

		if (dyn_reg_info[i].index == -EINVAL) {
    d754:	f114 0f16 	cmn.w	r4, #22
		dyn_reg_info[i].index =
    d758:	602c      	str	r4, [r5, #0]
		if (dyn_reg_info[i].index == -EINVAL) {
    d75a:	d0f8      	beq.n	d74e <arm_core_mpu_mark_areas_for_dynamic_regions+0x4e>

			return -EINVAL;
		}

		if (dyn_reg_info[i].index >= static_regions_num) {
    d75c:	7819      	ldrb	r1, [r3, #0]
    d75e:	42a1      	cmp	r1, r4
    d760:	ddf5      	ble.n	d74e <arm_core_mpu_mark_areas_for_dynamic_regions+0x4e>
	attr->rbar = MPU->RBAR &
    d762:	fb02 b008 	mla	r0, r2, r8, fp
	MPU->RNR = index;
    d766:	60bc      	str	r4, [r7, #8]
	MPU->RNR = index;
    d768:	60bc      	str	r4, [r7, #8]
	attr->rbar = MPU->RBAR &
    d76a:	68fc      	ldr	r4, [r7, #12]
    d76c:	f100 0108 	add.w	r1, r0, #8
    d770:	7b00      	ldrb	r0, [r0, #12]
    d772:	f364 0004 	bfi	r0, r4, #0, #5
    d776:	7108      	strb	r0, [r1, #4]
	attr->mair_idx = (MPU->RLAR & MPU_RLAR_AttrIndx_Msk) >>
    d778:	6938      	ldr	r0, [r7, #16]
    d77a:	790c      	ldrb	r4, [r1, #4]
    d77c:	0840      	lsrs	r0, r0, #1
    d77e:	f360 1447 	bfi	r4, r0, #5, #3
    d782:	710c      	strb	r4, [r1, #4]
	region_conf->base = (MPU->RBAR & MPU_RBAR_BASE_Msk);
    d784:	68f9      	ldr	r1, [r7, #12]
    d786:	f021 011f 	bic.w	r1, r1, #31
    d78a:	6069      	str	r1, [r5, #4]
	region_conf->attr.r_limit = MPU->RLAR & MPU_RLAR_LIMIT_Msk;
    d78c:	6939      	ldr	r1, [r7, #16]
    d78e:	f021 011f 	bic.w	r1, r1, #31
    d792:	6129      	str	r1, [r5, #16]
	for (int i = 0; i < dyn_region_areas_num; i++) {
    d794:	f108 0801 	add.w	r8, r8, #1
    d798:	3514      	adds	r5, #20
    d79a:	360c      	adds	r6, #12
    d79c:	e7b9      	b.n	d712 <arm_core_mpu_mark_areas_for_dynamic_regions+0x12>
    d79e:	bf00      	nop
    d7a0:	20010208 	.word	0x20010208
    d7a4:	e000ed90 	.word	0xe000ed90
    d7a8:	20010284 	.word	0x20010284

0000d7ac <__stdout_hook_install>:

static int (*_stdout_hook)(int) = _stdout_hook_default;

void __stdout_hook_install(int (*hook)(int))
{
	_stdout_hook = hook;
    d7ac:	4b01      	ldr	r3, [pc, #4]	; (d7b4 <__stdout_hook_install+0x8>)
    d7ae:	6018      	str	r0, [r3, #0]
}
    d7b0:	4770      	bx	lr
    d7b2:	bf00      	nop
    d7b4:	20010004 	.word	0x20010004

0000d7b8 <nrf_gpio_cfg_sense_set>:
}

NRF_STATIC_INLINE uint32_t nrf_gpio_pin_port_number_extract(uint32_t * p_pin)
{
    uint32_t pin_number = *p_pin;
    *p_pin = pin_number & 0x1F;
    d7b8:	f000 021f 	and.w	r2, r0, #31
    d7bc:	4805      	ldr	r0, [pc, #20]	; (d7d4 <nrf_gpio_cfg_sense_set+0x1c>)
    d7be:	eb00 0082 	add.w	r0, r0, r2, lsl #2
    uint32_t cnf = reg->PIN_CNF[pin_number] & ~GPIO_PIN_CNF_SENSE_Msk;
    d7c2:	f8d0 3200 	ldr.w	r3, [r0, #512]	; 0x200
    d7c6:	f423 3340 	bic.w	r3, r3, #196608	; 0x30000
    reg->PIN_CNF[pin_number] = cnf | (sense_config << GPIO_PIN_CNF_SENSE_Pos);
    d7ca:	ea43 4301 	orr.w	r3, r3, r1, lsl #16
    d7ce:	f8c0 3200 	str.w	r3, [r0, #512]	; 0x200
}
    d7d2:	4770      	bx	lr
    d7d4:	40842500 	.word	0x40842500

0000d7d8 <gpio_nrfx_init>:
}

#define GPIOTE_NODE DT_INST(0, nordic_nrf_gpiote)

static int gpio_nrfx_init(const struct device *port)
{
    d7d8:	b508      	push	{r3, lr}
	static bool gpio_initialized;

	if (!gpio_initialized) {
    d7da:	4b09      	ldr	r3, [pc, #36]	; (d800 <gpio_nrfx_init+0x28>)
    d7dc:	781a      	ldrb	r2, [r3, #0]
    d7de:	b96a      	cbnz	r2, d7fc <gpio_nrfx_init+0x24>
		gpio_initialized = true;
    d7e0:	2101      	movs	r1, #1
		IRQ_CONNECT(DT_IRQN(GPIOTE_NODE), DT_IRQ(GPIOTE_NODE, priority),
    d7e2:	2031      	movs	r0, #49	; 0x31
		gpio_initialized = true;
    d7e4:	7019      	strb	r1, [r3, #0]
		IRQ_CONNECT(DT_IRQN(GPIOTE_NODE), DT_IRQ(GPIOTE_NODE, priority),
    d7e6:	2105      	movs	r1, #5
    d7e8:	f7ff fc68 	bl	d0bc <z_arm_irq_priority_set>
			    gpiote_event_handler, NULL, 0);

		irq_enable(DT_IRQN(GPIOTE_NODE));
    d7ec:	2031      	movs	r0, #49	; 0x31
    d7ee:	f7ff fc47 	bl	d080 <arch_irq_enable>
    return ((uint32_t)p_reg + event);
}

NRF_STATIC_INLINE void nrf_gpiote_int_enable(NRF_GPIOTE_Type * p_reg, uint32_t mask)
{
    p_reg->INTENSET = mask;
    d7f2:	f04f 4200 	mov.w	r2, #2147483648	; 0x80000000
    d7f6:	4b03      	ldr	r3, [pc, #12]	; (d804 <gpio_nrfx_init+0x2c>)
    d7f8:	f8c3 2304 	str.w	r2, [r3, #772]	; 0x304
		nrf_gpiote_int_enable(NRF_GPIOTE, NRF_GPIOTE_INT_PORT_MASK);
	}

	return 0;
}
    d7fc:	2000      	movs	r0, #0
    d7fe:	bd08      	pop	{r3, pc}
    d800:	20010285 	.word	0x20010285
    d804:	40031000 	.word	0x40031000

0000d808 <gpio_nrfx_config>:
	switch (flags & (GPIO_DS_LOW_MASK | GPIO_DS_HIGH_MASK |
    d808:	4b28      	ldr	r3, [pc, #160]	; (d8ac <gpio_nrfx_config+0xa4>)
{
    d80a:	b570      	push	{r4, r5, r6, lr}
	NRF_GPIO_Type *reg = get_port_cfg(port)->port;
    d80c:	6846      	ldr	r6, [r0, #4]
	switch (flags & (GPIO_DS_LOW_MASK | GPIO_DS_HIGH_MASK |
    d80e:	4828      	ldr	r0, [pc, #160]	; (d8b0 <gpio_nrfx_config+0xa8>)
    d810:	4013      	ands	r3, r2
    d812:	4283      	cmp	r3, r0
    d814:	d03b      	beq.n	d88e <gpio_nrfx_config+0x86>
    d816:	d80d      	bhi.n	d834 <gpio_nrfx_config+0x2c>
    d818:	2b06      	cmp	r3, #6
    d81a:	d015      	beq.n	d848 <gpio_nrfx_config+0x40>
    d81c:	d805      	bhi.n	d82a <gpio_nrfx_config+0x22>
    d81e:	b19b      	cbz	r3, d848 <gpio_nrfx_config+0x40>
    d820:	2b02      	cmp	r3, #2
    d822:	d036      	beq.n	d892 <gpio_nrfx_config+0x8a>
    d824:	f06f 0015 	mvn.w	r0, #21
    d828:	e030      	b.n	d88c <gpio_nrfx_config+0x84>
    d82a:	f5b3 1f80 	cmp.w	r3, #1048576	; 0x100000
    d82e:	d1f9      	bne.n	d824 <gpio_nrfx_config+0x1c>
		drive = NRF_GPIO_PIN_H0S1;
    d830:	2301      	movs	r3, #1
    d832:	e009      	b.n	d848 <gpio_nrfx_config+0x40>
	switch (flags & (GPIO_DS_LOW_MASK | GPIO_DS_HIGH_MASK |
    d834:	481f      	ldr	r0, [pc, #124]	; (d8b4 <gpio_nrfx_config+0xac>)
    d836:	4283      	cmp	r3, r0
    d838:	d02d      	beq.n	d896 <gpio_nrfx_config+0x8e>
    d83a:	f5b3 0fa0 	cmp.w	r3, #5242880	; 0x500000
    d83e:	d02c      	beq.n	d89a <gpio_nrfx_config+0x92>
    d840:	f5b3 0f80 	cmp.w	r3, #4194304	; 0x400000
    d844:	d1ee      	bne.n	d824 <gpio_nrfx_config+0x1c>
		drive = NRF_GPIO_PIN_S0H1;
    d846:	2302      	movs	r3, #2
	if ((flags & GPIO_PULL_UP) != 0) {
    d848:	06d0      	lsls	r0, r2, #27
		pull = NRF_GPIO_PIN_PULLUP;
    d84a:	bf4c      	ite	mi
    d84c:	2503      	movmi	r5, #3
		pull = NRF_GPIO_PIN_NOPULL;
    d84e:	f3c2 1540 	ubfxpl	r5, r2, #5, #1
		: NRF_GPIO_PIN_INPUT_DISCONNECT;
    d852:	f482 7480 	eor.w	r4, r2, #256	; 0x100
	if ((flags & GPIO_OUTPUT) != 0) {
    d856:	f412 7f00 	tst.w	r2, #512	; 0x200
	dir = ((flags & GPIO_OUTPUT) != 0)
    d85a:	f3c2 2040 	ubfx	r0, r2, #9, #1
		: NRF_GPIO_PIN_INPUT_DISCONNECT;
    d85e:	f3c4 2400 	ubfx	r4, r4, #8, #1
	if ((flags & GPIO_OUTPUT) != 0) {
    d862:	d006      	beq.n	d872 <gpio_nrfx_config+0x6a>
		if ((flags & GPIO_OUTPUT_INIT_HIGH) != 0) {
    d864:	f412 6f00 	tst.w	r2, #2048	; 0x800
	NRF_GPIO_Type *reg = get_port_cfg(port)->port;
    d868:	6876      	ldr	r6, [r6, #4]
		if ((flags & GPIO_OUTPUT_INIT_HIGH) != 0) {
    d86a:	d018      	beq.n	d89e <gpio_nrfx_config+0x96>
			nrf_gpio_port_out_set(reg, BIT(pin));
    d86c:	2201      	movs	r2, #1
    d86e:	408a      	lsls	r2, r1
    p_reg->OUTSET = set_mask;
    d870:	60b2      	str	r2, [r6, #8]
                               | ((uint32_t)drive << GPIO_PIN_CNF_DRIVE_Pos)
    d872:	ea40 0244 	orr.w	r2, r0, r4, lsl #1
	return 0;
    d876:	2000      	movs	r0, #0
    d878:	ea42 2303 	orr.w	r3, r2, r3, lsl #8
    *p_pin = pin_number & 0x1F;
    d87c:	f001 011f 	and.w	r1, r1, #31
    reg->PIN_CNF[pin_number] = ((uint32_t)dir << GPIO_PIN_CNF_DIR_Pos)
    d880:	4a0d      	ldr	r2, [pc, #52]	; (d8b8 <gpio_nrfx_config+0xb0>)
                               | ((uint32_t)drive << GPIO_PIN_CNF_DRIVE_Pos)
    d882:	ea43 0385 	orr.w	r3, r3, r5, lsl #2
    reg->PIN_CNF[pin_number] = ((uint32_t)dir << GPIO_PIN_CNF_DIR_Pos)
    d886:	3180      	adds	r1, #128	; 0x80
    d888:	f842 3021 	str.w	r3, [r2, r1, lsl #2]
}
    d88c:	bd70      	pop	{r4, r5, r6, pc}
		drive = NRF_GPIO_PIN_H0D1;
    d88e:	2307      	movs	r3, #7
    d890:	e7da      	b.n	d848 <gpio_nrfx_config+0x40>
		drive = NRF_GPIO_PIN_D0S1;
    d892:	2304      	movs	r3, #4
    d894:	e7d8      	b.n	d848 <gpio_nrfx_config+0x40>
		drive = NRF_GPIO_PIN_D0H1;
    d896:	2305      	movs	r3, #5
    d898:	e7d6      	b.n	d848 <gpio_nrfx_config+0x40>
		drive = NRF_GPIO_PIN_H0H1;
    d89a:	2303      	movs	r3, #3
    d89c:	e7d4      	b.n	d848 <gpio_nrfx_config+0x40>
		} else if ((flags & GPIO_OUTPUT_INIT_LOW) != 0) {
    d89e:	0552      	lsls	r2, r2, #21
			nrf_gpio_port_out_clear(reg, BIT(pin));
    d8a0:	bf42      	ittt	mi
    d8a2:	2201      	movmi	r2, #1
    d8a4:	408a      	lslmi	r2, r1
    p_reg->OUTCLR = clr_mask;
    d8a6:	60f2      	strmi	r2, [r6, #12]
}
    d8a8:	e7e3      	b.n	d872 <gpio_nrfx_config+0x6a>
    d8aa:	bf00      	nop
    d8ac:	00f00006 	.word	0x00f00006
    d8b0:	00100006 	.word	0x00100006
    d8b4:	00400002 	.word	0x00400002
    d8b8:	40842500 	.word	0x40842500

0000d8bc <gpio_nrfx_pin_interrupt_configure>:
{
    d8bc:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    d8c0:	460d      	mov	r5, r1
	uint32_t abs_pin = NRF_GPIO_PIN_MAP(get_port_cfg(port)->port_num, pin);
    d8c2:	6841      	ldr	r1, [r0, #4]
	struct gpio_nrfx_data *data = get_port_data(port);
    d8c4:	f8d0 800c 	ldr.w	r8, [r0, #12]
	uint32_t abs_pin = NRF_GPIO_PIN_MAP(get_port_cfg(port)->port_num, pin);
    d8c8:	7a08      	ldrb	r0, [r1, #8]
    d8ca:	f005 071f 	and.w	r7, r5, #31
	if ((mode == GPIO_INT_MODE_EDGE) &&
    d8ce:	f5b2 3fa0 	cmp.w	r2, #81920	; 0x14000
    d8d2:	ea47 1740 	orr.w	r7, r7, r0, lsl #5
    d8d6:	d10a      	bne.n	d8ee <gpio_nrfx_pin_interrupt_configure+0x32>
    return (nrf_gpio_pin_dir_t)((reg->PIN_CNF[pin_number] &
    d8d8:	486e      	ldr	r0, [pc, #440]	; (da94 <gpio_nrfx_pin_interrupt_configure+0x1d8>)
    *p_pin = pin_number & 0x1F;
    d8da:	f007 011f 	and.w	r1, r7, #31
    return (nrf_gpio_pin_dir_t)((reg->PIN_CNF[pin_number] &
    d8de:	3180      	adds	r1, #128	; 0x80
    d8e0:	f850 1021 	ldr.w	r1, [r0, r1, lsl #2]
    d8e4:	07c8      	lsls	r0, r1, #31
    d8e6:	d508      	bpl.n	d8fa <gpio_nrfx_pin_interrupt_configure+0x3e>
		return -ENOTSUP;
    d8e8:	f06f 0022 	mvn.w	r0, #34	; 0x22
    d8ec:	e0c2      	b.n	da74 <gpio_nrfx_pin_interrupt_configure+0x1b8>
	WRITE_BIT(data->pin_int_en, pin, mode != GPIO_INT_MODE_DISABLED);
    d8ee:	f5b2 5f00 	cmp.w	r2, #8192	; 0x2000
    d8f2:	f8d8 100c 	ldr.w	r1, [r8, #12]
    d8f6:	f000 80ae 	beq.w	da56 <gpio_nrfx_pin_interrupt_configure+0x19a>
    d8fa:	2101      	movs	r1, #1
    d8fc:	f8d8 000c 	ldr.w	r0, [r8, #12]
    d900:	40a9      	lsls	r1, r5
    d902:	4301      	orrs	r1, r0
    d904:	f8c8 100c 	str.w	r1, [r8, #12]
	WRITE_BIT(data->trig_edge, pin, mode == GPIO_INT_MODE_EDGE);
    d908:	2101      	movs	r1, #1
    d90a:	f8d8 0014 	ldr.w	r0, [r8, #20]
    d90e:	40a9      	lsls	r1, r5
    d910:	f5b2 3fa0 	cmp.w	r2, #81920	; 0x14000
    d914:	f8d8 2018 	ldr.w	r2, [r8, #24]
    d918:	bf0c      	ite	eq
    d91a:	4308      	orreq	r0, r1
    d91c:	4388      	bicne	r0, r1
	WRITE_BIT(data->double_edge, pin, trig == GPIO_INT_TRIG_BOTH);
    d91e:	f5b3 2fc0 	cmp.w	r3, #393216	; 0x60000
    d922:	bf0c      	ite	eq
    d924:	430a      	orreq	r2, r1
    d926:	438a      	bicne	r2, r1
	WRITE_BIT(data->int_active_level, pin, trig == GPIO_INT_TRIG_HIGH);
    d928:	f5b3 2f80 	cmp.w	r3, #262144	; 0x40000
	for (size_t i = 0; i < GPIOTE_CH_NUM; i++) {
    d92c:	f04f 0300 	mov.w	r3, #0
	WRITE_BIT(data->double_edge, pin, trig == GPIO_INT_TRIG_BOTH);
    d930:	f8c8 2018 	str.w	r2, [r8, #24]
    d934:	f8d8 2010 	ldr.w	r2, [r8, #16]
    p_reg->INTENCLR = mask;
}

NRF_STATIC_INLINE uint32_t nrf_gpiote_int_enable_check(NRF_GPIOTE_Type const * p_reg, uint32_t mask)
{
    return p_reg->INTENSET & mask;
    d938:	4e57      	ldr	r6, [pc, #348]	; (da98 <gpio_nrfx_pin_interrupt_configure+0x1dc>)
	WRITE_BIT(data->int_active_level, pin, trig == GPIO_INT_TRIG_HIGH);
    d93a:	bf0c      	ite	eq
    d93c:	4311      	orreq	r1, r2
    d93e:	ea22 0101 	bicne.w	r1, r2, r1
	WRITE_BIT(data->trig_edge, pin, mode == GPIO_INT_MODE_EDGE);
    d942:	f8c8 0014 	str.w	r0, [r8, #20]
	WRITE_BIT(data->int_active_level, pin, trig == GPIO_INT_TRIG_HIGH);
    d946:	f8c8 1010 	str.w	r1, [r8, #16]
    d94a:	f8d6 2304 	ldr.w	r2, [r6, #772]	; 0x304
    d94e:	b2d2      	uxtb	r2, r2
                        ((polarity << GPIOTE_CONFIG_POLARITY_Pos) & GPIOTE_CONFIG_POLARITY_Msk);
}

NRF_STATIC_INLINE uint32_t nrf_gpiote_event_pin_get(NRF_GPIOTE_Type const * p_reg, uint32_t idx)
{
    return ((p_reg->CONFIG[idx] & GPIOTE_CONFIG_PORT_PIN_Msk) >> GPIOTE_CONFIG_PSEL_Pos);
    d950:	f503 71a2 	add.w	r1, r3, #324	; 0x144
    d954:	f856 1021 	ldr.w	r1, [r6, r1, lsl #2]
    d958:	f3c1 2104 	ubfx	r1, r1, #8, #5
		if ((nrf_gpiote_event_pin_get(NRF_GPIOTE, i) == abs_pin)
    d95c:	428f      	cmp	r7, r1
    d95e:	d17f      	bne.n	da60 <gpio_nrfx_pin_interrupt_configure+0x1a4>
		    && (intenset & BIT(i))) {
    d960:	fa22 f103 	lsr.w	r1, r2, r3
    d964:	07c9      	lsls	r1, r1, #31
    d966:	d57b      	bpl.n	da60 <gpio_nrfx_pin_interrupt_configure+0x1a4>
			(void)atomic_and(mask, ~BIT(i));
    d968:	2201      	movs	r2, #1
    d96a:	409a      	lsls	r2, r3
    d96c:	43d0      	mvns	r0, r2
	return __atomic_fetch_and(target, value, __ATOMIC_SEQ_CST);
    d96e:	494b      	ldr	r1, [pc, #300]	; (da9c <gpio_nrfx_pin_interrupt_configure+0x1e0>)
    d970:	e8d1 4fef 	ldaex	r4, [r1]
    d974:	4004      	ands	r4, r0
    d976:	e8c1 4fec 	stlex	ip, r4, [r1]
    d97a:	f1bc 0f00 	cmp.w	ip, #0
    d97e:	d1f7      	bne.n	d970 <gpio_nrfx_pin_interrupt_configure+0xb4>
   p_reg->CONFIG[idx] &= ~GPIOTE_CONFIG_MODE_Event;
    d980:	009b      	lsls	r3, r3, #2
    d982:	f103 4380 	add.w	r3, r3, #1073741824	; 0x40000000
    d986:	f503 3344 	add.w	r3, r3, #200704	; 0x31000
    d98a:	f8d3 1510 	ldr.w	r1, [r3, #1296]	; 0x510
    d98e:	f021 0101 	bic.w	r1, r1, #1
    d992:	f8c3 1510 	str.w	r1, [r3, #1296]	; 0x510
    p_reg->INTENCLR = mask;
    d996:	f8c6 2308 	str.w	r2, [r6, #776]	; 0x308
	nrf_gpio_cfg_sense_set(abs_pin, NRF_GPIO_PIN_NOSENSE);
    d99a:	2100      	movs	r1, #0
    d99c:	4638      	mov	r0, r7
    d99e:	f7ff ff0b 	bl	d7b8 <nrf_gpio_cfg_sense_set>
	if (data->pin_int_en & BIT(pin)) {
    d9a2:	f8d8 300c 	ldr.w	r3, [r8, #12]
    d9a6:	40eb      	lsrs	r3, r5
    d9a8:	f013 0301 	ands.w	r3, r3, #1
    d9ac:	d051      	beq.n	da52 <gpio_nrfx_pin_interrupt_configure+0x196>
		if (data->trig_edge & BIT(pin)) {
    d9ae:	f8d8 3014 	ldr.w	r3, [r8, #20]
    d9b2:	40eb      	lsrs	r3, r5
    d9b4:	f013 0401 	ands.w	r4, r3, #1
    d9b8:	d05e      	beq.n	da78 <gpio_nrfx_pin_interrupt_configure+0x1bc>
			if (data->double_edge & BIT(pin)) {
    d9ba:	f8d8 3018 	ldr.w	r3, [r8, #24]
				pol = NRF_GPIOTE_POLARITY_TOGGLE;
    d9be:	2200      	movs	r2, #0
			if (data->double_edge & BIT(pin)) {
    d9c0:	40eb      	lsrs	r3, r5
    d9c2:	07db      	lsls	r3, r3, #31
				pol = NRF_GPIOTE_POLARITY_TOGGLE;
    d9c4:	bf48      	it	mi
    d9c6:	2503      	movmi	r5, #3
		atomic_val_t prev = atomic_or(mask, BIT(channel));
    d9c8:	f04f 0c01 	mov.w	ip, #1
			} else if ((data->int_active_level & BIT(pin)) != 0U) {
    d9cc:	bf5f      	itttt	pl
    d9ce:	f8d8 1010 	ldrpl.w	r1, [r8, #16]
    d9d2:	fa21 f505 	lsrpl.w	r5, r1, r5
    d9d6:	f005 0501 	andpl.w	r5, r5, #1
    d9da:	f1c5 0502 	rsbpl	r5, r5, #2
	return __atomic_fetch_or(target, value, __ATOMIC_SEQ_CST);
    d9de:	492f      	ldr	r1, [pc, #188]	; (da9c <gpio_nrfx_pin_interrupt_configure+0x1e0>)
    d9e0:	bf58      	it	pl
    d9e2:	b2ed      	uxtbpl	r5, r5
		atomic_val_t prev = atomic_or(mask, BIT(channel));
    d9e4:	fa0c f402 	lsl.w	r4, ip, r2
    d9e8:	e8d1 0fef 	ldaex	r0, [r1]
    d9ec:	ea40 0304 	orr.w	r3, r0, r4
    d9f0:	e8c1 3fee 	stlex	lr, r3, [r1]
    d9f4:	f1be 0f00 	cmp.w	lr, #0
    d9f8:	d1f6      	bne.n	d9e8 <gpio_nrfx_pin_interrupt_configure+0x12c>
		if ((prev & BIT(channel)) == 0) {
    d9fa:	40d0      	lsrs	r0, r2
    d9fc:	f010 0301 	ands.w	r3, r0, #1
    da00:	d133      	bne.n	da6a <gpio_nrfx_pin_interrupt_configure+0x1ae>
  p_reg->CONFIG[idx] &= ~(GPIOTE_CONFIG_PORT_PIN_Msk | GPIOTE_CONFIG_POLARITY_Msk);
    da02:	0091      	lsls	r1, r2, #2
    da04:	f101 4180 	add.w	r1, r1, #1073741824	; 0x40000000
    da08:	f501 3144 	add.w	r1, r1, #200704	; 0x31000
    da0c:	f8d1 0510 	ldr.w	r0, [r1, #1296]	; 0x510
			nrf_gpiote_event_t evt =
    da10:	3240      	adds	r2, #64	; 0x40
    da12:	f420 3047 	bic.w	r0, r0, #203776	; 0x31c00
    da16:	f420 7040 	bic.w	r0, r0, #768	; 0x300
    da1a:	f8c1 0510 	str.w	r0, [r1, #1296]	; 0x510
  p_reg->CONFIG[idx] |= ((pin << GPIOTE_CONFIG_PSEL_Pos) & GPIOTE_CONFIG_PORT_PIN_Msk) |
    da1e:	023f      	lsls	r7, r7, #8
    da20:	0092      	lsls	r2, r2, #2
    da22:	f8d1 0510 	ldr.w	r0, [r1, #1296]	; 0x510
    da26:	f407 57f8 	and.w	r7, r7, #7936	; 0x1f00
    return ((uint32_t)p_reg + event);
    da2a:	b292      	uxth	r2, r2
  p_reg->CONFIG[idx] |= ((pin << GPIOTE_CONFIG_PSEL_Pos) & GPIOTE_CONFIG_PORT_PIN_Msk) |
    da2c:	ea47 4705 	orr.w	r7, r7, r5, lsl #16
    return ((uint32_t)p_reg + event);
    da30:	f102 4280 	add.w	r2, r2, #1073741824	; 0x40000000
    da34:	f502 3244 	add.w	r2, r2, #200704	; 0x31000
  p_reg->CONFIG[idx] |= ((pin << GPIOTE_CONFIG_PSEL_Pos) & GPIOTE_CONFIG_PORT_PIN_Msk) |
    da38:	4307      	orrs	r7, r0
    da3a:	f8c1 7510 	str.w	r7, [r1, #1296]	; 0x510
    *((volatile uint32_t *)nrf_gpiote_event_address_get(p_reg, event)) = 0;
    da3e:	6013      	str	r3, [r2, #0]
    da40:	6812      	ldr	r2, [r2, #0]
   p_reg->CONFIG[idx] |= GPIOTE_CONFIG_MODE_Event;
    da42:	f8d1 2510 	ldr.w	r2, [r1, #1296]	; 0x510
    da46:	f042 0201 	orr.w	r2, r2, #1
    da4a:	f8c1 2510 	str.w	r2, [r1, #1296]	; 0x510
    p_reg->INTENSET = mask;
    da4e:	f8c6 4304 	str.w	r4, [r6, #772]	; 0x304
	int res = 0;
    da52:	4618      	mov	r0, r3
    da54:	e00e      	b.n	da74 <gpio_nrfx_pin_interrupt_configure+0x1b8>
	WRITE_BIT(data->pin_int_en, pin, mode != GPIO_INT_MODE_DISABLED);
    da56:	2001      	movs	r0, #1
    da58:	40a8      	lsls	r0, r5
    da5a:	ea21 0100 	bic.w	r1, r1, r0
    da5e:	e751      	b.n	d904 <gpio_nrfx_pin_interrupt_configure+0x48>
	for (size_t i = 0; i < GPIOTE_CH_NUM; i++) {
    da60:	3301      	adds	r3, #1
    da62:	2b08      	cmp	r3, #8
    da64:	f47f af74 	bne.w	d950 <gpio_nrfx_pin_interrupt_configure+0x94>
    da68:	e797      	b.n	d99a <gpio_nrfx_pin_interrupt_configure+0xde>
	for (uint8_t channel = 0; channel < GPIOTE_CH_NUM; ++channel) {
    da6a:	3201      	adds	r2, #1
    da6c:	2a08      	cmp	r2, #8
    da6e:	d1b9      	bne.n	d9e4 <gpio_nrfx_pin_interrupt_configure+0x128>
	return -ENODEV;
    da70:	f06f 0012 	mvn.w	r0, #18
}
    da74:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
	if ((BIT(pin) & data->int_active_level) != 0U) {
    da78:	f8d8 1010 	ldr.w	r1, [r8, #16]
			nrf_gpio_cfg_sense_set(abs_pin, sense);
    da7c:	4638      	mov	r0, r7
	if ((BIT(pin) & data->int_active_level) != 0U) {
    da7e:	40e9      	lsrs	r1, r5
    da80:	f001 0101 	and.w	r1, r1, #1
    da84:	f1c1 0103 	rsb	r1, r1, #3
			nrf_gpio_cfg_sense_set(abs_pin, sense);
    da88:	b2c9      	uxtb	r1, r1
    da8a:	f7ff fe95 	bl	d7b8 <nrf_gpio_cfg_sense_set>
	int res = 0;
    da8e:	4620      	mov	r0, r4
    da90:	e7f0      	b.n	da74 <gpio_nrfx_pin_interrupt_configure+0x1b8>
    da92:	bf00      	nop
    da94:	40842500 	.word	0x40842500
    da98:	40031000 	.word	0x40031000
    da9c:	20010238 	.word	0x20010238

0000daa0 <gpiote_event_handler>:
{
    daa0:	e92d 43f8 	stmdb	sp!, {r3, r4, r5, r6, r7, r8, r9, lr}
    return (bool)*(volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event);
    daa4:	4f3f      	ldr	r7, [pc, #252]	; (dba4 <gpiote_event_handler+0x104>)
    daa6:	683e      	ldr	r6, [r7, #0]
	if (port_event) {
    daa8:	2e00      	cmp	r6, #0
    daaa:	d04f      	beq.n	db4c <gpiote_event_handler+0xac>
	uint32_t bit = 1U << pin;
    daac:	f04f 0801 	mov.w	r8, #1
	uint32_t pin = 0U;
    dab0:	f04f 0900 	mov.w	r9, #0
	uint32_t out = data->pin_int_en;
    dab4:	4b3c      	ldr	r3, [pc, #240]	; (dba8 <gpiote_event_handler+0x108>)
    dab6:	68dd      	ldr	r5, [r3, #12]
	out &= ~data->trig_edge & ~data->double_edge;
    dab8:	e9d3 2105 	ldrd	r2, r1, [r3, #20]
    dabc:	430a      	orrs	r2, r1
    dabe:	ea25 0502 	bic.w	r5, r5, r2
    return p_reg->IN;
    dac2:	4a3a      	ldr	r2, [pc, #232]	; (dbac <gpiote_event_handler+0x10c>)
	uint32_t pin_states = ~(port_in ^ data->int_active_level);
    dac4:	691b      	ldr	r3, [r3, #16]
    dac6:	6914      	ldr	r4, [r2, #16]
    dac8:	405c      	eors	r4, r3
	uint32_t out = pin_states & level_pins;
    daca:	ea25 0404 	bic.w	r4, r5, r4
	while (level_pins) {
    dace:	bb75      	cbnz	r5, db2e <gpiote_event_handler+0x8e>
    *((volatile uint32_t *)nrf_gpiote_event_address_get(p_reg, event)) = 0;
    dad0:	603d      	str	r5, [r7, #0]
    dad2:	683b      	ldr	r3, [r7, #0]
	uint32_t fired_triggers[GPIO_COUNT] = {0};
    dad4:	2300      	movs	r3, #0
		if (nrf_gpiote_int_enable_check(NRF_GPIOTE, BIT(i)) &&
    dad6:	2501      	movs	r5, #1
    dad8:	461f      	mov	r7, r3
    return p_reg->INTENSET & mask;
    dada:	4835      	ldr	r0, [pc, #212]	; (dbb0 <gpiote_event_handler+0x110>)
    dadc:	4935      	ldr	r1, [pc, #212]	; (dbb4 <gpiote_event_handler+0x114>)
    dade:	f8d0 2304 	ldr.w	r2, [r0, #772]	; 0x304
    dae2:	fa05 fc03 	lsl.w	ip, r5, r3
    dae6:	ea1c 0f02 	tst.w	ip, r2
    daea:	d00f      	beq.n	db0c <gpiote_event_handler+0x6c>
    return (bool)*(volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event);
    daec:	f851 2023 	ldr.w	r2, [r1, r3, lsl #2]
    daf0:	b162      	cbz	r2, db0c <gpiote_event_handler+0x6c>
    return ((p_reg->CONFIG[idx] & GPIOTE_CONFIG_PORT_PIN_Msk) >> GPIOTE_CONFIG_PSEL_Pos);
    daf2:	f503 72a2 	add.w	r2, r3, #324	; 0x144
    daf6:	f850 2022 	ldr.w	r2, [r0, r2, lsl #2]
    *((volatile uint32_t *)nrf_gpiote_event_address_get(p_reg, event)) = 0;
    dafa:	f841 7023 	str.w	r7, [r1, r3, lsl #2]
    return ((p_reg->CONFIG[idx] & GPIOTE_CONFIG_PORT_PIN_Msk) >> GPIOTE_CONFIG_PSEL_Pos);
    dafe:	f3c2 2204 	ubfx	r2, r2, #8, #5
			fired_triggers[abs_pin / 32U] |= BIT(abs_pin % 32);
    db02:	fa05 f202 	lsl.w	r2, r5, r2
    db06:	4314      	orrs	r4, r2
    db08:	f851 2023 	ldr.w	r2, [r1, r3, lsl #2]
	for (size_t i = 0; i < GPIOTE_CH_NUM; i++) {
    db0c:	3301      	adds	r3, #1
    db0e:	2b08      	cmp	r3, #8
    db10:	d1e5      	bne.n	dade <gpiote_event_handler+0x3e>
	if (fired_triggers[0]) {
    db12:	b9ec      	cbnz	r4, db50 <gpiote_event_handler+0xb0>
	if (port_event) {
    db14:	b14e      	cbz	r6, db2a <gpiote_event_handler+0x8a>
	uint32_t bit = 1U << pin;
    db16:	2601      	movs	r6, #1
	uint32_t pin = 0U;
    db18:	2700      	movs	r7, #0
	uint32_t out = data->pin_int_en;
    db1a:	4d23      	ldr	r5, [pc, #140]	; (dba8 <gpiote_event_handler+0x108>)
    db1c:	68ec      	ldr	r4, [r5, #12]
	out &= ~data->trig_edge & ~data->double_edge;
    db1e:	e9d5 2105 	ldrd	r2, r1, [r5, #20]
    db22:	430a      	orrs	r2, r1
    db24:	ea24 0402 	bic.w	r4, r4, r2
	while (level_pins) {
    db28:	bb54      	cbnz	r4, db80 <gpiote_event_handler+0xe0>
}
    db2a:	e8bd 83f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, pc}
		if (level_pins & bit) {
    db2e:	ea15 0f08 	tst.w	r5, r8
    db32:	d006      	beq.n	db42 <gpiote_event_handler+0xa2>
			nrf_gpio_cfg_sense_set(abs_pin, NRF_GPIO_PIN_NOSENSE);
    db34:	2100      	movs	r1, #0
    db36:	f009 001f 	and.w	r0, r9, #31
    db3a:	f7ff fe3d 	bl	d7b8 <nrf_gpio_cfg_sense_set>
			level_pins &= ~bit;
    db3e:	ea25 0508 	bic.w	r5, r5, r8
		++pin;
    db42:	f109 0901 	add.w	r9, r9, #1
		bit <<= 1;
    db46:	ea4f 0848 	mov.w	r8, r8, lsl #1
    db4a:	e7c0      	b.n	dace <gpiote_event_handler+0x2e>
	uint32_t fired_triggers[GPIO_COUNT] = {0};
    db4c:	4634      	mov	r4, r6
    db4e:	e7c1      	b.n	dad4 <gpiote_event_handler+0x34>
					const struct device *port,
					uint32_t pins)
{
	struct gpio_callback *cb, *tmp;

	SYS_SLIST_FOR_EACH_CONTAINER_SAFE(list, cb, tmp, node) {
    db50:	4b15      	ldr	r3, [pc, #84]	; (dba8 <gpiote_event_handler+0x108>)
    db52:	6859      	ldr	r1, [r3, #4]
    db54:	2900      	cmp	r1, #0
    db56:	d0dd      	beq.n	db14 <gpiote_event_handler+0x74>
	return node->next;
    db58:	680d      	ldr	r5, [r1, #0]
		if (cb->pin_mask & pins) {
			__ASSERT(cb->handler, "No callback handler!");
			cb->handler(port, cb, cb->pin_mask & pins);
    db5a:	4f17      	ldr	r7, [pc, #92]	; (dbb8 <gpiote_event_handler+0x118>)
    db5c:	2d00      	cmp	r5, #0
    db5e:	bf38      	it	cc
    db60:	2500      	movcc	r5, #0
		if (cb->pin_mask & pins) {
    db62:	688a      	ldr	r2, [r1, #8]
    db64:	4022      	ands	r2, r4
    db66:	d002      	beq.n	db6e <gpiote_event_handler+0xce>
			cb->handler(port, cb, cb->pin_mask & pins);
    db68:	4638      	mov	r0, r7
    db6a:	684b      	ldr	r3, [r1, #4]
    db6c:	4798      	blx	r3
	SYS_SLIST_FOR_EACH_CONTAINER_SAFE(list, cb, tmp, node) {
    db6e:	2d00      	cmp	r5, #0
    db70:	d0d0      	beq.n	db14 <gpiote_event_handler+0x74>
    db72:	682b      	ldr	r3, [r5, #0]
Z_GENLIST_PEEK_NEXT_NO_CHECK(slist, snode)
    db74:	4629      	mov	r1, r5
    db76:	2b00      	cmp	r3, #0
    db78:	bf38      	it	cc
    db7a:	2300      	movcc	r3, #0
    db7c:	461d      	mov	r5, r3
    db7e:	e7f0      	b.n	db62 <gpiote_event_handler+0xc2>
		if (level_pins & bit) {
    db80:	4226      	tst	r6, r4
    db82:	d00c      	beq.n	db9e <gpiote_event_handler+0xfe>
	if ((BIT(pin) & data->int_active_level) != 0U) {
    db84:	6929      	ldr	r1, [r5, #16]
			nrf_gpio_cfg_sense_set(abs_pin, sense);
    db86:	f007 001f 	and.w	r0, r7, #31
	if ((BIT(pin) & data->int_active_level) != 0U) {
    db8a:	40f9      	lsrs	r1, r7
    db8c:	f001 0101 	and.w	r1, r1, #1
    db90:	f1c1 0103 	rsb	r1, r1, #3
			nrf_gpio_cfg_sense_set(abs_pin, sense);
    db94:	b2c9      	uxtb	r1, r1
    db96:	f7ff fe0f 	bl	d7b8 <nrf_gpio_cfg_sense_set>
			level_pins &= ~bit;
    db9a:	ea24 0406 	bic.w	r4, r4, r6
		++pin;
    db9e:	3701      	adds	r7, #1
		bit <<= 1;
    dba0:	0076      	lsls	r6, r6, #1
    dba2:	e7c1      	b.n	db28 <gpiote_event_handler+0x88>
    dba4:	4003117c 	.word	0x4003117c
    dba8:	2001021c 	.word	0x2001021c
    dbac:	40842500 	.word	0x40842500
    dbb0:	40031000 	.word	0x40031000
    dbb4:	40031100 	.word	0x40031100
    dbb8:	2001007c 	.word	0x2001007c

0000dbbc <uarte_nrfx_configure>:
	return 0;
}

static int uarte_nrfx_configure(const struct device *dev,
				const struct uart_config *cfg)
{
    dbbc:	b5f0      	push	{r4, r5, r6, r7, lr}
	nrf_uarte_config_t uarte_cfg;

#if defined(UARTE_CONFIG_STOP_Msk)
	switch (cfg->stop_bits) {
    dbbe:	794b      	ldrb	r3, [r1, #5]
    dbc0:	2b01      	cmp	r3, #1
    dbc2:	d029      	beq.n	dc18 <uarte_nrfx_configure+0x5c>
    dbc4:	2b03      	cmp	r3, #3
    dbc6:	d124      	bne.n	dc12 <uarte_nrfx_configure+0x56>
	case UART_CFG_STOP_BITS_1:
		uarte_cfg.stop = NRF_UARTE_STOP_ONE;
		break;
	case UART_CFG_STOP_BITS_2:
		uarte_cfg.stop = NRF_UARTE_STOP_TWO;
    dbc8:	2610      	movs	r6, #16
	if (cfg->stop_bits != UART_CFG_STOP_BITS_1) {
		return -ENOTSUP;
	}
#endif

	if (cfg->data_bits != UART_CFG_DATA_BITS_8) {
    dbca:	798b      	ldrb	r3, [r1, #6]
    dbcc:	2b03      	cmp	r3, #3
    dbce:	d120      	bne.n	dc12 <uarte_nrfx_configure+0x56>
		return -ENOTSUP;
	}

	switch (cfg->flow_ctrl) {
    dbd0:	79cc      	ldrb	r4, [r1, #7]
    dbd2:	b124      	cbz	r4, dbde <uarte_nrfx_configure+0x22>
    dbd4:	2c01      	cmp	r4, #1
    dbd6:	d11c      	bne.n	dc12 <uarte_nrfx_configure+0x56>
	case UART_CFG_FLOW_CTRL_NONE:
		uarte_cfg.hwfc = NRF_UARTE_HWFC_DISABLED;
		break;
	case UART_CFG_FLOW_CTRL_RTS_CTS:
		if (get_dev_config(dev)->rts_cts_pins_set) {
    dbd8:	6843      	ldr	r3, [r0, #4]
    dbda:	791b      	ldrb	r3, [r3, #4]
    dbdc:	b1cb      	cbz	r3, dc12 <uarte_nrfx_configure+0x56>
	}

#if defined(UARTE_CONFIG_PARITYTYPE_Msk)
	uarte_cfg.paritytype = NRF_UARTE_PARITYTYPE_EVEN;
#endif
	switch (cfg->parity) {
    dbde:	790a      	ldrb	r2, [r1, #4]
    dbe0:	b112      	cbz	r2, dbe8 <uarte_nrfx_configure+0x2c>
    dbe2:	2a02      	cmp	r2, #2
    dbe4:	d115      	bne.n	dc12 <uarte_nrfx_configure+0x56>
	case UART_CFG_PARITY_NONE:
		uarte_cfg.parity = NRF_UARTE_PARITY_EXCLUDED;
		break;
	case UART_CFG_PARITY_EVEN:
		uarte_cfg.parity = NRF_UARTE_PARITY_INCLUDED;
    dbe6:	220e      	movs	r2, #14
#endif
	default:
		return -ENOTSUP;
	}

	if (baudrate_set(dev, cfg->baudrate) != 0) {
    dbe8:	680b      	ldr	r3, [r1, #0]
	return config->uarte_regs;
    dbea:	6845      	ldr	r5, [r0, #4]
	switch (baudrate) {
    dbec:	f5b3 4f16 	cmp.w	r3, #38400	; 0x9600
	return config->uarte_regs;
    dbf0:	682d      	ldr	r5, [r5, #0]
	switch (baudrate) {
    dbf2:	d065      	beq.n	dcc0 <uarte_nrfx_configure+0x104>
    dbf4:	d82d      	bhi.n	dc52 <uarte_nrfx_configure+0x96>
    dbf6:	f5b3 5f16 	cmp.w	r3, #9600	; 0x2580
    dbfa:	d064      	beq.n	dcc6 <uarte_nrfx_configure+0x10a>
    dbfc:	d816      	bhi.n	dc2c <uarte_nrfx_configure+0x70>
    dbfe:	f5b3 6f96 	cmp.w	r3, #1200	; 0x4b0
    dc02:	d062      	beq.n	dcca <uarte_nrfx_configure+0x10e>
    dc04:	d80a      	bhi.n	dc1c <uarte_nrfx_configure+0x60>
    dc06:	f5b3 7f96 	cmp.w	r3, #300	; 0x12c
    dc0a:	d061      	beq.n	dcd0 <uarte_nrfx_configure+0x114>
    dc0c:	f5b3 7f16 	cmp.w	r3, #600	; 0x258
    dc10:	d061      	beq.n	dcd6 <uarte_nrfx_configure+0x11a>
    dc12:	f06f 0022 	mvn.w	r0, #34	; 0x22
    dc16:	e052      	b.n	dcbe <uarte_nrfx_configure+0x102>
	switch (cfg->stop_bits) {
    dc18:	2600      	movs	r6, #0
    dc1a:	e7d6      	b.n	dbca <uarte_nrfx_configure+0xe>
	switch (baudrate) {
    dc1c:	f5b3 6f16 	cmp.w	r3, #2400	; 0x960
    dc20:	d05c      	beq.n	dcdc <uarte_nrfx_configure+0x120>
    dc22:	f5b3 5f96 	cmp.w	r3, #4800	; 0x12c0
    dc26:	d1f4      	bne.n	dc12 <uarte_nrfx_configure+0x56>
		nrf_baudrate = NRF_UARTE_BAUDRATE_4800;
    dc28:	4b37      	ldr	r3, [pc, #220]	; (dd08 <uarte_nrfx_configure+0x14c>)
    dc2a:	e03c      	b.n	dca6 <uarte_nrfx_configure+0xea>
	switch (baudrate) {
    dc2c:	f5b3 4fe1 	cmp.w	r3, #28800	; 0x7080
    dc30:	d057      	beq.n	dce2 <uarte_nrfx_configure+0x126>
    dc32:	d807      	bhi.n	dc44 <uarte_nrfx_configure+0x88>
    dc34:	f5b3 5f61 	cmp.w	r3, #14400	; 0x3840
    dc38:	d055      	beq.n	dce6 <uarte_nrfx_configure+0x12a>
    dc3a:	f5b3 4f96 	cmp.w	r3, #19200	; 0x4b00
    dc3e:	d1e8      	bne.n	dc12 <uarte_nrfx_configure+0x56>
		nrf_baudrate = NRF_UARTE_BAUDRATE_19200;
    dc40:	4b32      	ldr	r3, [pc, #200]	; (dd0c <uarte_nrfx_configure+0x150>)
    dc42:	e030      	b.n	dca6 <uarte_nrfx_configure+0xea>
	switch (baudrate) {
    dc44:	f647 2712 	movw	r7, #31250	; 0x7a12
    dc48:	42bb      	cmp	r3, r7
    dc4a:	d1e2      	bne.n	dc12 <uarte_nrfx_configure+0x56>
		nrf_baudrate = NRF_UARTE_BAUDRATE_31250;
    dc4c:	f44f 0300 	mov.w	r3, #8388608	; 0x800000
    dc50:	e029      	b.n	dca6 <uarte_nrfx_configure+0xea>
	switch (baudrate) {
    dc52:	f5b3 3f61 	cmp.w	r3, #230400	; 0x38400
    dc56:	d048      	beq.n	dcea <uarte_nrfx_configure+0x12e>
    dc58:	d813      	bhi.n	dc82 <uarte_nrfx_configure+0xc6>
    dc5a:	f5b3 3f96 	cmp.w	r3, #76800	; 0x12c00
    dc5e:	d047      	beq.n	dcf0 <uarte_nrfx_configure+0x134>
    dc60:	d809      	bhi.n	dc76 <uarte_nrfx_configure+0xba>
    dc62:	f64d 27c0 	movw	r7, #56000	; 0xdac0
    dc66:	42bb      	cmp	r3, r7
    dc68:	d044      	beq.n	dcf4 <uarte_nrfx_configure+0x138>
    dc6a:	f5b3 4f61 	cmp.w	r3, #57600	; 0xe100
    dc6e:	d1d0      	bne.n	dc12 <uarte_nrfx_configure+0x56>
		nrf_baudrate = NRF_UARTE_BAUDRATE_57600;
    dc70:	f44f 036b 	mov.w	r3, #15400960	; 0xeb0000
    dc74:	e017      	b.n	dca6 <uarte_nrfx_configure+0xea>
	switch (baudrate) {
    dc76:	f5b3 3fe1 	cmp.w	r3, #115200	; 0x1c200
    dc7a:	d1ca      	bne.n	dc12 <uarte_nrfx_configure+0x56>
		nrf_baudrate = NRF_UARTE_BAUDRATE_115200;
    dc7c:	f04f 73eb 	mov.w	r3, #30801920	; 0x1d60000
    dc80:	e011      	b.n	dca6 <uarte_nrfx_configure+0xea>
	switch (baudrate) {
    dc82:	f5b3 2f61 	cmp.w	r3, #921600	; 0xe1000
    dc86:	d038      	beq.n	dcfa <uarte_nrfx_configure+0x13e>
    dc88:	d808      	bhi.n	dc9c <uarte_nrfx_configure+0xe0>
    dc8a:	4f21      	ldr	r7, [pc, #132]	; (dd10 <uarte_nrfx_configure+0x154>)
    dc8c:	42bb      	cmp	r3, r7
    dc8e:	d037      	beq.n	dd00 <uarte_nrfx_configure+0x144>
    dc90:	f5b3 2fe1 	cmp.w	r3, #460800	; 0x70800
    dc94:	d1bd      	bne.n	dc12 <uarte_nrfx_configure+0x56>
		nrf_baudrate = NRF_UARTE_BAUDRATE_460800;
    dc96:	f04f 63e8 	mov.w	r3, #121634816	; 0x7400000
    dc9a:	e004      	b.n	dca6 <uarte_nrfx_configure+0xea>
	switch (baudrate) {
    dc9c:	4f1d      	ldr	r7, [pc, #116]	; (dd14 <uarte_nrfx_configure+0x158>)
    dc9e:	42bb      	cmp	r3, r7
    dca0:	d1b7      	bne.n	dc12 <uarte_nrfx_configure+0x56>
		nrf_baudrate = NRF_UARTE_BAUDRATE_1000000;
    dca2:	f04f 5380 	mov.w	r3, #268435456	; 0x10000000
                    | (uint32_t)p_cfg->hwfc;
}

NRF_STATIC_INLINE void nrf_uarte_baudrate_set(NRF_UARTE_Type * p_reg, nrf_uarte_baudrate_t baudrate)
{
    p_reg->BAUDRATE = baudrate;
    dca6:	f8c5 3524 	str.w	r3, [r5, #1316]	; 0x524
		return -ENOTSUP;
	}

	nrf_uarte_configure(get_uarte_instance(dev), &uarte_cfg);

	get_dev_data(dev)->uart_config = *cfg;
    dcaa:	68c3      	ldr	r3, [r0, #12]
                    | (uint32_t)p_cfg->hwfc;
    dcac:	4334      	orrs	r4, r6
    dcae:	4322      	orrs	r2, r4
    dcb0:	3304      	adds	r3, #4
    dcb2:	c903      	ldmia	r1, {r0, r1}
    p_reg->CONFIG = (uint32_t)p_cfg->parity
    dcb4:	f8c5 256c 	str.w	r2, [r5, #1388]	; 0x56c
    dcb8:	e883 0003 	stmia.w	r3, {r0, r1}

	return 0;
    dcbc:	2000      	movs	r0, #0
}
    dcbe:	bdf0      	pop	{r4, r5, r6, r7, pc}
		nrf_baudrate = NRF_UARTE_BAUDRATE_38400;
    dcc0:	f44f 031d 	mov.w	r3, #10289152	; 0x9d0000
    dcc4:	e7ef      	b.n	dca6 <uarte_nrfx_configure+0xea>
		nrf_baudrate = NRF_UARTE_BAUDRATE_9600;
    dcc6:	4b14      	ldr	r3, [pc, #80]	; (dd18 <uarte_nrfx_configure+0x15c>)
    dcc8:	e7ed      	b.n	dca6 <uarte_nrfx_configure+0xea>
		nrf_baudrate = NRF_UARTE_BAUDRATE_1200;
    dcca:	f44f 239e 	mov.w	r3, #323584	; 0x4f000
    dcce:	e7ea      	b.n	dca6 <uarte_nrfx_configure+0xea>
		nrf_baudrate = 0x00014000;
    dcd0:	f44f 33a0 	mov.w	r3, #81920	; 0x14000
    dcd4:	e7e7      	b.n	dca6 <uarte_nrfx_configure+0xea>
	switch (baudrate) {
    dcd6:	f44f 331c 	mov.w	r3, #159744	; 0x27000
    dcda:	e7e4      	b.n	dca6 <uarte_nrfx_configure+0xea>
		nrf_baudrate = NRF_UARTE_BAUDRATE_2400;
    dcdc:	f44f 231d 	mov.w	r3, #643072	; 0x9d000
    dce0:	e7e1      	b.n	dca6 <uarte_nrfx_configure+0xea>
		nrf_baudrate = NRF_UARTE_BAUDRATE_28800;
    dce2:	4b0e      	ldr	r3, [pc, #56]	; (dd1c <uarte_nrfx_configure+0x160>)
    dce4:	e7df      	b.n	dca6 <uarte_nrfx_configure+0xea>
		nrf_baudrate = NRF_UARTE_BAUDRATE_14400;
    dce6:	4b0e      	ldr	r3, [pc, #56]	; (dd20 <uarte_nrfx_configure+0x164>)
    dce8:	e7dd      	b.n	dca6 <uarte_nrfx_configure+0xea>
		nrf_baudrate = NRF_UARTE_BAUDRATE_230400;
    dcea:	f04f 736c 	mov.w	r3, #61865984	; 0x3b00000
    dcee:	e7da      	b.n	dca6 <uarte_nrfx_configure+0xea>
		nrf_baudrate = NRF_UARTE_BAUDRATE_76800;
    dcf0:	4b0c      	ldr	r3, [pc, #48]	; (dd24 <uarte_nrfx_configure+0x168>)
    dcf2:	e7d8      	b.n	dca6 <uarte_nrfx_configure+0xea>
		nrf_baudrate = NRF_UARTE_BAUDRATE_56000;
    dcf4:	f44f 0365 	mov.w	r3, #15007744	; 0xe50000
    dcf8:	e7d5      	b.n	dca6 <uarte_nrfx_configure+0xea>
		nrf_baudrate = NRF_UARTE_BAUDRATE_921600;
    dcfa:	f04f 6370 	mov.w	r3, #251658240	; 0xf000000
    dcfe:	e7d2      	b.n	dca6 <uarte_nrfx_configure+0xea>
		nrf_baudrate = NRF_UARTE_BAUDRATE_250000;
    dd00:	f04f 6380 	mov.w	r3, #67108864	; 0x4000000
    dd04:	e7cf      	b.n	dca6 <uarte_nrfx_configure+0xea>
    dd06:	bf00      	nop
    dd08:	0013b000 	.word	0x0013b000
    dd0c:	004ea000 	.word	0x004ea000
    dd10:	0003d090 	.word	0x0003d090
    dd14:	000f4240 	.word	0x000f4240
    dd18:	00275000 	.word	0x00275000
    dd1c:	0075c000 	.word	0x0075c000
    dd20:	003af000 	.word	0x003af000
    dd24:	013a9000 	.word	0x013a9000

0000dd28 <uarte_instance_init.isra.0>:
	.irq_update		= uarte_nrfx_irq_update,
	.irq_callback_set	= uarte_nrfx_irq_callback_set,
#endif /* UARTE_INTERRUPT_DRIVEN */
};

static int uarte_instance_init(const struct device *dev,
    dd28:	b5f8      	push	{r3, r4, r5, r6, r7, lr}

	nrf_uarte_disable(uarte);

	data->dev = dev;

	nrf_gpio_pin_write(config->pseltxd, 1);
    dd2a:	680f      	ldr	r7, [r1, #0]
static int uarte_instance_init(const struct device *dev,
    dd2c:	460d      	mov	r5, r1
    nrf_gpio_port_out_set(reg, 1UL << pin_number);
    dd2e:	2101      	movs	r1, #1
    p_reg->ENABLE = UARTE_ENABLE_ENABLE_Disabled;
    dd30:	f04f 0c00 	mov.w	ip, #0
	return config->uarte_regs;
    dd34:	6843      	ldr	r3, [r0, #4]
	struct uarte_nrfx_data *data = get_dev_data(dev);
    dd36:	68c6      	ldr	r6, [r0, #12]
	return config->uarte_regs;
    dd38:	681c      	ldr	r4, [r3, #0]
    *p_pin = pin_number & 0x1F;
    dd3a:	f007 021f 	and.w	r2, r7, #31
    p_reg->OUTSET = set_mask;
    dd3e:	4b25      	ldr	r3, [pc, #148]	; (ddd4 <uarte_instance_init.isra.0+0xac>)
    nrf_gpio_port_out_set(reg, 1UL << pin_number);
    dd40:	4091      	lsls	r1, r2
    dd42:	f8c4 c500 	str.w	ip, [r4, #1280]	; 0x500
	data->dev = dev;
    dd46:	6030      	str	r0, [r6, #0]
    p_reg->OUTSET = set_mask;
    dd48:	6099      	str	r1, [r3, #8]
    reg->PIN_CNF[pin_number] = ((uint32_t)dir << GPIO_PIN_CNF_DIR_Pos)
    dd4a:	2103      	movs	r1, #3
    dd4c:	3280      	adds	r2, #128	; 0x80
    dd4e:	f843 1022 	str.w	r1, [r3, r2, lsl #2]
	nrf_gpio_cfg_output(config->pseltxd);

	if (config->pselrxd !=  NRF_UARTE_PSEL_DISCONNECTED) {
    dd52:	686a      	ldr	r2, [r5, #4]
    dd54:	1c51      	adds	r1, r2, #1
    *p_pin = pin_number & 0x1F;
    dd56:	bf1e      	ittt	ne
    dd58:	f002 011f 	andne.w	r1, r2, #31
    reg->PIN_CNF[pin_number] = ((uint32_t)dir << GPIO_PIN_CNF_DIR_Pos)
    dd5c:	3180      	addne	r1, #128	; 0x80
    dd5e:	f843 c021 	strne.w	ip, [r3, r1, lsl #2]
		nrf_gpio_cfg_input(config->pselrxd, NRF_GPIO_PIN_NOPULL);
	}

	nrf_uarte_txrx_pins_set(uarte, config->pseltxd, config->pselrxd);

	if (config->pselcts != NRF_UARTE_PSEL_DISCONNECTED) {
    dd62:	68a9      	ldr	r1, [r5, #8]
    p_reg->PSEL.TXD = pseltxd;
    dd64:	f8c4 750c 	str.w	r7, [r4, #1292]	; 0x50c
    dd68:	1c4f      	adds	r7, r1, #1
    dd6a:	bf18      	it	ne
    dd6c:	2700      	movne	r7, #0
    p_reg->PSEL.RXD = pselrxd;
    dd6e:	f8c4 2514 	str.w	r2, [r4, #1300]	; 0x514
    *p_pin = pin_number & 0x1F;
    dd72:	bf1e      	ittt	ne
    dd74:	f001 021f 	andne.w	r2, r1, #31
    reg->PIN_CNF[pin_number] = ((uint32_t)dir << GPIO_PIN_CNF_DIR_Pos)
    dd78:	3280      	addne	r2, #128	; 0x80
    dd7a:	f843 7022 	strne.w	r7, [r3, r2, lsl #2]
		nrf_gpio_cfg_input(config->pselcts, NRF_GPIO_PIN_NOPULL);
	}

	if (config->pselrts != NRF_UARTE_PSEL_DISCONNECTED) {
    dd7e:	68ef      	ldr	r7, [r5, #12]
    dd80:	1c7a      	adds	r2, r7, #1
    dd82:	d00c      	beq.n	dd9e <uarte_instance_init.isra.0+0x76>
    nrf_gpio_port_out_set(reg, 1UL << pin_number);
    dd84:	f04f 0c01 	mov.w	ip, #1
    *p_pin = pin_number & 0x1F;
    dd88:	f007 021f 	and.w	r2, r7, #31
    nrf_gpio_port_out_set(reg, 1UL << pin_number);
    dd8c:	fa0c fc02 	lsl.w	ip, ip, r2
    p_reg->OUTSET = set_mask;
    dd90:	f8c3 c008 	str.w	ip, [r3, #8]
    reg->PIN_CNF[pin_number] = ((uint32_t)dir << GPIO_PIN_CNF_DIR_Pos)
    dd94:	f04f 0c03 	mov.w	ip, #3
    dd98:	3280      	adds	r2, #128	; 0x80
    dd9a:	f843 c022 	str.w	ip, [r3, r2, lsl #2]
    p_reg->PSEL.RTS = pselrts;
    dd9e:	f8c4 7508 	str.w	r7, [r4, #1288]	; 0x508
    p_reg->PSEL.CTS = pselcts;
    dda2:	f8c4 1510 	str.w	r1, [r4, #1296]	; 0x510
		nrf_gpio_cfg_output(config->pselrts);
	}

	nrf_uarte_hwfc_pins_set(uarte, config->pselrts, config->pselcts);

	err = uarte_nrfx_configure(dev, &get_dev_data(dev)->uart_config);
    dda6:	68c1      	ldr	r1, [r0, #12]
    dda8:	3104      	adds	r1, #4
    ddaa:	f7ff ff07 	bl	dbbc <uarte_nrfx_configure>
	if (err) {
    ddae:	b980      	cbnz	r0, ddd2 <uarte_instance_init.isra.0+0xaa>
    p_reg->ENABLE = UARTE_ENABLE_ENABLE_Enabled;
    ddb0:	2308      	movs	r3, #8
    ddb2:	f8c4 3500 	str.w	r3, [r4, #1280]	; 0x500
	}
#endif
	/* Enable receiver and transmitter */
	nrf_uarte_enable(uarte);

	if (config->pselrxd != NRF_UARTE_PSEL_DISCONNECTED) {
    ddb6:	686b      	ldr	r3, [r5, #4]
    ddb8:	3301      	adds	r3, #1
    ddba:	d00a      	beq.n	ddd2 <uarte_instance_init.isra.0+0xaa>
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0x0UL;
    ddbc:	f8c4 0110 	str.w	r0, [r4, #272]	; 0x110
    ddc0:	f8d4 3110 	ldr.w	r3, [r4, #272]	; 0x110
NRF_STATIC_INLINE void nrf_uarte_rx_buffer_set(NRF_UARTE_Type * p_reg,
                                               uint8_t *        p_buffer,
                                               size_t           length)
{
    p_reg->RXD.PTR    = (uint32_t)p_buffer;
    p_reg->RXD.MAXCNT = length;
    ddc4:	2301      	movs	r3, #1
		nrf_uarte_event_clear(uarte, NRF_UARTE_EVENT_ENDRX);

		nrf_uarte_rx_buffer_set(uarte, &data->rx_data, 1);
    ddc6:	3610      	adds	r6, #16
    p_reg->RXD.PTR    = (uint32_t)p_buffer;
    ddc8:	f8c4 6534 	str.w	r6, [r4, #1332]	; 0x534
    p_reg->RXD.MAXCNT = length;
    ddcc:	f8c4 3538 	str.w	r3, [r4, #1336]	; 0x538
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)task)) = 0x1UL;
    ddd0:	6023      	str	r3, [r4, #0]
		/* switch off transmitter to save an energy */
		nrf_uarte_task_trigger(uarte, NRF_UARTE_TASK_STOPTX);
	}
#endif
	return 0;
}
    ddd2:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    ddd4:	40842500 	.word	0x40842500

0000ddd8 <uarte_0_init>:
				.tx_buffer = uarte##idx##_tx_buffer,	       \
				.tx_buff_size = sizeof(uarte##idx##_tx_buffer),\
			};))

#ifdef CONFIG_UART_0_NRF_UARTE
UART_NRF_UARTE_DEVICE(0);
    ddd8:	b530      	push	{r4, r5, lr}
    ddda:	b085      	sub	sp, #20
    dddc:	4605      	mov	r5, r0
    ddde:	466c      	mov	r4, sp
    dde0:	4b04      	ldr	r3, [pc, #16]	; (ddf4 <uarte_0_init+0x1c>)
    dde2:	cb0f      	ldmia	r3, {r0, r1, r2, r3}
    dde4:	e884 000f 	stmia.w	r4, {r0, r1, r2, r3}
    dde8:	4621      	mov	r1, r4
    ddea:	4628      	mov	r0, r5
    ddec:	f7ff ff9c 	bl	dd28 <uarte_instance_init.isra.0>
    ddf0:	b005      	add	sp, #20
    ddf2:	bd30      	pop	{r4, r5, pc}
    ddf4:	0000f9d0 	.word	0x0000f9d0

0000ddf8 <uarte_1_init>:
#endif

#ifdef CONFIG_UART_1_NRF_UARTE
UART_NRF_UARTE_DEVICE(1);
    ddf8:	b530      	push	{r4, r5, lr}
    ddfa:	b085      	sub	sp, #20
    ddfc:	4605      	mov	r5, r0
    ddfe:	466c      	mov	r4, sp
    de00:	4b04      	ldr	r3, [pc, #16]	; (de14 <uarte_1_init+0x1c>)
    de02:	cb0f      	ldmia	r3, {r0, r1, r2, r3}
    de04:	e884 000f 	stmia.w	r4, {r0, r1, r2, r3}
    de08:	4621      	mov	r1, r4
    de0a:	4628      	mov	r0, r5
    de0c:	f7ff ff8c 	bl	dd28 <uarte_instance_init.isra.0>
    de10:	b005      	add	sp, #20
    de12:	bd30      	pop	{r4, r5, pc}
    de14:	0000f9e0 	.word	0x0000f9e0

0000de18 <check_ext_api_requests>:
	}
};
#endif

static int check_ext_api_requests(const struct device *dev)
{
    de18:	e92d 43f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, lr}
	(void)dev;

	const struct fw_info_ext_api_request *ext_api_req =
			skip_ext_apis(&m_firmware_info);

	for (uint32_t i = 0; i < m_firmware_info.ext_api_request_num; i++) {
    de1c:	2500      	movs	r5, #0
			skip_ext_apis(&m_firmware_info);
    de1e:	4c21      	ldr	r4, [pc, #132]	; (dea4 <check_ext_api_requests+0x8c>)
 */
static inline const struct fw_info_ext_api *fw_info_ext_api_check(
							uint32_t ext_api_addr)
{
	const struct fw_info_ext_api *ext_api;
	const uint32_t ext_api_magic[] = {EXT_API_MAGIC};
    de20:	4e21      	ldr	r6, [pc, #132]	; (dea8 <check_ext_api_requests+0x90>)
	for (uint32_t i = 0; i < m_firmware_info.ext_api_request_num; i++) {
    de22:	f854 8c04 	ldr.w	r8, [r4, #-4]
			/* EXT_API hard requirement not met. */
			printk("ERROR: Cannot fulfill EXT_API request.\r\n");
			k_panic();
		} else {
			/* EXT_API soft requirement not met. */
			printk("WARNING: Optional EXT_API request not "
    de26:	f8df 9088 	ldr.w	r9, [pc, #136]	; deb0 <check_ext_api_requests+0x98>
{
    de2a:	b085      	sub	sp, #20
	for (uint32_t i = 0; i < m_firmware_info.ext_api_request_num; i++) {
    de2c:	45a8      	cmp	r8, r5
    de2e:	d803      	bhi.n	de38 <check_ext_api_requests+0x20>
		}
		ADVANCE_EXT_API_REQ(ext_api_req);
	}

	return 0;
}
    de30:	2000      	movs	r0, #0
    de32:	b005      	add	sp, #20
    de34:	e8bd 83f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, pc}
		if (fw_info_ext_api_check((uint32_t)*(ext_api_req->ext_api))
    de38:	6a63      	ldr	r3, [r4, #36]	; 0x24
    de3a:	e896 0007 	ldmia.w	r6, {r0, r1, r2}
    de3e:	681f      	ldr	r7, [r3, #0]
    de40:	ab01      	add	r3, sp, #4
    de42:	e883 0007 	stmia.w	r3, {r0, r1, r2}

	ext_api = (const struct fw_info_ext_api *)(ext_api_addr);
	if (memcmp(ext_api->magic, ext_api_magic, CONFIG_FW_INFO_MAGIC_LEN)
    de46:	220c      	movs	r2, #12
    de48:	4619      	mov	r1, r3
    de4a:	4638      	mov	r0, r7
    de4c:	f001 fa50 	bl	f2f0 <memcmp>
    de50:	b990      	cbnz	r0, de78 <check_ext_api_requests+0x60>
    de52:	b18f      	cbz	r7, de78 <check_ext_api_requests+0x60>
			&& ext_api_satisfies_req(*(ext_api_req->ext_api),
    de54:	6a63      	ldr	r3, [r4, #36]	; 0x24
	const uint32_t req_id = ext_api_req->request.ext_api_id;
    de56:	6921      	ldr	r1, [r4, #16]
			&& ext_api_satisfies_req(*(ext_api_req->ext_api),
    de58:	681b      	ldr	r3, [r3, #0]
	return ((ext_api->ext_api_id == req_id)
    de5a:	691a      	ldr	r2, [r3, #16]
		&& ((ext_api->ext_api_flags & req_flags) == req_flags));
    de5c:	4291      	cmp	r1, r2
    de5e:	d10b      	bne.n	de78 <check_ext_api_requests+0x60>
		&&  (ext_api->ext_api_version >= req_min_version)
    de60:	699a      	ldr	r2, [r3, #24]
	const uint32_t req_min_version = ext_api_req->request.ext_api_version;
    de62:	69a1      	ldr	r1, [r4, #24]
		&&  (ext_api->ext_api_version >= req_min_version)
    de64:	4291      	cmp	r1, r2
    de66:	d807      	bhi.n	de78 <check_ext_api_requests+0x60>
	const uint32_t req_max_version = ext_api_req->ext_api_max_version;
    de68:	69e1      	ldr	r1, [r4, #28]
		&&  (ext_api->ext_api_version <  req_max_version)
    de6a:	4291      	cmp	r1, r2
    de6c:	d904      	bls.n	de78 <check_ext_api_requests+0x60>
	const uint32_t req_flags = ext_api_req->request.ext_api_flags;
    de6e:	6962      	ldr	r2, [r4, #20]
		&& ((ext_api->ext_api_flags & req_flags) == req_flags));
    de70:	695b      	ldr	r3, [r3, #20]
    de72:	ea32 0303 	bics.w	r3, r2, r3
    de76:	d00a      	beq.n	de8e <check_ext_api_requests+0x76>
		} else if (ext_api_req->required) {
    de78:	6a27      	ldr	r7, [r4, #32]
    de7a:	b167      	cbz	r7, de96 <check_ext_api_requests+0x7e>
			printk("ERROR: Cannot fulfill EXT_API request.\r\n");
    de7c:	480b      	ldr	r0, [pc, #44]	; (deac <check_ext_api_requests+0x94>)
    de7e:	f000 ffb3 	bl	ede8 <printk>
			k_panic();
    de82:	4040      	eors	r0, r0
    de84:	f380 8811 	msr	BASEPRI, r0
    de88:	f04f 0004 	mov.w	r0, #4
    de8c:	df02      	svc	2
		ADVANCE_EXT_API_REQ(ext_api_req);
    de8e:	68e3      	ldr	r3, [r4, #12]
	for (uint32_t i = 0; i < m_firmware_info.ext_api_request_num; i++) {
    de90:	3501      	adds	r5, #1
		ADVANCE_EXT_API_REQ(ext_api_req);
    de92:	441c      	add	r4, r3
	for (uint32_t i = 0; i < m_firmware_info.ext_api_request_num; i++) {
    de94:	e7ca      	b.n	de2c <check_ext_api_requests+0x14>
			printk("WARNING: Optional EXT_API request not "
    de96:	4648      	mov	r0, r9
    de98:	f000 ffa6 	bl	ede8 <printk>
			*ext_api_req->ext_api = NULL;
    de9c:	6a63      	ldr	r3, [r4, #36]	; 0x24
    de9e:	601f      	str	r7, [r3, #0]
    dea0:	e7f5      	b.n	de8e <check_ext_api_requests+0x76>
    dea2:	bf00      	nop
    dea4:	0000c23c 	.word	0x0000c23c
    dea8:	0000f9f0 	.word	0x0000f9f0
    deac:	0000fb21 	.word	0x0000fb21
    deb0:	0000fb4a 	.word	0x0000fb4a

0000deb4 <SystemInit>:
    static bool uicr_HFXOCNT_erased(void);
#endif

void SystemCoreClockUpdate(void)
{
    SystemCoreClock = __SYSTEM_CLOCK;
    deb4:	4b01      	ldr	r3, [pc, #4]	; (debc <SystemInit+0x8>)
    deb6:	4a02      	ldr	r2, [pc, #8]	; (dec0 <SystemInit+0xc>)
    deb8:	601a      	str	r2, [r3, #0]
      __DSB();
      __ISB();
    #endif
    
    SystemCoreClockUpdate();
}
    deba:	4770      	bx	lr
    debc:	20010030 	.word	0x20010030
    dec0:	03d09000 	.word	0x03d09000

0000dec4 <nrfx_clock_init>:
nrfx_err_t nrfx_clock_init(nrfx_clock_event_handler_t event_handler)
{
    NRFX_ASSERT(event_handler);

    nrfx_err_t err_code = NRFX_SUCCESS;
    if (m_clock_cb.module_initialized)
    dec4:	4b04      	ldr	r3, [pc, #16]	; (ded8 <nrfx_clock_init+0x14>)
    dec6:	791a      	ldrb	r2, [r3, #4]
    dec8:	b922      	cbnz	r2, ded4 <nrfx_clock_init+0x10>
    {
#if NRFX_CHECK(NRFX_CLOCK_CONFIG_LF_CAL_ENABLED)
        m_clock_cb.cal_state = CAL_STATE_IDLE;
#endif
        m_clock_cb.event_handler = event_handler;
        m_clock_cb.module_initialized = true;
    deca:	2201      	movs	r2, #1
        m_clock_cb.event_handler = event_handler;
    decc:	6018      	str	r0, [r3, #0]
        m_clock_cb.module_initialized = true;
    dece:	711a      	strb	r2, [r3, #4]
    nrfx_err_t err_code = NRFX_SUCCESS;
    ded0:	4802      	ldr	r0, [pc, #8]	; (dedc <nrfx_clock_init+0x18>)
    ded2:	4770      	bx	lr
        err_code = NRFX_ERROR_ALREADY_INITIALIZED;
    ded4:	4802      	ldr	r0, [pc, #8]	; (dee0 <nrfx_clock_init+0x1c>)
#endif
    }

    NRFX_LOG_INFO("Function: %s, error code: %s.", __func__, NRFX_LOG_ERROR_STRING_GET(err_code));
    return err_code;
}
    ded6:	4770      	bx	lr
    ded8:	2001023c 	.word	0x2001023c
    dedc:	0bad0000 	.word	0x0bad0000
    dee0:	0bad000c 	.word	0x0bad000c

0000dee4 <nrfx_clock_start>:
}

void nrfx_clock_start(nrf_clock_domain_t domain)
{
    NRFX_ASSERT(m_clock_cb.module_initialized);
    switch (domain)
    dee4:	b110      	cbz	r0, deec <nrfx_clock_start+0x8>
    dee6:	2801      	cmp	r0, #1
    dee8:	d01e      	beq.n	df28 <nrfx_clock_start+0x44>
    deea:	4770      	bx	lr
                    (nrf_clock_lfclk_t)((p_reg->LFCLKSTAT & CLOCK_LFCLKSTAT_SRC_Msk)
    deec:	4b13      	ldr	r3, [pc, #76]	; (df3c <nrfx_clock_start+0x58>)
    deee:	f8d3 2418 	ldr.w	r2, [r3, #1048]	; 0x418
            if ((p_reg->LFCLKSTAT & CLOCK_LFCLKSTAT_STATE_Msk)
    def2:	f8d3 1418 	ldr.w	r1, [r3, #1048]	; 0x418
    def6:	f411 3f80 	tst.w	r1, #65536	; 0x10000
    defa:	4619      	mov	r1, r3
    defc:	d010      	beq.n	df20 <nrfx_clock_start+0x3c>
    {
        case NRF_CLOCK_DOMAIN_LFCLK:
#if NRFX_CHECK(NRFX_CLOCK_CONFIG_LFXO_TWO_STAGE_ENABLED)
            {
                nrf_clock_lfclk_t lfclksrc;
                if (nrf_clock_is_running(NRF_CLOCK, NRF_CLOCK_DOMAIN_LFCLK, &lfclksrc) &&
    defe:	f002 0203 	and.w	r2, r2, #3
    df02:	2a02      	cmp	r2, #2
    df04:	d10c      	bne.n	df20 <nrfx_clock_start+0x3c>
    p_reg->LFCLKSRC = (uint32_t)(source);
    df06:	f8c3 2518 	str.w	r2, [r3, #1304]	; 0x518
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0x0UL;
    df0a:	2200      	movs	r2, #0
    df0c:	4b0c      	ldr	r3, [pc, #48]	; (df40 <nrfx_clock_start+0x5c>)
    df0e:	601a      	str	r2, [r3, #0]
    p_reg->INTENSET = mask;
    df10:	2202      	movs	r2, #2
    df12:	681b      	ldr	r3, [r3, #0]
    df14:	4b09      	ldr	r3, [pc, #36]	; (df3c <nrfx_clock_start+0x58>)
    df16:	f8c3 2304 	str.w	r2, [r3, #772]	; 0x304
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)task)) = 0x1UL;
    df1a:	2201      	movs	r2, #1
    df1c:	609a      	str	r2, [r3, #8]
}
    df1e:	4770      	bx	lr
    p_reg->LFCLKSRC = (uint32_t)(source);
    df20:	2301      	movs	r3, #1
    df22:	f8c1 3518 	str.w	r3, [r1, #1304]	; 0x518
}
    df26:	e7f0      	b.n	df0a <nrfx_clock_start+0x26>
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0x0UL;
    df28:	2200      	movs	r2, #0
    df2a:	4b06      	ldr	r3, [pc, #24]	; (df44 <nrfx_clock_start+0x60>)
    df2c:	601a      	str	r2, [r3, #0]
    df2e:	681b      	ldr	r3, [r3, #0]
    p_reg->INTENSET = mask;
    df30:	4b02      	ldr	r3, [pc, #8]	; (df3c <nrfx_clock_start+0x58>)
    df32:	f8c3 0304 	str.w	r0, [r3, #772]	; 0x304
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)task)) = 0x1UL;
    df36:	6018      	str	r0, [r3, #0]
#endif
        default:
            NRFX_ASSERT(0);
            break;
    }
}
    df38:	4770      	bx	lr
    df3a:	bf00      	nop
    df3c:	40005000 	.word	0x40005000
    df40:	40005104 	.word	0x40005104
    df44:	40005100 	.word	0x40005100

0000df48 <nrfx_clock_stop>:

void nrfx_clock_stop(nrf_clock_domain_t domain)
{
    df48:	b538      	push	{r3, r4, r5, lr}
    NRFX_ASSERT(m_clock_cb.module_initialized);
    switch (domain)
    df4a:	b110      	cbz	r0, df52 <nrfx_clock_stop+0xa>
    df4c:	2801      	cmp	r0, #1
    df4e:	d016      	beq.n	df7e <nrfx_clock_stop+0x36>
    if (domain == NRF_CLOCK_DOMAIN_HFCLK)
    {
            m_clock_cb.hfclk_started = false;
    }
#endif
}
    df50:	bd38      	pop	{r3, r4, r5, pc}
    p_reg->INTENCLR = mask;
    df52:	2202      	movs	r2, #2
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)task)) = 0x1UL;
    df54:	2101      	movs	r1, #1
    df56:	f242 7510 	movw	r5, #10000	; 0x2710
    p_reg->INTENCLR = mask;
    df5a:	4c16      	ldr	r4, [pc, #88]	; (dfb4 <nrfx_clock_stop+0x6c>)
    df5c:	f8c4 2308 	str.w	r2, [r4, #776]	; 0x308
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0x0UL;
    df60:	4a15      	ldr	r2, [pc, #84]	; (dfb8 <nrfx_clock_stop+0x70>)
    df62:	6010      	str	r0, [r2, #0]
    df64:	6812      	ldr	r2, [r2, #0]
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)task)) = 0x1UL;
    df66:	4a15      	ldr	r2, [pc, #84]	; (dfbc <nrfx_clock_stop+0x74>)
    df68:	6011      	str	r1, [r2, #0]
            if ((p_reg->LFCLKSTAT & CLOCK_LFCLKSTAT_STATE_Msk)
    df6a:	f8d4 3418 	ldr.w	r3, [r4, #1048]	; 0x418
    df6e:	03db      	lsls	r3, r3, #15
    df70:	d5ee      	bpl.n	df50 <nrfx_clock_stop+0x8>
        NRFX_WAIT_FOR(!nrfx_clock_is_running(domain, NULL), 10000, 1, stopped);
    df72:	2001      	movs	r0, #1
    df74:	f001 fad0 	bl	f518 <nrfx_busy_wait>
    df78:	3d01      	subs	r5, #1
    df7a:	d1f6      	bne.n	df6a <nrfx_clock_stop+0x22>
    df7c:	e7e8      	b.n	df50 <nrfx_clock_stop+0x8>
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0x0UL;
    df7e:	2200      	movs	r2, #0
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)task)) = 0x1UL;
    df80:	f242 7510 	movw	r5, #10000	; 0x2710
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0x0UL;
    df84:	4b0e      	ldr	r3, [pc, #56]	; (dfc0 <nrfx_clock_stop+0x78>)
    p_reg->INTENCLR = mask;
    df86:	4c0b      	ldr	r4, [pc, #44]	; (dfb4 <nrfx_clock_stop+0x6c>)
    df88:	f8c4 0308 	str.w	r0, [r4, #776]	; 0x308
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0x0UL;
    df8c:	601a      	str	r2, [r3, #0]
    df8e:	681b      	ldr	r3, [r3, #0]
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)task)) = 0x1UL;
    df90:	4b0c      	ldr	r3, [pc, #48]	; (dfc4 <nrfx_clock_stop+0x7c>)
    df92:	6018      	str	r0, [r3, #0]
                    (nrf_clock_hfclk_t)((p_reg->HFCLKSTAT & CLOCK_HFCLKSTAT_SRC_Msk)
    df94:	f8d4 340c 	ldr.w	r3, [r4, #1036]	; 0x40c
            if ((p_reg->HFCLKSTAT & CLOCK_HFCLKSTAT_STATE_Msk)
    df98:	f8d4 240c 	ldr.w	r2, [r4, #1036]	; 0x40c
                    (nrf_clock_hfclk_t)((p_reg->HFCLKSTAT & CLOCK_HFCLKSTAT_SRC_Msk)
    df9c:	f003 0301 	and.w	r3, r3, #1
            if ((p_reg->HFCLKSTAT & CLOCK_HFCLKSTAT_STATE_Msk)
    dfa0:	03d2      	lsls	r2, r2, #15
    dfa2:	d5d5      	bpl.n	df50 <nrfx_clock_stop+0x8>
        NRFX_WAIT_FOR((!nrfx_clock_is_running(domain, &clk_src) ||
    dfa4:	2b00      	cmp	r3, #0
    dfa6:	d0d3      	beq.n	df50 <nrfx_clock_stop+0x8>
    dfa8:	2001      	movs	r0, #1
    dfaa:	f001 fab5 	bl	f518 <nrfx_busy_wait>
    dfae:	3d01      	subs	r5, #1
    dfb0:	d1f0      	bne.n	df94 <nrfx_clock_stop+0x4c>
    dfb2:	e7cd      	b.n	df50 <nrfx_clock_stop+0x8>
    dfb4:	40005000 	.word	0x40005000
    dfb8:	40005104 	.word	0x40005104
    dfbc:	4000500c 	.word	0x4000500c
    dfc0:	40005100 	.word	0x40005100
    dfc4:	40005004 	.word	0x40005004

0000dfc8 <nrfx_power_clock_irq_handler>:
    return (bool)*((volatile uint32_t *)((uint8_t *)p_reg + event));
    dfc8:	4b15      	ldr	r3, [pc, #84]	; (e020 <nrfx_power_clock_irq_handler+0x58>)
    }
}
#endif

void nrfx_clock_irq_handler(void)
{
    dfca:	b510      	push	{r4, lr}
    dfcc:	681a      	ldr	r2, [r3, #0]
    if (nrf_clock_event_check(NRF_CLOCK, NRF_CLOCK_EVENT_HFCLKSTARTED))
    dfce:	b14a      	cbz	r2, dfe4 <nrfx_power_clock_irq_handler+0x1c>
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0x0UL;
    dfd0:	2000      	movs	r0, #0
    p_reg->INTENCLR = mask;
    dfd2:	2201      	movs	r2, #1
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0x0UL;
    dfd4:	6018      	str	r0, [r3, #0]
    dfd6:	681b      	ldr	r3, [r3, #0]
    p_reg->INTENCLR = mask;
    dfd8:	4b12      	ldr	r3, [pc, #72]	; (e024 <nrfx_power_clock_irq_handler+0x5c>)
    dfda:	f8c3 2308 	str.w	r2, [r3, #776]	; 0x308
        {
            m_clock_cb.hfclk_started = true;
            m_clock_cb.event_handler(NRFX_CLOCK_EVT_HFCLK_STARTED);
        }
#else
        m_clock_cb.event_handler(NRFX_CLOCK_EVT_HFCLK_STARTED);
    dfde:	4b12      	ldr	r3, [pc, #72]	; (e028 <nrfx_power_clock_irq_handler+0x60>)
    dfe0:	681b      	ldr	r3, [r3, #0]
    dfe2:	4798      	blx	r3
    return (bool)*((volatile uint32_t *)((uint8_t *)p_reg + event));
    dfe4:	4b11      	ldr	r3, [pc, #68]	; (e02c <nrfx_power_clock_irq_handler+0x64>)
    dfe6:	681a      	ldr	r2, [r3, #0]
#endif
    }
    if (nrf_clock_event_check(NRF_CLOCK, NRF_CLOCK_EVENT_LFCLKSTARTED))
    dfe8:	b182      	cbz	r2, e00c <nrfx_power_clock_irq_handler+0x44>
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0x0UL;
    dfea:	2200      	movs	r2, #0
    dfec:	601a      	str	r2, [r3, #0]
    dfee:	681b      	ldr	r3, [r3, #0]
                    (nrf_clock_lfclk_t)((p_reg->LFCLKSTAT & CLOCK_LFCLKSTAT_SRC_Msk)
    dff0:	4b0c      	ldr	r3, [pc, #48]	; (e024 <nrfx_power_clock_irq_handler+0x5c>)
    dff2:	f8d3 2418 	ldr.w	r2, [r3, #1048]	; 0x418
            if ((p_reg->LFCLKSTAT & CLOCK_LFCLKSTAT_STATE_Msk)
    dff6:	f8d3 1418 	ldr.w	r1, [r3, #1048]	; 0x418
        NRFX_LOG_DEBUG("Event: NRF_CLOCK_EVENT_LFCLKSTARTED");

#if NRFX_CHECK(NRFX_CLOCK_CONFIG_LFXO_TWO_STAGE_ENABLED)
        nrf_clock_lfclk_t lfclksrc;
        (void)nrf_clock_is_running(NRF_CLOCK, NRF_CLOCK_DOMAIN_LFCLK, &lfclksrc);
        if (lfclksrc == NRF_CLOCK_LFCLK_RC)
    dffa:	f002 0203 	and.w	r2, r2, #3
    dffe:	2a01      	cmp	r2, #1
    e000:	f04f 0102 	mov.w	r1, #2
    e004:	d103      	bne.n	e00e <nrfx_power_clock_irq_handler+0x46>
    p_reg->LFCLKSRC = (uint32_t)(source);
    e006:	f8c3 1518 	str.w	r1, [r3, #1304]	; 0x518
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)task)) = 0x1UL;
    e00a:	609a      	str	r2, [r3, #8]
        nrf_clock_int_disable(NRF_CLOCK, NRF_CLOCK_INT_HF192M_STARTED_MASK);

        m_clock_cb.event_handler(NRFX_CLOCK_EVT_HFCLK192M_STARTED);
    }
#endif
}
    e00c:	bd10      	pop	{r4, pc}
    p_reg->INTENCLR = mask;
    e00e:	f8c3 1308 	str.w	r1, [r3, #776]	; 0x308
            m_clock_cb.event_handler(NRFX_CLOCK_EVT_LFCLK_STARTED);
    e012:	4b05      	ldr	r3, [pc, #20]	; (e028 <nrfx_power_clock_irq_handler+0x60>)
    e014:	2001      	movs	r0, #1
}
    e016:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
            m_clock_cb.event_handler(NRFX_CLOCK_EVT_LFCLK_STARTED);
    e01a:	681b      	ldr	r3, [r3, #0]
    e01c:	4718      	bx	r3
    e01e:	bf00      	nop
    e020:	40005100 	.word	0x40005100
    e024:	40005000 	.word	0x40005000
    e028:	2001023c 	.word	0x2001023c
    e02c:	40005104 	.word	0x40005104

0000e030 <z_sys_init_run_level>:
 * off and the next one begins.
 *
 * @param level init level to run.
 */
void z_sys_init_run_level(int32_t level)
{
    e030:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
		/* End marker */
		__init_end,
	};
	const struct init_entry *entry;

	for (entry = levels[level]; entry < levels[level+1]; entry++) {
    e032:	4b10      	ldr	r3, [pc, #64]	; (e074 <z_sys_init_run_level+0x44>)
			/* Initialization failed.
			 * Set the init status bit so device is not declared ready.
			 */
			sys_bitfield_set_bit(
				(mem_addr_t) __device_init_status_start,
				(dev - __device_start));
    e034:	4f10      	ldr	r7, [pc, #64]	; (e078 <z_sys_init_run_level+0x48>)
	for (entry = levels[level]; entry < levels[level+1]; entry++) {
    e036:	f853 5020 	ldr.w	r5, [r3, r0, lsl #2]
    e03a:	3001      	adds	r0, #1
    e03c:	f853 6020 	ldr.w	r6, [r3, r0, lsl #2]
    e040:	42ae      	cmp	r6, r5
    e042:	d800      	bhi.n	e046 <z_sys_init_run_level+0x16>
		}
	}
}
    e044:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
		if ((entry->init(dev) != 0) && (dev != NULL)) {
    e046:	e9d5 3400 	ldrd	r3, r4, [r5]
    e04a:	4620      	mov	r0, r4
    e04c:	4798      	blx	r3
    e04e:	b170      	cbz	r0, e06e <z_sys_init_run_level+0x3e>
    e050:	b16c      	cbz	r4, e06e <z_sys_init_run_level+0x3e>

static ALWAYS_INLINE void sys_set_bit(mem_addr_t addr, unsigned int bit)
{
	uint32_t temp = *(volatile uint32_t *)addr;

	*(volatile uint32_t *)addr = temp | (1 << bit);
    e052:	2301      	movs	r3, #1
				(dev - __device_start));
    e054:	1be4      	subs	r4, r4, r7
	void sys_bitfield_set_bit(mem_addr_t addr, unsigned int bit)
{
	/* Doing memory offsets in terms of 32-bit values to prevent
	 * alignment issues
	 */
	sys_set_bit(addr + ((bit >> 5) << 2), bit & 0x1F);
    e056:	4a09      	ldr	r2, [pc, #36]	; (e07c <z_sys_init_run_level+0x4c>)
    e058:	1124      	asrs	r4, r4, #4
    e05a:	0961      	lsrs	r1, r4, #5
	uint32_t temp = *(volatile uint32_t *)addr;
    e05c:	f852 0021 	ldr.w	r0, [r2, r1, lsl #2]
	sys_set_bit(addr + ((bit >> 5) << 2), bit & 0x1F);
    e060:	f004 041f 	and.w	r4, r4, #31
	*(volatile uint32_t *)addr = temp | (1 << bit);
    e064:	fa03 f404 	lsl.w	r4, r3, r4
    e068:	4304      	orrs	r4, r0
    e06a:	f842 4021 	str.w	r4, [r2, r1, lsl #2]
	for (entry = levels[level]; entry < levels[level+1]; entry++) {
    e06e:	3508      	adds	r5, #8
    e070:	e7e6      	b.n	e040 <z_sys_init_run_level+0x10>
    e072:	bf00      	nop
    e074:	0000fac4 	.word	0x0000fac4
    e078:	2001003c 	.word	0x2001003c
    e07c:	2001008c 	.word	0x2001008c

0000e080 <z_device_ready>:

bool z_device_ready(const struct device *dev)
{
	/* Set bit indicates device failed initialization */
	return !(sys_bitfield_test_bit((mem_addr_t)__device_init_status_start,
					(dev - __device_start)));
    e080:	4b08      	ldr	r3, [pc, #32]	; (e0a4 <z_device_ready+0x24>)
    e082:	1ac0      	subs	r0, r0, r3
    e084:	1100      	asrs	r0, r0, #4
}

static ALWAYS_INLINE
	int sys_bitfield_test_bit(mem_addr_t addr, unsigned int bit)
{
	return sys_test_bit(addr + ((bit >> 5) << 2), bit & 0x1F);
    e086:	4b08      	ldr	r3, [pc, #32]	; (e0a8 <z_device_ready+0x28>)
    e088:	0942      	lsrs	r2, r0, #5
	uint32_t temp = *(volatile uint32_t *)addr;
    e08a:	f853 2022 	ldr.w	r2, [r3, r2, lsl #2]
	return temp & (1 << bit);
    e08e:	2301      	movs	r3, #1
	return sys_test_bit(addr + ((bit >> 5) << 2), bit & 0x1F);
    e090:	f000 001f 	and.w	r0, r0, #31
	return temp & (1 << bit);
    e094:	fa03 f000 	lsl.w	r0, r3, r0
	return !(sys_bitfield_test_bit((mem_addr_t)__device_init_status_start,
    e098:	4210      	tst	r0, r2
}
    e09a:	bf0c      	ite	eq
    e09c:	4618      	moveq	r0, r3
    e09e:	2000      	movne	r0, #0
    e0a0:	4770      	bx	lr
    e0a2:	bf00      	nop
    e0a4:	2001003c 	.word	0x2001003c
    e0a8:	2001008c 	.word	0x2001008c

0000e0ac <z_impl_device_get_binding>:
	for (dev = __device_start; dev != __device_end; dev++) {
    e0ac:	4911      	ldr	r1, [pc, #68]	; (e0f4 <z_impl_device_get_binding+0x48>)
{
    e0ae:	b570      	push	{r4, r5, r6, lr}
    e0b0:	4605      	mov	r5, r0
    e0b2:	460e      	mov	r6, r1
	for (dev = __device_start; dev != __device_end; dev++) {
    e0b4:	4c10      	ldr	r4, [pc, #64]	; (e0f8 <z_impl_device_get_binding+0x4c>)
    e0b6:	428c      	cmp	r4, r1
    e0b8:	d104      	bne.n	e0c4 <z_impl_device_get_binding+0x18>
	for (dev = __device_start; dev != __device_end; dev++) {
    e0ba:	4c0f      	ldr	r4, [pc, #60]	; (e0f8 <z_impl_device_get_binding+0x4c>)
    e0bc:	42b4      	cmp	r4, r6
    e0be:	d10a      	bne.n	e0d6 <z_impl_device_get_binding+0x2a>
	return NULL;
    e0c0:	2400      	movs	r4, #0
    e0c2:	e014      	b.n	e0ee <z_impl_device_get_binding+0x42>
		if (z_device_ready(dev) && (dev->name == name)) {
    e0c4:	4620      	mov	r0, r4
    e0c6:	f7ff ffdb 	bl	e080 <z_device_ready>
    e0ca:	b110      	cbz	r0, e0d2 <z_impl_device_get_binding+0x26>
    e0cc:	6823      	ldr	r3, [r4, #0]
    e0ce:	42ab      	cmp	r3, r5
    e0d0:	d00d      	beq.n	e0ee <z_impl_device_get_binding+0x42>
	for (dev = __device_start; dev != __device_end; dev++) {
    e0d2:	3410      	adds	r4, #16
    e0d4:	e7ef      	b.n	e0b6 <z_impl_device_get_binding+0xa>
		if (z_device_ready(dev) && (strcmp(name, dev->name) == 0)) {
    e0d6:	4620      	mov	r0, r4
    e0d8:	f7ff ffd2 	bl	e080 <z_device_ready>
    e0dc:	b908      	cbnz	r0, e0e2 <z_impl_device_get_binding+0x36>
	for (dev = __device_start; dev != __device_end; dev++) {
    e0de:	3410      	adds	r4, #16
    e0e0:	e7ec      	b.n	e0bc <z_impl_device_get_binding+0x10>
		if (z_device_ready(dev) && (strcmp(name, dev->name) == 0)) {
    e0e2:	4628      	mov	r0, r5
    e0e4:	6821      	ldr	r1, [r4, #0]
    e0e6:	f001 f8f7 	bl	f2d8 <strcmp>
    e0ea:	2800      	cmp	r0, #0
    e0ec:	d1f7      	bne.n	e0de <z_impl_device_get_binding+0x32>
}
    e0ee:	4620      	mov	r0, r4
    e0f0:	bd70      	pop	{r4, r5, r6, pc}
    e0f2:	bf00      	nop
    e0f4:	2001008c 	.word	0x2001008c
    e0f8:	2001003c 	.word	0x2001003c

0000e0fc <idle>:
#else
#define IDLE_YIELD_IF_COOP() do { } while (false)
#endif

void idle(void *unused1, void *unused2, void *unused3)
{
    e0fc:	b508      	push	{r3, lr}
	_kernel.idle = ticks;
    e0fe:	4d0b      	ldr	r5, [pc, #44]	; (e12c <idle+0x30>)
    e100:	f04f 0220 	mov.w	r2, #32
    e104:	f3ef 8311 	mrs	r3, BASEPRI
    e108:	f382 8811 	msr	BASEPRI, r2
    e10c:	f3bf 8f6f 	isb	sy
	int32_t ticks = z_get_next_timeout_expiry();
    e110:	f001 faf6 	bl	f700 <z_get_next_timeout_expiry>
	z_set_timeout_expiry((ticks < IDLE_THRESH) ? 1 : ticks, true);
    e114:	2101      	movs	r1, #1
	int32_t ticks = z_get_next_timeout_expiry();
    e116:	4604      	mov	r4, r0
	z_set_timeout_expiry((ticks < IDLE_THRESH) ? 1 : ticks, true);
    e118:	2802      	cmp	r0, #2
    e11a:	bfd8      	it	le
    e11c:	4608      	movle	r0, r1
    e11e:	f001 faff 	bl	f720 <z_set_timeout_expiry>
	_kernel.idle = ticks;
    e122:	622c      	str	r4, [r5, #32]
	arch_cpu_idle();
    e124:	f7ff f81c 	bl	d160 <arch_cpu_idle>
}
    e128:	e7ea      	b.n	e100 <idle+0x4>
    e12a:	bf00      	nop
    e12c:	20010244 	.word	0x20010244

0000e130 <z_bss_zero>:
 *
 * @return N/A
 */
void z_bss_zero(void)
{
	(void)memset(__bss_start, 0, __bss_end - __bss_start);
    e130:	4802      	ldr	r0, [pc, #8]	; (e13c <z_bss_zero+0xc>)
    e132:	4a03      	ldr	r2, [pc, #12]	; (e140 <z_bss_zero+0x10>)
    e134:	2100      	movs	r1, #0
    e136:	1a12      	subs	r2, r2, r0
    e138:	f001 b915 	b.w	f366 <memset>
    e13c:	20010090 	.word	0x20010090
    e140:	20010288 	.word	0x20010288

0000e144 <z_data_copy>:
 * This routine copies the data section from ROM to RAM.
 *
 * @return N/A
 */
void z_data_copy(void)
{
    e144:	b508      	push	{r3, lr}
	(void)memcpy(&__data_ram_start, &__data_rom_start,
		 __data_ram_end - __data_ram_start);
    e146:	4806      	ldr	r0, [pc, #24]	; (e160 <z_data_copy+0x1c>)
	(void)memcpy(&__data_ram_start, &__data_rom_start,
    e148:	4a06      	ldr	r2, [pc, #24]	; (e164 <z_data_copy+0x20>)
    e14a:	4907      	ldr	r1, [pc, #28]	; (e168 <z_data_copy+0x24>)
    e14c:	1a12      	subs	r2, r2, r0
    e14e:	f001 f8df 	bl	f310 <memcpy>
#else
	(void)memcpy(&_app_smem_start, &_app_smem_rom_start,
		 _app_smem_end - _app_smem_start);
#endif /* CONFIG_STACK_CANARIES */
#endif /* CONFIG_USERSPACE */
}
    e152:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
	(void)memcpy(&_ramfunc_ram_start, &_ramfunc_rom_start,
    e156:	4a05      	ldr	r2, [pc, #20]	; (e16c <z_data_copy+0x28>)
    e158:	4905      	ldr	r1, [pc, #20]	; (e170 <z_data_copy+0x2c>)
    e15a:	4806      	ldr	r0, [pc, #24]	; (e174 <z_data_copy+0x30>)
    e15c:	f001 b8d8 	b.w	f310 <memcpy>
    e160:	20010000 	.word	0x20010000
    e164:	20010090 	.word	0x20010090
    e168:	0000fbbc 	.word	0x0000fbbc
    e16c:	00000000 	.word	0x00000000
    e170:	0000fbbc 	.word	0x0000fbbc
    e174:	20010000 	.word	0x20010000

0000e178 <bg_thread_main>:
	static const unsigned int boot_delay = CONFIG_BOOT_DELAY;
#else
	static const unsigned int boot_delay;
#endif

	z_sys_post_kernel = true;
    e178:	2201      	movs	r2, #1
{
    e17a:	b508      	push	{r3, lr}
	z_sys_post_kernel = true;
    e17c:	4b0b      	ldr	r3, [pc, #44]	; (e1ac <bg_thread_main+0x34>)

	z_sys_init_run_level(_SYS_INIT_LEVEL_POST_KERNEL);
    e17e:	2002      	movs	r0, #2
	z_sys_post_kernel = true;
    e180:	701a      	strb	r2, [r3, #0]
	z_sys_init_run_level(_SYS_INIT_LEVEL_POST_KERNEL);
    e182:	f7ff ff55 	bl	e030 <z_sys_init_run_level>
		k_busy_wait(CONFIG_BOOT_DELAY * USEC_PER_MSEC);
	}

#if defined(CONFIG_BOOT_BANNER)
#ifdef BUILD_VERSION
	printk("*** Booting Zephyr OS build %s %s ***\n",
    e186:	4a0a      	ldr	r2, [pc, #40]	; (e1b0 <bg_thread_main+0x38>)
    e188:	490a      	ldr	r1, [pc, #40]	; (e1b4 <bg_thread_main+0x3c>)
    e18a:	480b      	ldr	r0, [pc, #44]	; (e1b8 <bg_thread_main+0x40>)
    e18c:	f000 fe2c 	bl	ede8 <printk>
	__do_global_ctors_aux();
	__do_init_array_aux();
#endif

	/* Final init level before app starts */
	z_sys_init_run_level(_SYS_INIT_LEVEL_APPLICATION);
    e190:	2003      	movs	r0, #3
    e192:	f7ff ff4d 	bl	e030 <z_sys_init_run_level>

	z_init_static_threads();
    e196:	f000 fc2b 	bl	e9f0 <z_init_static_threads>
	z_timestamp_main = k_cycle_get_32();
#endif

	extern void main(void);

	main();
    e19a:	f7fe f9cd 	bl	c538 <main>

	/* Mark nonessenrial since main() has no more work to do */
	z_main_thread.base.user_options &= ~K_ESSENTIAL;
    e19e:	4a07      	ldr	r2, [pc, #28]	; (e1bc <bg_thread_main+0x44>)
    e1a0:	7b13      	ldrb	r3, [r2, #12]
    e1a2:	f023 0301 	bic.w	r3, r3, #1
    e1a6:	7313      	strb	r3, [r2, #12]

#ifdef CONFIG_COVERAGE_DUMP
	/* Dump coverage data once the main() has exited. */
	gcov_coverage_dump();
#endif
} /* LCOV_EXCL_LINE ... because we just dumped final coverage data */
    e1a8:	bd08      	pop	{r3, pc}
    e1aa:	bf00      	nop
    e1ac:	20010286 	.word	0x20010286
    e1b0:	0000fb7c 	.word	0x0000fb7c
    e1b4:	0000fb7d 	.word	0x0000fb7d
    e1b8:	0000fb89 	.word	0x0000fb89
    e1bc:	20010110 	.word	0x20010110

0000e1c0 <z_cstart>:
 * cleared/zeroed.
 *
 * @return Does not return
 */
FUNC_NORETURN void z_cstart(void)
{
    e1c0:	e92d 4880 	stmdb	sp!, {r7, fp, lr}
 * @return N/A
 */
static ALWAYS_INLINE void z_arm_interrupt_stack_setup(void)
{
	uint32_t msp =
		(uint32_t)(Z_KERNEL_STACK_BUFFER(z_interrupt_stacks[0])) +
    e1c4:	4b34      	ldr	r3, [pc, #208]	; (e298 <z_cstart+0xd8>)
    e1c6:	b0a7      	sub	sp, #156	; 0x9c
	uint32_t msp =
    e1c8:	f503 6900 	add.w	r9, r3, #2048	; 0x800
  __ASM volatile ("MSR msp, %0" : : "r" (topOfMainStack) : );
    e1cc:	f389 8808 	msr	MSP, r9
  __ASM volatile ("MSR msplim, %0" : : "r" (MainStackPtrLimit));
    e1d0:	f383 880a 	msr	MSPLIM, r3
    SCB->SHPR[(((uint32_t)IRQn) & 0xFUL)-4UL] = (uint8_t)((priority << (8U - __NVIC_PRIO_BITS)) & (uint32_t)0xFFUL);
    e1d4:	2400      	movs	r4, #0
    e1d6:	23e0      	movs	r3, #224	; 0xe0
    e1d8:	4d30      	ldr	r5, [pc, #192]	; (e29c <z_cstart+0xdc>)
	stack_ptr = z_setup_new_thread(&z_main_thread, z_main_stack,
    e1da:	f04f 0b01 	mov.w	fp, #1
    e1de:	f885 3022 	strb.w	r3, [r5, #34]	; 0x22
    e1e2:	77ec      	strb	r4, [r5, #31]
    e1e4:	762c      	strb	r4, [r5, #24]
    e1e6:	766c      	strb	r4, [r5, #25]
    e1e8:	76ac      	strb	r4, [r5, #26]
#if defined(CONFIG_ARM_SECURE_FIRMWARE)
	NVIC_SetPriority(SecureFault_IRQn, _EXC_FAULT_PRIO);
#endif /* CONFIG_ARM_SECURE_FIRMWARE */

	/* Enable Usage, Mem, & Bus Faults */
	SCB->SHCSR |= SCB_SHCSR_USGFAULTENA_Msk | SCB_SHCSR_MEMFAULTENA_Msk |
    e1ea:	6a6b      	ldr	r3, [r5, #36]	; 0x24
	_kernel.ready_q.cache = &z_main_thread;
    e1ec:	4e2c      	ldr	r6, [pc, #176]	; (e2a0 <z_cstart+0xe0>)
    e1ee:	f443 23e0 	orr.w	r3, r3, #458752	; 0x70000
    e1f2:	626b      	str	r3, [r5, #36]	; 0x24

static ALWAYS_INLINE void arch_kernel_init(void)
{
	z_arm_interrupt_stack_setup();
	z_arm_exc_setup();
	z_arm_fault_init();
    e1f4:	f7ff f8fe 	bl	d3f4 <z_arm_fault_init>
	z_arm_cpu_idle_init();
    e1f8:	f7fe ffac 	bl	d154 <z_arm_cpu_idle_init>
static ALWAYS_INLINE void z_arm_clear_faults(void)
{
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
	/* Reset all faults */
	SCB->CFSR = SCB_CFSR_USGFAULTSR_Msk |
    e1fc:	f04f 33ff 	mov.w	r3, #4294967295
    e200:	62ab      	str	r3, [r5, #40]	; 0x28
		    SCB_CFSR_MEMFAULTSR_Msk |
		    SCB_CFSR_BUSFAULTSR_Msk;

	/* Clear all Hard Faults - HFSR is write-one-to-clear */
	SCB->HFSR = 0xffffffff;
    e202:	62eb      	str	r3, [r5, #44]	; 0x2c
{
	dummy_thread->base.thread_state = _THREAD_DUMMY;
#ifdef CONFIG_SCHED_CPU_MASK
	dummy_thread->base.cpu_mask = -1;
#endif
	dummy_thread->base.user_options = K_ESSENTIAL;
    e204:	f240 1301 	movw	r3, #257	; 0x101
#endif
#ifdef CONFIG_USERSPACE
	dummy_thread->mem_domain_info.mem_domain = &k_mem_domain_default;
#endif

	_current_cpu->current = dummy_thread;
    e208:	4d26      	ldr	r5, [pc, #152]	; (e2a4 <z_cstart+0xe4>)
	dummy_thread->base.user_options = K_ESSENTIAL;
    e20a:	f8ad 3024 	strh.w	r3, [sp, #36]	; 0x24
	_current_cpu->current = dummy_thread;
    e20e:	ab06      	add	r3, sp, #24
    e210:	60ab      	str	r3, [r5, #8]

	z_dummy_thread_init(&dummy_thread);
#endif

	/* perform basic hardware initialization */
	z_sys_init_run_level(_SYS_INIT_LEVEL_PRE_KERNEL_1);
    e212:	4620      	mov	r0, r4
	dummy_thread->stack_info.size = 0U;
    e214:	e9cd 4420 	strd	r4, r4, [sp, #128]	; 0x80
    e218:	f7ff ff0a 	bl	e030 <z_sys_init_run_level>
	z_sys_init_run_level(_SYS_INIT_LEVEL_PRE_KERNEL_2);
    e21c:	2001      	movs	r0, #1
    e21e:	f7ff ff07 	bl	e030 <z_sys_init_run_level>
	stack_ptr = z_setup_new_thread(&z_main_thread, z_main_stack,
    e222:	f8df a098 	ldr.w	sl, [pc, #152]	; e2bc <z_cstart+0xfc>
	z_sched_init();
    e226:	f000 fae9 	bl	e7fc <z_sched_init>
	stack_ptr = z_setup_new_thread(&z_main_thread, z_main_stack,
    e22a:	4b1f      	ldr	r3, [pc, #124]	; (e2a8 <z_cstart+0xe8>)
	_kernel.ready_q.cache = &z_main_thread;
    e22c:	626e      	str	r6, [r5, #36]	; 0x24
	stack_ptr = z_setup_new_thread(&z_main_thread, z_main_stack,
    e22e:	f44f 6280 	mov.w	r2, #1024	; 0x400
    e232:	491e      	ldr	r1, [pc, #120]	; (e2ac <z_cstart+0xec>)
    e234:	9305      	str	r3, [sp, #20]
    e236:	4630      	mov	r0, r6
    e238:	4653      	mov	r3, sl
    e23a:	e9cd 4b03 	strd	r4, fp, [sp, #12]
    e23e:	e9cd 4401 	strd	r4, r4, [sp, #4]
    e242:	9400      	str	r4, [sp, #0]
    e244:	f000 fba4 	bl	e990 <z_setup_new_thread>
	sys_trace_thread_resume(thread);
}

static inline void z_mark_thread_as_started(struct k_thread *thread)
{
	thread->base.thread_state &= ~_THREAD_PRESTART;
    e248:	7b73      	ldrb	r3, [r6, #13]
    e24a:	4680      	mov	r8, r0
    e24c:	f023 0304 	bic.w	r3, r3, #4
	z_ready_thread(&z_main_thread);
    e250:	4630      	mov	r0, r6
    e252:	7373      	strb	r3, [r6, #13]
    e254:	f001 f9b6 	bl	f5c4 <z_ready_thread>
	z_setup_new_thread(thread, stack,
    e258:	230f      	movs	r3, #15
    e25a:	4f15      	ldr	r7, [pc, #84]	; (e2b0 <z_cstart+0xf0>)
    e25c:	f44f 72a0 	mov.w	r2, #320	; 0x140
    e260:	e9cd 4302 	strd	r4, r3, [sp, #8]
    e264:	4913      	ldr	r1, [pc, #76]	; (e2b4 <z_cstart+0xf4>)
    e266:	4b14      	ldr	r3, [pc, #80]	; (e2b8 <z_cstart+0xf8>)
    e268:	4638      	mov	r0, r7
    e26a:	e9cd b404 	strd	fp, r4, [sp, #16]
    e26e:	e9cd 4400 	strd	r4, r4, [sp]
    e272:	f000 fb8d 	bl	e990 <z_setup_new_thread>
    e276:	7b7b      	ldrb	r3, [r7, #13]
	arch_switch_to_main_thread(&z_main_thread, stack_ptr, bg_thread_main);
    e278:	4652      	mov	r2, sl
    e27a:	f023 0304 	bic.w	r3, r3, #4
    e27e:	737b      	strb	r3, [r7, #13]
 * @return N/A
 */

static inline void sys_dlist_init(sys_dlist_t *list)
{
	list->head = (sys_dnode_t *)list;
    e280:	f105 0318 	add.w	r3, r5, #24
    e284:	4641      	mov	r1, r8
    e286:	4630      	mov	r0, r6
	list->tail = (sys_dnode_t *)list;
    e288:	e9c5 3306 	strd	r3, r3, [r5, #24]
		_kernel.cpus[i].idle_thread = &z_idle_threads[i];
    e28c:	60ef      	str	r7, [r5, #12]
		_kernel.cpus[i].id = i;
    e28e:	752c      	strb	r4, [r5, #20]
		_kernel.cpus[i].irq_stack =
    e290:	f8c5 9004 	str.w	r9, [r5, #4]
	arch_switch_to_main_thread(&z_main_thread, stack_ptr, bg_thread_main);
    e294:	f7fe ff44 	bl	d120 <arch_switch_to_main_thread>
	CODE_UNREACHABLE; /* LCOV_EXCL_LINE */
    e298:	200107c8 	.word	0x200107c8
    e29c:	e000ed00 	.word	0xe000ed00
    e2a0:	20010110 	.word	0x20010110
    e2a4:	20010244 	.word	0x20010244
    e2a8:	0000fbb0 	.word	0x0000fbb0
    e2ac:	20010288 	.word	0x20010288
    e2b0:	20010090 	.word	0x20010090
    e2b4:	20010688 	.word	0x20010688
    e2b8:	0000e0fd 	.word	0x0000e0fd
    e2bc:	0000e179 	.word	0x0000e179

0000e2c0 <z_reset_time_slice>:
 */
static struct k_thread *pending_current;
#endif

void z_reset_time_slice(void)
{
    e2c0:	b510      	push	{r4, lr}
	/* Add the elapsed time since the last announced tick to the
	 * slice count, as we'll see those "expired" ticks arrive in a
	 * FUTURE z_time_slice() call.
	 */
	if (slice_time != 0) {
    e2c2:	4c08      	ldr	r4, [pc, #32]	; (e2e4 <z_reset_time_slice+0x24>)
    e2c4:	6823      	ldr	r3, [r4, #0]
    e2c6:	b15b      	cbz	r3, e2e0 <z_reset_time_slice+0x20>
		_current_cpu->slice_ticks = slice_time + z_clock_elapsed();
    e2c8:	f7fe fe6a 	bl	cfa0 <z_clock_elapsed>
    e2cc:	4603      	mov	r3, r0
    e2ce:	6820      	ldr	r0, [r4, #0]
    e2d0:	4a05      	ldr	r2, [pc, #20]	; (e2e8 <z_reset_time_slice+0x28>)
    e2d2:	4403      	add	r3, r0
		z_set_timeout_expiry(slice_time, false);
    e2d4:	2100      	movs	r1, #0
	}
}
    e2d6:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
		_current_cpu->slice_ticks = slice_time + z_clock_elapsed();
    e2da:	6113      	str	r3, [r2, #16]
		z_set_timeout_expiry(slice_time, false);
    e2dc:	f001 ba20 	b.w	f720 <z_set_timeout_expiry>
}
    e2e0:	bd10      	pop	{r4, pc}
    e2e2:	bf00      	nop
    e2e4:	2001027c 	.word	0x2001027c
    e2e8:	20010244 	.word	0x20010244

0000e2ec <k_sched_time_slice_set>:

void k_sched_time_slice_set(int32_t slice, int prio)
{
    e2ec:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
    e2ee:	4605      	mov	r5, r0
    e2f0:	460c      	mov	r4, r1
    e2f2:	f04f 0320 	mov.w	r3, #32
    e2f6:	f3ef 8611 	mrs	r6, BASEPRI
    e2fa:	f383 8811 	msr	BASEPRI, r3
    e2fe:	f3bf 8f6f 	isb	sy
	LOCKED(&sched_spinlock) {
		_current_cpu->slice_ticks = 0;
    e302:	2200      	movs	r2, #0
		} else {
			return t * (to_hz / from_hz);
		}
	} else {
		if (result32) {
			return (uint32_t)((t * to_hz + off) / from_hz);
    e304:	f44f 4700 	mov.w	r7, #32768	; 0x8000
    e308:	f240 30e7 	movw	r0, #999	; 0x3e7
    e30c:	2100      	movs	r1, #0
    e30e:	4b0a      	ldr	r3, [pc, #40]	; (e338 <k_sched_time_slice_set+0x4c>)
    e310:	fbe7 0105 	umlal	r0, r1, r7, r5
    e314:	611a      	str	r2, [r3, #16]
    e316:	f44f 727a 	mov.w	r2, #1000	; 0x3e8
    e31a:	2300      	movs	r3, #0
    e31c:	f7fd ff8e 	bl	c23c <__aeabi_uldivmod>
		slice_time = k_ms_to_ticks_ceil32(slice);
    e320:	4b06      	ldr	r3, [pc, #24]	; (e33c <k_sched_time_slice_set+0x50>)
    e322:	6018      	str	r0, [r3, #0]
		slice_max_prio = prio;
    e324:	4b06      	ldr	r3, [pc, #24]	; (e340 <k_sched_time_slice_set+0x54>)
    e326:	601c      	str	r4, [r3, #0]
		z_reset_time_slice();
    e328:	f7ff ffca 	bl	e2c0 <z_reset_time_slice>
	__asm__ volatile(
    e32c:	f386 8811 	msr	BASEPRI, r6
    e330:	f3bf 8f6f 	isb	sy
	}
}
    e334:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    e336:	bf00      	nop
    e338:	20010244 	.word	0x20010244
    e33c:	2001027c 	.word	0x2001027c
    e340:	20010278 	.word	0x20010278

0000e344 <z_reschedule>:
{
#ifdef CONFIG_SMP
	_current_cpu->swap_ok = 0;
#endif

	return arch_irq_unlocked(key) && !arch_is_in_isr();
    e344:	b949      	cbnz	r1, e35a <z_reschedule+0x16>
  __ASM volatile ("MRS %0, ipsr" : "=r" (result) );
    e346:	f3ef 8005 	mrs	r0, IPSR
    e34a:	b930      	cbnz	r0, e35a <z_reschedule+0x16>
	return _kernel.ready_q.cache;
    e34c:	4b05      	ldr	r3, [pc, #20]	; (e364 <z_reschedule+0x20>)
#endif
}

void z_reschedule(struct k_spinlock *lock, k_spinlock_key_t key)
{
	if (resched(key.key) && need_swap()) {
    e34e:	6a5a      	ldr	r2, [r3, #36]	; 0x24
    e350:	689b      	ldr	r3, [r3, #8]
    e352:	429a      	cmp	r2, r3
    e354:	d001      	beq.n	e35a <z_reschedule+0x16>
	ret = arch_swap(key);
    e356:	f7fe be3d 	b.w	cfd4 <arch_swap>
    e35a:	f381 8811 	msr	BASEPRI, r1
    e35e:	f3bf 8f6f 	isb	sy
		z_swap(lock, key);
	} else {
		k_spin_unlock(lock, key);
	}
}
    e362:	4770      	bx	lr
    e364:	20010244 	.word	0x20010244

0000e368 <k_sched_lock>:
	__asm__ volatile(
    e368:	f04f 0320 	mov.w	r3, #32
    e36c:	f3ef 8111 	mrs	r1, BASEPRI
    e370:	f383 8811 	msr	BASEPRI, r3
    e374:	f3bf 8f6f 	isb	sy
{
#ifdef CONFIG_PREEMPT_ENABLED
	__ASSERT(!arch_is_in_isr(), "");
	__ASSERT(_current->base.sched_locked != 1, "");

	--_current->base.sched_locked;
    e378:	4b04      	ldr	r3, [pc, #16]	; (e38c <k_sched_lock+0x24>)
    e37a:	689a      	ldr	r2, [r3, #8]
    e37c:	7bd3      	ldrb	r3, [r2, #15]
    e37e:	3b01      	subs	r3, #1
    e380:	73d3      	strb	r3, [r2, #15]
	__asm__ volatile(
    e382:	f381 8811 	msr	BASEPRI, r1
    e386:	f3bf 8f6f 	isb	sy
void k_sched_lock(void)
{
	LOCKED(&sched_spinlock) {
		z_sched_lock();
	}
}
    e38a:	4770      	bx	lr
    e38c:	20010244 	.word	0x20010244

0000e390 <z_priq_dumb_remove>:
}

void z_priq_dumb_remove(sys_dlist_t *pq, struct k_thread *thread)
{
#if defined(CONFIG_SWAP_NONATOMIC) && defined(CONFIG_SCHED_DUMB)
	if (pq == &_kernel.ready_q.runq && thread == _current &&
    e390:	4b09      	ldr	r3, [pc, #36]	; (e3b8 <z_priq_dumb_remove+0x28>)
    e392:	f103 0228 	add.w	r2, r3, #40	; 0x28
    e396:	4282      	cmp	r2, r0
    e398:	d105      	bne.n	e3a6 <z_priq_dumb_remove+0x16>
    e39a:	689b      	ldr	r3, [r3, #8]
    e39c:	428b      	cmp	r3, r1
    e39e:	d102      	bne.n	e3a6 <z_priq_dumb_remove+0x16>
    e3a0:	7b4b      	ldrb	r3, [r1, #13]
    e3a2:	06db      	lsls	r3, r3, #27
    e3a4:	d106      	bne.n	e3b4 <z_priq_dumb_remove+0x24>
 * @return N/A
 */

static inline void sys_dlist_remove(sys_dnode_t *node)
{
	node->prev->next = node->next;
    e3a6:	e9d1 3200 	ldrd	r3, r2, [r1]
    e3aa:	6013      	str	r3, [r2, #0]
	node->next->prev = node->prev;
    e3ac:	605a      	str	r2, [r3, #4]
	node->next = NULL;
    e3ae:	2300      	movs	r3, #0
	node->prev = NULL;
    e3b0:	e9c1 3300 	strd	r3, r3, [r1]
#endif

	__ASSERT_NO_MSG(!z_is_idle_thread_object(thread));

	sys_dlist_remove(&thread->base.qnode_dlist);
}
    e3b4:	4770      	bx	lr
    e3b6:	bf00      	nop
    e3b8:	20010244 	.word	0x20010244

0000e3bc <update_cache>:
{
    e3bc:	b570      	push	{r4, r5, r6, lr}
	struct k_thread *thread = _priq_run_best(&_kernel.ready_q.runq);
    e3be:	4c10      	ldr	r4, [pc, #64]	; (e400 <update_cache+0x44>)
{
    e3c0:	4606      	mov	r6, r0
	struct k_thread *thread = _priq_run_best(&_kernel.ready_q.runq);
    e3c2:	f104 0028 	add.w	r0, r4, #40	; 0x28
    e3c6:	f001 f8f3 	bl	f5b0 <z_priq_dumb_best>
    e3ca:	4605      	mov	r5, r0
	if (_current->base.thread_state & _THREAD_ABORTING) {
    e3cc:	68a3      	ldr	r3, [r4, #8]
    e3ce:	7b59      	ldrb	r1, [r3, #13]
    e3d0:	0688      	lsls	r0, r1, #26
		_current->base.thread_state |= _THREAD_DEAD;
    e3d2:	bf44      	itt	mi
    e3d4:	f041 0108 	orrmi.w	r1, r1, #8
    e3d8:	7359      	strbmi	r1, [r3, #13]
	return thread ? thread : _current_cpu->idle_thread;
    e3da:	b905      	cbnz	r5, e3de <update_cache+0x22>
    e3dc:	68e5      	ldr	r5, [r4, #12]
	if (preempt_ok != 0) {
    e3de:	b94e      	cbnz	r6, e3f4 <update_cache+0x38>
	if (z_is_thread_prevented_from_running(_current)) {
    e3e0:	7b5a      	ldrb	r2, [r3, #13]
    e3e2:	06d2      	lsls	r2, r2, #27
    e3e4:	d106      	bne.n	e3f4 <update_cache+0x38>
	if (IS_ENABLED(CONFIG_SWAP_NONATOMIC)
    e3e6:	69aa      	ldr	r2, [r5, #24]
    e3e8:	b922      	cbnz	r2, e3f4 <update_cache+0x38>
	if (is_preempt(_current) || is_metairq(thread)) {
    e3ea:	89da      	ldrh	r2, [r3, #14]
    e3ec:	2a7f      	cmp	r2, #127	; 0x7f
    e3ee:	d901      	bls.n	e3f4 <update_cache+0x38>
		_kernel.ready_q.cache = _current;
    e3f0:	6263      	str	r3, [r4, #36]	; 0x24
}
    e3f2:	bd70      	pop	{r4, r5, r6, pc}
		if (thread != _current) {
    e3f4:	42ab      	cmp	r3, r5
    e3f6:	d001      	beq.n	e3fc <update_cache+0x40>
			z_reset_time_slice();
    e3f8:	f7ff ff62 	bl	e2c0 <z_reset_time_slice>
		_kernel.ready_q.cache = thread;
    e3fc:	6265      	str	r5, [r4, #36]	; 0x24
}
    e3fe:	e7f8      	b.n	e3f2 <update_cache+0x36>
    e400:	20010244 	.word	0x20010244

0000e404 <k_sched_unlock>:
{
    e404:	b510      	push	{r4, lr}
	__asm__ volatile(
    e406:	f04f 0320 	mov.w	r3, #32
    e40a:	f3ef 8411 	mrs	r4, BASEPRI
    e40e:	f383 8811 	msr	BASEPRI, r3
    e412:	f3bf 8f6f 	isb	sy
		++_current->base.sched_locked;
    e416:	4b08      	ldr	r3, [pc, #32]	; (e438 <k_sched_unlock+0x34>)
		update_cache(0);
    e418:	2000      	movs	r0, #0
		++_current->base.sched_locked;
    e41a:	689a      	ldr	r2, [r3, #8]
    e41c:	7bd3      	ldrb	r3, [r2, #15]
    e41e:	3301      	adds	r3, #1
    e420:	73d3      	strb	r3, [r2, #15]
		update_cache(0);
    e422:	f7ff ffcb 	bl	e3bc <update_cache>
	__asm__ volatile(
    e426:	f384 8811 	msr	BASEPRI, r4
    e42a:	f3bf 8f6f 	isb	sy
}
    e42e:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
	z_reschedule_unlocked();
    e432:	f001 b8a7 	b.w	f584 <z_reschedule_unlocked>
    e436:	bf00      	nop
    e438:	20010244 	.word	0x20010244

0000e43c <ready_thread>:
{
    e43c:	b470      	push	{r4, r5, r6}
	return !((z_is_thread_prevented_from_running(thread)) != 0 ||
    e43e:	7b43      	ldrb	r3, [r0, #13]
    e440:	06db      	lsls	r3, r3, #27
    e442:	d12a      	bne.n	e49a <ready_thread+0x5e>

int z_abort_timeout(struct _timeout *to);

static inline bool z_is_inactive_timeout(struct _timeout *t)
{
	return !sys_dnode_is_linked(&t->node);
    e444:	6983      	ldr	r3, [r0, #24]
	if (z_is_thread_ready(thread)) {
    e446:	bb43      	cbnz	r3, e49a <ready_thread+0x5e>
	return list->head == list;
    e448:	4a15      	ldr	r2, [pc, #84]	; (e4a0 <ready_thread+0x64>)
    e44a:	4611      	mov	r1, r2
    e44c:	f851 4f28 	ldr.w	r4, [r1, #40]!
	return sys_dlist_is_empty(list) ? NULL : list->head;
    e450:	428c      	cmp	r4, r1
    e452:	bf18      	it	ne
    e454:	4623      	movne	r3, r4
    e456:	2b00      	cmp	r3, #0
    e458:	bf38      	it	cc
    e45a:	2300      	movcc	r3, #0
	return (node != NULL) ? sys_dlist_peek_next_no_check(list, node) : NULL;
    e45c:	6ad4      	ldr	r4, [r2, #44]	; 0x2c
	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
    e45e:	b1b3      	cbz	r3, e48e <ready_thread+0x52>
	if (thread_1->base.prio < thread_2->base.prio) {
    e460:	f990 600e 	ldrsb.w	r6, [r0, #14]
    e464:	f993 500e 	ldrsb.w	r5, [r3, #14]
    e468:	42ae      	cmp	r6, r5
    e46a:	db03      	blt.n	e474 <ready_thread+0x38>
	return (node == list->tail) ? NULL : node->next;
    e46c:	42a3      	cmp	r3, r4
    e46e:	d00e      	beq.n	e48e <ready_thread+0x52>
    e470:	681b      	ldr	r3, [r3, #0]
    e472:	e7f4      	b.n	e45e <ready_thread+0x22>
	node->prev = successor->prev;
    e474:	685a      	ldr	r2, [r3, #4]
	node->next = successor;
    e476:	e9c0 3200 	strd	r3, r2, [r0]
	successor->prev->next = node;
    e47a:	6010      	str	r0, [r2, #0]
	successor->prev = node;
    e47c:	6058      	str	r0, [r3, #4]
	thread->base.thread_state |= states;
    e47e:	7b43      	ldrb	r3, [r0, #13]
    e480:	f063 037f 	orn	r3, r3, #127	; 0x7f
    e484:	7343      	strb	r3, [r0, #13]
}
    e486:	bc70      	pop	{r4, r5, r6}
		update_cache(0);
    e488:	2000      	movs	r0, #0
    e48a:	f7ff bf97 	b.w	e3bc <update_cache>
	node->prev = list->tail;
    e48e:	e9c0 1400 	strd	r1, r4, [r0]
	list->tail->next = node;
    e492:	6ad3      	ldr	r3, [r2, #44]	; 0x2c
    e494:	6018      	str	r0, [r3, #0]
	list->tail = node;
    e496:	62d0      	str	r0, [r2, #44]	; 0x2c
}
    e498:	e7f1      	b.n	e47e <ready_thread+0x42>
}
    e49a:	bc70      	pop	{r4, r5, r6}
    e49c:	4770      	bx	lr
    e49e:	bf00      	nop
    e4a0:	20010244 	.word	0x20010244

0000e4a4 <z_sched_start>:
{
    e4a4:	b510      	push	{r4, lr}
	__asm__ volatile(
    e4a6:	f04f 0220 	mov.w	r2, #32
    e4aa:	f3ef 8411 	mrs	r4, BASEPRI
    e4ae:	f382 8811 	msr	BASEPRI, r2
    e4b2:	f3bf 8f6f 	isb	sy
	if (z_has_thread_started(thread)) {
    e4b6:	7b42      	ldrb	r2, [r0, #13]
    e4b8:	0751      	lsls	r1, r2, #29
    e4ba:	d404      	bmi.n	e4c6 <z_sched_start+0x22>
	__asm__ volatile(
    e4bc:	f384 8811 	msr	BASEPRI, r4
    e4c0:	f3bf 8f6f 	isb	sy
}
    e4c4:	bd10      	pop	{r4, pc}
	thread->base.thread_state &= ~_THREAD_PRESTART;
    e4c6:	f022 0204 	bic.w	r2, r2, #4
    e4ca:	7342      	strb	r2, [r0, #13]
	ready_thread(thread);
    e4cc:	f7ff ffb6 	bl	e43c <ready_thread>
	z_reschedule(&sched_spinlock, key);
    e4d0:	4621      	mov	r1, r4
}
    e4d2:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
	z_reschedule(&sched_spinlock, key);
    e4d6:	4801      	ldr	r0, [pc, #4]	; (e4dc <z_sched_start+0x38>)
    e4d8:	f7ff bf34 	b.w	e344 <z_reschedule>
    e4dc:	20010287 	.word	0x20010287

0000e4e0 <move_thread_to_end_of_prio_q>:
{
    e4e0:	b570      	push	{r4, r5, r6, lr}
	if (z_is_thread_queued(thread)) {
    e4e2:	f990 300d 	ldrsb.w	r3, [r0, #13]
{
    e4e6:	4601      	mov	r1, r0
	if (z_is_thread_queued(thread)) {
    e4e8:	2b00      	cmp	r3, #0
    e4ea:	da02      	bge.n	e4f2 <move_thread_to_end_of_prio_q+0x12>
		_priq_run_remove(&_kernel.ready_q.runq, thread);
    e4ec:	4817      	ldr	r0, [pc, #92]	; (e54c <move_thread_to_end_of_prio_q+0x6c>)
    e4ee:	f7ff ff4f 	bl	e390 <z_priq_dumb_remove>
	return list->head == list;
    e4f2:	4a17      	ldr	r2, [pc, #92]	; (e550 <move_thread_to_end_of_prio_q+0x70>)
    e4f4:	4610      	mov	r0, r2
    e4f6:	f850 3f28 	ldr.w	r3, [r0, #40]!
	return (node != NULL) ? sys_dlist_peek_next_no_check(list, node) : NULL;
    e4fa:	6ad4      	ldr	r4, [r2, #44]	; 0x2c
	return sys_dlist_is_empty(list) ? NULL : list->head;
    e4fc:	4283      	cmp	r3, r0
    e4fe:	bf08      	it	eq
    e500:	2300      	moveq	r3, #0
    e502:	2b00      	cmp	r3, #0
    e504:	bf38      	it	cc
    e506:	2300      	movcc	r3, #0
	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
    e508:	b1d3      	cbz	r3, e540 <move_thread_to_end_of_prio_q+0x60>
	if (thread_1->base.prio < thread_2->base.prio) {
    e50a:	f991 600e 	ldrsb.w	r6, [r1, #14]
    e50e:	f993 500e 	ldrsb.w	r5, [r3, #14]
    e512:	42ae      	cmp	r6, r5
    e514:	db03      	blt.n	e51e <move_thread_to_end_of_prio_q+0x3e>
	return (node == list->tail) ? NULL : node->next;
    e516:	42a3      	cmp	r3, r4
    e518:	d012      	beq.n	e540 <move_thread_to_end_of_prio_q+0x60>
    e51a:	681b      	ldr	r3, [r3, #0]
    e51c:	e7f4      	b.n	e508 <move_thread_to_end_of_prio_q+0x28>
	node->prev = successor->prev;
    e51e:	6858      	ldr	r0, [r3, #4]
	node->next = successor;
    e520:	e9c1 3000 	strd	r3, r0, [r1]
	successor->prev->next = node;
    e524:	6001      	str	r1, [r0, #0]
	successor->prev = node;
    e526:	6059      	str	r1, [r3, #4]
	thread->base.thread_state |= states;
    e528:	7b4b      	ldrb	r3, [r1, #13]
	update_cache(thread == _current);
    e52a:	6890      	ldr	r0, [r2, #8]
    e52c:	f063 037f 	orn	r3, r3, #127	; 0x7f
    e530:	734b      	strb	r3, [r1, #13]
    e532:	1a43      	subs	r3, r0, r1
    e534:	4258      	negs	r0, r3
    e536:	4158      	adcs	r0, r3
}
    e538:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
	update_cache(thread == _current);
    e53c:	f7ff bf3e 	b.w	e3bc <update_cache>
	node->prev = list->tail;
    e540:	e9c1 0400 	strd	r0, r4, [r1]
	list->tail->next = node;
    e544:	6ad3      	ldr	r3, [r2, #44]	; 0x2c
    e546:	6019      	str	r1, [r3, #0]
	list->tail = node;
    e548:	62d1      	str	r1, [r2, #44]	; 0x2c
}
    e54a:	e7ed      	b.n	e528 <move_thread_to_end_of_prio_q+0x48>
    e54c:	2001026c 	.word	0x2001026c
    e550:	20010244 	.word	0x20010244

0000e554 <z_time_slice>:
{
    e554:	4601      	mov	r1, r0
    e556:	b570      	push	{r4, r5, r6, lr}
	__asm__ volatile(
    e558:	f04f 0320 	mov.w	r3, #32
    e55c:	f3ef 8411 	mrs	r4, BASEPRI
    e560:	f383 8811 	msr	BASEPRI, r3
    e564:	f3bf 8f6f 	isb	sy
	if (pending_current == _current) {
    e568:	4b16      	ldr	r3, [pc, #88]	; (e5c4 <z_time_slice+0x70>)
    e56a:	4a17      	ldr	r2, [pc, #92]	; (e5c8 <z_time_slice+0x74>)
    e56c:	6898      	ldr	r0, [r3, #8]
    e56e:	6815      	ldr	r5, [r2, #0]
    e570:	42a8      	cmp	r0, r5
    e572:	461d      	mov	r5, r3
    e574:	d106      	bne.n	e584 <z_time_slice+0x30>
			z_reset_time_slice();
    e576:	f7ff fea3 	bl	e2c0 <z_reset_time_slice>
	__asm__ volatile(
    e57a:	f384 8811 	msr	BASEPRI, r4
    e57e:	f3bf 8f6f 	isb	sy
}
    e582:	bd70      	pop	{r4, r5, r6, pc}
	pending_current = NULL;
    e584:	2600      	movs	r6, #0
    e586:	6016      	str	r6, [r2, #0]
	if (slice_time && sliceable(_current)) {
    e588:	4a10      	ldr	r2, [pc, #64]	; (e5cc <z_time_slice+0x78>)
    e58a:	6812      	ldr	r2, [r2, #0]
    e58c:	b1ba      	cbz	r2, e5be <z_time_slice+0x6a>
		&& !z_is_idle_thread_object(thread);
    e58e:	89c2      	ldrh	r2, [r0, #14]
    e590:	2a7f      	cmp	r2, #127	; 0x7f
    e592:	d814      	bhi.n	e5be <z_time_slice+0x6a>
		&& !z_is_thread_prevented_from_running(thread)
    e594:	7b42      	ldrb	r2, [r0, #13]
    e596:	06d2      	lsls	r2, r2, #27
    e598:	d111      	bne.n	e5be <z_time_slice+0x6a>
		&& !z_is_prio_higher(thread->base.prio, slice_max_prio)
    e59a:	4a0d      	ldr	r2, [pc, #52]	; (e5d0 <z_time_slice+0x7c>)
    e59c:	f990 600e 	ldrsb.w	r6, [r0, #14]
    e5a0:	6812      	ldr	r2, [r2, #0]
    e5a2:	4296      	cmp	r6, r2
    e5a4:	db0b      	blt.n	e5be <z_time_slice+0x6a>
		&& !z_is_idle_thread_object(thread);
    e5a6:	4a0b      	ldr	r2, [pc, #44]	; (e5d4 <z_time_slice+0x80>)
    e5a8:	4290      	cmp	r0, r2
    e5aa:	d008      	beq.n	e5be <z_time_slice+0x6a>
		if (ticks >= _current_cpu->slice_ticks) {
    e5ac:	691a      	ldr	r2, [r3, #16]
    e5ae:	428a      	cmp	r2, r1
    e5b0:	dc02      	bgt.n	e5b8 <z_time_slice+0x64>
			move_thread_to_end_of_prio_q(_current);
    e5b2:	f7ff ff95 	bl	e4e0 <move_thread_to_end_of_prio_q>
    e5b6:	e7de      	b.n	e576 <z_time_slice+0x22>
			_current_cpu->slice_ticks -= ticks;
    e5b8:	1a52      	subs	r2, r2, r1
    e5ba:	611a      	str	r2, [r3, #16]
    e5bc:	e7dd      	b.n	e57a <z_time_slice+0x26>
		_current_cpu->slice_ticks = 0;
    e5be:	2300      	movs	r3, #0
    e5c0:	612b      	str	r3, [r5, #16]
    e5c2:	e7da      	b.n	e57a <z_time_slice+0x26>
    e5c4:	20010244 	.word	0x20010244
    e5c8:	20010274 	.word	0x20010274
    e5cc:	2001027c 	.word	0x2001027c
    e5d0:	20010278 	.word	0x20010278
    e5d4:	20010090 	.word	0x20010090

0000e5d8 <z_impl_k_thread_suspend>:
{
    e5d8:	b570      	push	{r4, r5, r6, lr}
    e5da:	4604      	mov	r4, r0
	z_add_timeout(&th->base.timeout, z_thread_timeout, ticks);
}

static inline int z_abort_thread_timeout(struct k_thread *thread)
{
	return z_abort_timeout(&thread->base.timeout);
    e5dc:	3018      	adds	r0, #24
    e5de:	f001 f879 	bl	f6d4 <z_abort_timeout>
	__asm__ volatile(
    e5e2:	f04f 0320 	mov.w	r3, #32
    e5e6:	f3ef 8611 	mrs	r6, BASEPRI
    e5ea:	f383 8811 	msr	BASEPRI, r3
    e5ee:	f3bf 8f6f 	isb	sy
		if (z_is_thread_queued(thread)) {
    e5f2:	f994 300d 	ldrsb.w	r3, [r4, #13]
    e5f6:	2b00      	cmp	r3, #0
    e5f8:	da07      	bge.n	e60a <z_impl_k_thread_suspend+0x32>
			_priq_run_remove(&_kernel.ready_q.runq, thread);
    e5fa:	4621      	mov	r1, r4
    e5fc:	480e      	ldr	r0, [pc, #56]	; (e638 <z_impl_k_thread_suspend+0x60>)
    e5fe:	f7ff fec7 	bl	e390 <z_priq_dumb_remove>
	thread->base.thread_state &= ~states;
    e602:	7b63      	ldrb	r3, [r4, #13]
    e604:	f003 037f 	and.w	r3, r3, #127	; 0x7f
    e608:	7363      	strb	r3, [r4, #13]
		update_cache(thread == _current);
    e60a:	4d0c      	ldr	r5, [pc, #48]	; (e63c <z_impl_k_thread_suspend+0x64>)
	thread->base.thread_state |= _THREAD_SUSPENDED;
    e60c:	7b63      	ldrb	r3, [r4, #13]
    e60e:	68a8      	ldr	r0, [r5, #8]
    e610:	f043 0310 	orr.w	r3, r3, #16
    e614:	7363      	strb	r3, [r4, #13]
    e616:	1b03      	subs	r3, r0, r4
    e618:	4258      	negs	r0, r3
    e61a:	4158      	adcs	r0, r3
    e61c:	f7ff fece 	bl	e3bc <update_cache>
	__asm__ volatile(
    e620:	f386 8811 	msr	BASEPRI, r6
    e624:	f3bf 8f6f 	isb	sy
	if (thread == _current) {
    e628:	68ab      	ldr	r3, [r5, #8]
    e62a:	42a3      	cmp	r3, r4
    e62c:	d103      	bne.n	e636 <z_impl_k_thread_suspend+0x5e>
}
    e62e:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
		z_reschedule_unlocked();
    e632:	f000 bfa7 	b.w	f584 <z_reschedule_unlocked>
}
    e636:	bd70      	pop	{r4, r5, r6, pc}
    e638:	2001026c 	.word	0x2001026c
    e63c:	20010244 	.word	0x20010244

0000e640 <z_thread_single_abort>:
	if (thread->fn_abort != NULL) {
    e640:	6e03      	ldr	r3, [r0, #96]	; 0x60
{
    e642:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    e646:	4604      	mov	r4, r0
	if (thread->fn_abort != NULL) {
    e648:	b103      	cbz	r3, e64c <z_thread_single_abort+0xc>
		thread->fn_abort();
    e64a:	4798      	blx	r3
    e64c:	f104 0018 	add.w	r0, r4, #24
    e650:	f001 f840 	bl	f6d4 <z_abort_timeout>
	__asm__ volatile(
    e654:	f04f 0320 	mov.w	r3, #32
    e658:	f3ef 8611 	mrs	r6, BASEPRI
    e65c:	f383 8811 	msr	BASEPRI, r3
    e660:	f3bf 8f6f 	isb	sy
	return !((z_is_thread_prevented_from_running(thread)) != 0 ||
    e664:	7b63      	ldrb	r3, [r4, #13]
    e666:	06d8      	lsls	r0, r3, #27
    e668:	d123      	bne.n	e6b2 <z_thread_single_abort+0x72>
		if (z_is_thread_ready(thread)) {
    e66a:	69a2      	ldr	r2, [r4, #24]
    e66c:	bb0a      	cbnz	r2, e6b2 <z_thread_single_abort+0x72>
			if (z_is_thread_queued(thread)) {
    e66e:	0619      	lsls	r1, r3, #24
    e670:	d507      	bpl.n	e682 <z_thread_single_abort+0x42>
				_priq_run_remove(&_kernel.ready_q.runq,
    e672:	4621      	mov	r1, r4
    e674:	481e      	ldr	r0, [pc, #120]	; (e6f0 <z_thread_single_abort+0xb0>)
    e676:	f7ff fe8b 	bl	e390 <z_priq_dumb_remove>
	thread->base.thread_state &= ~states;
    e67a:	7b63      	ldrb	r3, [r4, #13]
    e67c:	f003 037f 	and.w	r3, r3, #127	; 0x7f
    e680:	7363      	strb	r3, [r4, #13]
			update_cache(thread == _current);
    e682:	4b1c      	ldr	r3, [pc, #112]	; (e6f4 <z_thread_single_abort+0xb4>)
    e684:	6898      	ldr	r0, [r3, #8]
    e686:	1b02      	subs	r2, r0, r4
    e688:	4250      	negs	r0, r2
    e68a:	4150      	adcs	r0, r2
    e68c:	f7ff fe96 	bl	e3bc <update_cache>
			waiter->base.pended_on = NULL;
    e690:	2700      	movs	r7, #0
		thread->base.thread_state |= mask;
    e692:	7b63      	ldrb	r3, [r4, #13]
	sys_dlist_init(&w->waitq);
}

static inline struct k_thread *z_waitq_head(_wait_q_t *w)
{
	return (struct k_thread *)sys_dlist_peek_head(&w->waitq);
    e694:	f104 0830 	add.w	r8, r4, #48	; 0x30
    e698:	f043 0308 	orr.w	r3, r3, #8
    e69c:	7363      	strb	r3, [r4, #13]
	return list->head == list;
    e69e:	6b25      	ldr	r5, [r4, #48]	; 0x30
	return sys_dlist_is_empty(list) ? NULL : list->head;
    e6a0:	4545      	cmp	r5, r8
    e6a2:	d000      	beq.n	e6a6 <z_thread_single_abort+0x66>
		while ((waiter = z_waitq_head(&thread->base.join_waiters)) !=
    e6a4:	b995      	cbnz	r5, e6cc <z_thread_single_abort+0x8c>
	__asm__ volatile(
    e6a6:	f386 8811 	msr	BASEPRI, r6
    e6aa:	f3bf 8f6f 	isb	sy
}
    e6ae:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
			if (z_is_thread_pending(thread)) {
    e6b2:	079b      	lsls	r3, r3, #30
    e6b4:	d5ec      	bpl.n	e690 <z_thread_single_abort+0x50>
				_priq_wait_remove(&pended_on(thread)->waitq,
    e6b6:	4621      	mov	r1, r4
    e6b8:	68a0      	ldr	r0, [r4, #8]
    e6ba:	f7ff fe69 	bl	e390 <z_priq_dumb_remove>
	thread->base.thread_state &= ~_THREAD_PENDING;
    e6be:	7b63      	ldrb	r3, [r4, #13]
    e6c0:	f023 0302 	bic.w	r3, r3, #2
    e6c4:	7363      	strb	r3, [r4, #13]
				thread->base.pended_on = NULL;
    e6c6:	2300      	movs	r3, #0
    e6c8:	60a3      	str	r3, [r4, #8]
    e6ca:	e7e1      	b.n	e690 <z_thread_single_abort+0x50>
    e6cc:	f105 0018 	add.w	r0, r5, #24
    e6d0:	f001 f800 	bl	f6d4 <z_abort_timeout>
			_priq_wait_remove(&pended_on(waiter)->waitq, waiter);
    e6d4:	68a8      	ldr	r0, [r5, #8]
    e6d6:	4629      	mov	r1, r5
    e6d8:	f7ff fe5a 	bl	e390 <z_priq_dumb_remove>
    e6dc:	7b6b      	ldrb	r3, [r5, #13]
			ready_thread(waiter);
    e6de:	4628      	mov	r0, r5
    e6e0:	f023 0302 	bic.w	r3, r3, #2
    e6e4:	736b      	strb	r3, [r5, #13]
			waiter->base.pended_on = NULL;
    e6e6:	60af      	str	r7, [r5, #8]
}

static ALWAYS_INLINE void
arch_thread_return_value_set(struct k_thread *thread, unsigned int value)
{
	thread->arch.swap_return_value = value;
    e6e8:	67ef      	str	r7, [r5, #124]	; 0x7c
			ready_thread(waiter);
    e6ea:	f7ff fea7 	bl	e43c <ready_thread>
    e6ee:	e7d6      	b.n	e69e <z_thread_single_abort+0x5e>
    e6f0:	2001026c 	.word	0x2001026c
    e6f4:	20010244 	.word	0x20010244

0000e6f8 <unready_thread>:
{
    e6f8:	b508      	push	{r3, lr}
	if (z_is_thread_queued(thread)) {
    e6fa:	f990 300d 	ldrsb.w	r3, [r0, #13]
{
    e6fe:	4601      	mov	r1, r0
	if (z_is_thread_queued(thread)) {
    e700:	2b00      	cmp	r3, #0
    e702:	da06      	bge.n	e712 <unready_thread+0x1a>
		_priq_run_remove(&_kernel.ready_q.runq, thread);
    e704:	4807      	ldr	r0, [pc, #28]	; (e724 <unready_thread+0x2c>)
    e706:	f7ff fe43 	bl	e390 <z_priq_dumb_remove>
	thread->base.thread_state &= ~states;
    e70a:	7b4b      	ldrb	r3, [r1, #13]
    e70c:	f003 037f 	and.w	r3, r3, #127	; 0x7f
    e710:	734b      	strb	r3, [r1, #13]
	update_cache(thread == _current);
    e712:	4b05      	ldr	r3, [pc, #20]	; (e728 <unready_thread+0x30>)
    e714:	6898      	ldr	r0, [r3, #8]
    e716:	1a43      	subs	r3, r0, r1
    e718:	4258      	negs	r0, r3
    e71a:	4158      	adcs	r0, r3
}
    e71c:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
	update_cache(thread == _current);
    e720:	f7ff be4c 	b.w	e3bc <update_cache>
    e724:	2001026c 	.word	0x2001026c
    e728:	20010244 	.word	0x20010244

0000e72c <pend>:
{
    e72c:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    e730:	4606      	mov	r6, r0
    e732:	4614      	mov	r4, r2
    e734:	461d      	mov	r5, r3
	__asm__ volatile(
    e736:	f04f 0320 	mov.w	r3, #32
    e73a:	f3ef 8711 	mrs	r7, BASEPRI
    e73e:	f383 8811 	msr	BASEPRI, r3
    e742:	f3bf 8f6f 	isb	sy
		add_to_waitq_locked(thread, wait_q);
    e746:	f000 ff6d 	bl	f624 <add_to_waitq_locked>
	__asm__ volatile(
    e74a:	f387 8811 	msr	BASEPRI, r7
    e74e:	f3bf 8f6f 	isb	sy
	if (!K_TIMEOUT_EQ(timeout, K_FOREVER)) {
    e752:	1c6b      	adds	r3, r5, #1
    e754:	bf08      	it	eq
    e756:	f1b4 3fff 	cmpeq.w	r4, #4294967295
    e75a:	d008      	beq.n	e76e <pend+0x42>
	z_add_timeout(&th->base.timeout, z_thread_timeout, ticks);
    e75c:	4622      	mov	r2, r4
    e75e:	462b      	mov	r3, r5
    e760:	f106 0018 	add.w	r0, r6, #24
    e764:	4903      	ldr	r1, [pc, #12]	; (e774 <pend+0x48>)
}
    e766:	e8bd 41f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
    e76a:	f000 b9eb 	b.w	eb44 <z_add_timeout>
    e76e:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
    e772:	bf00      	nop
    e774:	0000f5e5 	.word	0x0000f5e5

0000e778 <z_pend_curr>:
{
    e778:	b510      	push	{r4, lr}
    e77a:	460c      	mov	r4, r1
	pending_current = _current;
    e77c:	4b06      	ldr	r3, [pc, #24]	; (e798 <z_pend_curr+0x20>)
{
    e77e:	4611      	mov	r1, r2
	pending_current = _current;
    e780:	6898      	ldr	r0, [r3, #8]
    e782:	4b06      	ldr	r3, [pc, #24]	; (e79c <z_pend_curr+0x24>)
    e784:	6018      	str	r0, [r3, #0]
	pend(_current, wait_q, timeout);
    e786:	e9dd 2302 	ldrd	r2, r3, [sp, #8]
    e78a:	f7ff ffcf 	bl	e72c <pend>
    e78e:	4620      	mov	r0, r4
}
    e790:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
    e794:	f7fe bc1e 	b.w	cfd4 <arch_swap>
    e798:	20010244 	.word	0x20010244
    e79c:	20010274 	.word	0x20010274

0000e7a0 <z_tick_sleep.part.0>:
	z_impl_k_yield();
}
#include <syscalls/k_yield_mrsh.c>
#endif

static int32_t z_tick_sleep(int32_t ticks)
    e7a0:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
    e7a2:	4605      	mov	r5, r0
#else
	ticks += _TICK_ALIGN;
	timeout = (k_ticks_t) ticks;
#endif

	expected_wakeup_time = ticks + z_tick_get_32();
    e7a4:	f000 ffd6 	bl	f754 <z_tick_get_32>
    e7a8:	182c      	adds	r4, r5, r0
	__asm__ volatile(
    e7aa:	f04f 0320 	mov.w	r3, #32
    e7ae:	f3ef 8711 	mrs	r7, BASEPRI
    e7b2:	f383 8811 	msr	BASEPRI, r3
    e7b6:	f3bf 8f6f 	isb	sy

	k_spinlock_key_t key = k_spin_lock(&sched_spinlock);

#if defined(CONFIG_TIMESLICING) && defined(CONFIG_SWAP_NONATOMIC)
	pending_current = _current;
    e7ba:	4e0d      	ldr	r6, [pc, #52]	; (e7f0 <z_tick_sleep.part.0+0x50>)
    e7bc:	4b0d      	ldr	r3, [pc, #52]	; (e7f4 <z_tick_sleep.part.0+0x54>)
    e7be:	68b0      	ldr	r0, [r6, #8]
    e7c0:	6018      	str	r0, [r3, #0]
#endif
	unready_thread(_current);
    e7c2:	f7ff ff99 	bl	e6f8 <unready_thread>
	z_add_thread_timeout(_current, timeout);
    e7c6:	68b0      	ldr	r0, [r6, #8]
    e7c8:	490b      	ldr	r1, [pc, #44]	; (e7f8 <z_tick_sleep.part.0+0x58>)
    e7ca:	462a      	mov	r2, r5
    e7cc:	17eb      	asrs	r3, r5, #31
    e7ce:	3018      	adds	r0, #24
    e7d0:	f000 f9b8 	bl	eb44 <z_add_timeout>
	z_mark_thread_as_suspended(_current);
    e7d4:	68b2      	ldr	r2, [r6, #8]
    e7d6:	4638      	mov	r0, r7
	thread->base.thread_state |= _THREAD_SUSPENDED;
    e7d8:	7b53      	ldrb	r3, [r2, #13]
    e7da:	f043 0310 	orr.w	r3, r3, #16
    e7de:	7353      	strb	r3, [r2, #13]
    e7e0:	f7fe fbf8 	bl	cfd4 <arch_swap>

	(void)z_swap(&sched_spinlock, key);

	__ASSERT(!z_is_thread_state_set(_current, _THREAD_SUSPENDED), "");

	ticks = expected_wakeup_time - z_tick_get_32();
    e7e4:	f000 ffb6 	bl	f754 <z_tick_get_32>
    e7e8:	1a20      	subs	r0, r4, r0
		return ticks;
	}
#endif

	return 0;
}
    e7ea:	ea20 70e0 	bic.w	r0, r0, r0, asr #31
    e7ee:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    e7f0:	20010244 	.word	0x20010244
    e7f4:	20010274 	.word	0x20010274
    e7f8:	0000f5e5 	.word	0x0000f5e5

0000e7fc <z_sched_init>:
	k_sched_time_slice_set(CONFIG_TIMESLICE_SIZE,
    e7fc:	2100      	movs	r1, #0
	list->head = (sys_dnode_t *)list;
    e7fe:	4b04      	ldr	r3, [pc, #16]	; (e810 <z_sched_init+0x14>)
    e800:	4608      	mov	r0, r1
    e802:	f103 0228 	add.w	r2, r3, #40	; 0x28
	list->tail = (sys_dnode_t *)list;
    e806:	e9c3 220a 	strd	r2, r2, [r3, #40]	; 0x28
    e80a:	f7ff bd6f 	b.w	e2ec <k_sched_time_slice_set>
    e80e:	bf00      	nop
    e810:	20010244 	.word	0x20010244

0000e814 <z_impl_k_yield>:
{
    e814:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	if (!z_is_idle_thread_object(_current)) {
    e816:	4c24      	ldr	r4, [pc, #144]	; (e8a8 <z_impl_k_yield+0x94>)
    e818:	4b24      	ldr	r3, [pc, #144]	; (e8ac <z_impl_k_yield+0x98>)
    e81a:	68a2      	ldr	r2, [r4, #8]
    e81c:	429a      	cmp	r2, r3
    e81e:	d030      	beq.n	e882 <z_impl_k_yield+0x6e>
    e820:	f04f 0320 	mov.w	r3, #32
    e824:	f3ef 8511 	mrs	r5, BASEPRI
    e828:	f383 8811 	msr	BASEPRI, r3
    e82c:	f3bf 8f6f 	isb	sy
				_priq_run_remove(&_kernel.ready_q.runq,
    e830:	68a1      	ldr	r1, [r4, #8]
    e832:	f104 0028 	add.w	r0, r4, #40	; 0x28
    e836:	f7ff fdab 	bl	e390 <z_priq_dumb_remove>
	return list->head == list;
    e83a:	6aa3      	ldr	r3, [r4, #40]	; 0x28
			_priq_run_add(&_kernel.ready_q.runq, _current);
    e83c:	68a2      	ldr	r2, [r4, #8]
	return sys_dlist_is_empty(list) ? NULL : list->head;
    e83e:	4283      	cmp	r3, r0
    e840:	bf08      	it	eq
    e842:	2300      	moveq	r3, #0
    e844:	2b00      	cmp	r3, #0
    e846:	bf38      	it	cc
    e848:	2300      	movcc	r3, #0
	return (node != NULL) ? sys_dlist_peek_next_no_check(list, node) : NULL;
    e84a:	6ae1      	ldr	r1, [r4, #44]	; 0x2c
	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
    e84c:	b32b      	cbz	r3, e89a <z_impl_k_yield+0x86>
	if (thread_1->base.prio < thread_2->base.prio) {
    e84e:	f992 700e 	ldrsb.w	r7, [r2, #14]
    e852:	f993 600e 	ldrsb.w	r6, [r3, #14]
    e856:	42b7      	cmp	r7, r6
    e858:	db03      	blt.n	e862 <z_impl_k_yield+0x4e>
	return (node == list->tail) ? NULL : node->next;
    e85a:	428b      	cmp	r3, r1
    e85c:	d01d      	beq.n	e89a <z_impl_k_yield+0x86>
    e85e:	681b      	ldr	r3, [r3, #0]
    e860:	e7f4      	b.n	e84c <z_impl_k_yield+0x38>
	node->prev = successor->prev;
    e862:	6859      	ldr	r1, [r3, #4]
	node->next = successor;
    e864:	e9c2 3100 	strd	r3, r1, [r2]
	successor->prev->next = node;
    e868:	600a      	str	r2, [r1, #0]
	successor->prev = node;
    e86a:	605a      	str	r2, [r3, #4]
	thread->base.thread_state |= states;
    e86c:	7b53      	ldrb	r3, [r2, #13]
			update_cache(1);
    e86e:	2001      	movs	r0, #1
    e870:	f063 037f 	orn	r3, r3, #127	; 0x7f
    e874:	7353      	strb	r3, [r2, #13]
    e876:	f7ff fda1 	bl	e3bc <update_cache>
	__asm__ volatile(
    e87a:	f385 8811 	msr	BASEPRI, r5
    e87e:	f3bf 8f6f 	isb	sy
	__asm__ volatile(
    e882:	f04f 0320 	mov.w	r3, #32
    e886:	f3ef 8011 	mrs	r0, BASEPRI
    e88a:	f383 8811 	msr	BASEPRI, r3
    e88e:	f3bf 8f6f 	isb	sy
}
    e892:	e8bd 40f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, lr}
    e896:	f7fe bb9d 	b.w	cfd4 <arch_swap>
	node->prev = list->tail;
    e89a:	e9c2 0100 	strd	r0, r1, [r2]
	list->tail->next = node;
    e89e:	6ae3      	ldr	r3, [r4, #44]	; 0x2c
    e8a0:	601a      	str	r2, [r3, #0]
	list->tail = node;
    e8a2:	62e2      	str	r2, [r4, #44]	; 0x2c
}
    e8a4:	e7e2      	b.n	e86c <z_impl_k_yield+0x58>
    e8a6:	bf00      	nop
    e8a8:	20010244 	.word	0x20010244
    e8ac:	20010090 	.word	0x20010090

0000e8b0 <z_impl_k_sleep>:

int32_t z_impl_k_sleep(k_timeout_t timeout)
{
    e8b0:	460b      	mov	r3, r1
	k_ticks_t ticks;

	__ASSERT(!arch_is_in_isr(), "");
	sys_trace_void(SYS_TRACE_ID_SLEEP);

	if (K_TIMEOUT_EQ(timeout, K_FOREVER)) {
    e8b2:	3301      	adds	r3, #1
    e8b4:	bf08      	it	eq
    e8b6:	f1b0 3fff 	cmpeq.w	r0, #4294967295
{
    e8ba:	b510      	push	{r4, lr}
	if (K_TIMEOUT_EQ(timeout, K_FOREVER)) {
    e8bc:	d106      	bne.n	e8cc <z_impl_k_sleep+0x1c>
		k_thread_suspend(_current);
    e8be:	4b0b      	ldr	r3, [pc, #44]	; (e8ec <z_impl_k_sleep+0x3c>)
    e8c0:	6898      	ldr	r0, [r3, #8]
	z_impl_k_thread_suspend(thread);
    e8c2:	f7ff fe89 	bl	e5d8 <z_impl_k_thread_suspend>
		return (int32_t) K_TICKS_FOREVER;
    e8c6:	f04f 30ff 	mov.w	r0, #4294967295
#endif

	ticks = z_tick_sleep(ticks);
	sys_trace_end_call(SYS_TRACE_ID_SLEEP);
	return k_ticks_to_ms_floor64(ticks);
}
    e8ca:	bd10      	pop	{r4, pc}
	ticks = z_tick_sleep(ticks);
    e8cc:	4604      	mov	r4, r0
	if (ticks == 0) {
    e8ce:	b948      	cbnz	r0, e8e4 <z_impl_k_sleep+0x34>
	z_impl_k_yield();
    e8d0:	f7ff ffa0 	bl	e814 <z_impl_k_yield>
		} else {
			return (t * to_hz + off) / from_hz;
    e8d4:	f44f 707a 	mov.w	r0, #1000	; 0x3e8
    e8d8:	fb84 3400 	smull	r3, r4, r4, r0
    e8dc:	0bd8      	lsrs	r0, r3, #15
    e8de:	ea40 4044 	orr.w	r0, r0, r4, lsl #17
	return k_ticks_to_ms_floor64(ticks);
    e8e2:	e7f2      	b.n	e8ca <z_impl_k_sleep+0x1a>
    e8e4:	f7ff ff5c 	bl	e7a0 <z_tick_sleep.part.0>
    e8e8:	4604      	mov	r4, r0
    e8ea:	e7f3      	b.n	e8d4 <z_impl_k_sleep+0x24>
    e8ec:	20010244 	.word	0x20010244

0000e8f0 <z_impl_k_current_get>:

#ifdef CONFIG_SMP
	arch_irq_unlock(k);
#endif
	return ret;
}
    e8f0:	4b01      	ldr	r3, [pc, #4]	; (e8f8 <z_impl_k_current_get+0x8>)
    e8f2:	6898      	ldr	r0, [r3, #8]
    e8f4:	4770      	bx	lr
    e8f6:	bf00      	nop
    e8f8:	20010244 	.word	0x20010244

0000e8fc <z_impl_k_sem_give>:
	ARG_UNUSED(sem);
#endif
}

void z_impl_k_sem_give(struct k_sem *sem)
{
    e8fc:	b538      	push	{r3, r4, r5, lr}
    e8fe:	4604      	mov	r4, r0
    e900:	f04f 0320 	mov.w	r3, #32
    e904:	f3ef 8511 	mrs	r5, BASEPRI
    e908:	f383 8811 	msr	BASEPRI, r3
    e90c:	f3bf 8f6f 	isb	sy
	k_spinlock_key_t key = k_spin_lock(&lock);
	struct k_thread *thread;

	sys_trace_semaphore_give(sem);
	thread = z_unpend_first_thread(&sem->wait_q);
    e910:	f000 feb3 	bl	f67a <z_unpend_first_thread>

	if (thread != NULL) {
    e914:	b148      	cbz	r0, e92a <z_impl_k_sem_give+0x2e>
    e916:	2200      	movs	r2, #0
    e918:	67c2      	str	r2, [r0, #124]	; 0x7c
		arch_thread_return_value_set(thread, 0);
		z_ready_thread(thread);
    e91a:	f000 fe53 	bl	f5c4 <z_ready_thread>
	} else {
		sem->count += (sem->count != sem->limit) ? 1U : 0U;
		handle_poll_events(sem);
	}

	z_reschedule(&lock, key);
    e91e:	4629      	mov	r1, r5
	sys_trace_end_call(SYS_TRACE_ID_SEMA_GIVE);
}
    e920:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
	z_reschedule(&lock, key);
    e924:	4804      	ldr	r0, [pc, #16]	; (e938 <z_impl_k_sem_give+0x3c>)
    e926:	f7ff bd0d 	b.w	e344 <z_reschedule>
		sem->count += (sem->count != sem->limit) ? 1U : 0U;
    e92a:	e9d4 3202 	ldrd	r3, r2, [r4, #8]
    e92e:	429a      	cmp	r2, r3
    e930:	bf18      	it	ne
    e932:	3301      	addne	r3, #1
    e934:	60a3      	str	r3, [r4, #8]
		handle_poll_events(sem);
    e936:	e7f2      	b.n	e91e <z_impl_k_sem_give+0x22>
    e938:	20010287 	.word	0x20010287

0000e93c <z_impl_k_sem_take>:
}
#include <syscalls/k_sem_give_mrsh.c>
#endif

int z_impl_k_sem_take(struct k_sem *sem, k_timeout_t timeout)
{
    e93c:	b537      	push	{r0, r1, r2, r4, r5, lr}
    e93e:	4614      	mov	r4, r2
    e940:	461d      	mov	r5, r3
    e942:	f04f 0320 	mov.w	r3, #32
    e946:	f3ef 8111 	mrs	r1, BASEPRI
    e94a:	f383 8811 	msr	BASEPRI, r3
    e94e:	f3bf 8f6f 	isb	sy
		  K_TIMEOUT_EQ(timeout, K_NO_WAIT)), "");

	k_spinlock_key_t key = k_spin_lock(&lock);
	sys_trace_semaphore_take(sem);

	if (likely(sem->count > 0U)) {
    e952:	6883      	ldr	r3, [r0, #8]
    e954:	b143      	cbz	r3, e968 <z_impl_k_sem_take+0x2c>
		sem->count--;
    e956:	3b01      	subs	r3, #1
    e958:	6083      	str	r3, [r0, #8]
	__asm__ volatile(
    e95a:	f381 8811 	msr	BASEPRI, r1
    e95e:	f3bf 8f6f 	isb	sy
		k_spin_unlock(&lock, key);
		ret = 0;
    e962:	2000      	movs	r0, #0
	ret = z_pend_curr(&lock, key, &sem->wait_q, timeout);

out:
	sys_trace_end_call(SYS_TRACE_ID_SEMA_TAKE);
	return ret;
}
    e964:	b003      	add	sp, #12
    e966:	bd30      	pop	{r4, r5, pc}
	if (K_TIMEOUT_EQ(timeout, K_NO_WAIT)) {
    e968:	ea54 0305 	orrs.w	r3, r4, r5
    e96c:	d106      	bne.n	e97c <z_impl_k_sem_take+0x40>
    e96e:	f381 8811 	msr	BASEPRI, r1
    e972:	f3bf 8f6f 	isb	sy
		ret = -EBUSY;
    e976:	f06f 000f 	mvn.w	r0, #15
    e97a:	e7f3      	b.n	e964 <z_impl_k_sem_take+0x28>
	ret = z_pend_curr(&lock, key, &sem->wait_q, timeout);
    e97c:	4602      	mov	r2, r0
    e97e:	e9cd 4500 	strd	r4, r5, [sp]
    e982:	4802      	ldr	r0, [pc, #8]	; (e98c <z_impl_k_sem_take+0x50>)
    e984:	f7ff fef8 	bl	e778 <z_pend_curr>
	return ret;
    e988:	e7ec      	b.n	e964 <z_impl_k_sem_take+0x28>
    e98a:	bf00      	nop
    e98c:	20010287 	.word	0x20010287

0000e990 <z_setup_new_thread>:
char *z_setup_new_thread(struct k_thread *new_thread,
			 k_thread_stack_t *stack, size_t stack_size,
			 k_thread_entry_t entry,
			 void *p1, void *p2, void *p3,
			 int prio, uint32_t options, const char *name)
{
    e990:	e92d 41ff 	stmdb	sp!, {r0, r1, r2, r3, r4, r5, r6, r7, r8, lr}
	sys_dlist_init(&w->waitq);
    e994:	f100 0530 	add.w	r5, r0, #48	; 0x30
	list->tail = (sys_dnode_t *)list;
    e998:	e9c0 550c 	strd	r5, r5, [r0, #48]	; 0x30
void z_init_thread_base(struct _thread_base *thread_base, int priority,
		       uint32_t initial_state, unsigned int options)
{
	/* k_q_node is initialized upon first insertion in a list */

	thread_base->user_options = (uint8_t)options;
    e99c:	9d0e      	ldr	r5, [sp, #56]	; 0x38
{
    e99e:	4604      	mov	r4, r0
	thread_base->user_options = (uint8_t)options;
    e9a0:	7305      	strb	r5, [r0, #12]
	thread_base->thread_state = (uint8_t)initial_state;
    e9a2:	2504      	movs	r5, #4
    e9a4:	7345      	strb	r5, [r0, #13]

	thread_base->prio = priority;
    e9a6:	9d0d      	ldr	r5, [sp, #52]	; 0x34
		stack_obj_size = Z_KERNEL_STACK_SIZE_ADJUST(stack_size);
    e9a8:	1dd6      	adds	r6, r2, #7
	thread_base->prio = priority;
    e9aa:	7385      	strb	r5, [r0, #14]

	thread_base->sched_locked = 0U;
    e9ac:	2500      	movs	r5, #0
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
    e9ae:	9a0c      	ldr	r2, [sp, #48]	; 0x30
		stack_obj_size = Z_KERNEL_STACK_SIZE_ADJUST(stack_size);
    e9b0:	f026 0607 	bic.w	r6, r6, #7
	node->prev = NULL;
    e9b4:	e9c0 5506 	strd	r5, r5, [r0, #24]
	new_thread->stack_info.size = stack_buf_size;
    e9b8:	e9c0 161a 	strd	r1, r6, [r0, #104]	; 0x68
	thread_base->sched_locked = 0U;
    e9bc:	73c5      	strb	r5, [r0, #15]
	new_thread->stack_info.delta = delta;
    e9be:	6705      	str	r5, [r0, #112]	; 0x70
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
    e9c0:	9202      	str	r2, [sp, #8]
    e9c2:	9a0b      	ldr	r2, [sp, #44]	; 0x2c
	stack_ptr = (char *)stack + stack_obj_size;
    e9c4:	eb01 0806 	add.w	r8, r1, r6
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
    e9c8:	9201      	str	r2, [sp, #4]
    e9ca:	9a0a      	ldr	r2, [sp, #40]	; 0x28
    e9cc:	9200      	str	r2, [sp, #0]
    e9ce:	4642      	mov	r2, r8
    e9d0:	f7fe fb8a 	bl	d0e8 <arch_new_thread>
	if (!_current) {
    e9d4:	4b05      	ldr	r3, [pc, #20]	; (e9ec <z_setup_new_thread+0x5c>)
	new_thread->fn_abort = NULL;
    e9d6:	e9c4 5517 	strd	r5, r5, [r4, #92]	; 0x5c
	if (!_current) {
    e9da:	689b      	ldr	r3, [r3, #8]
    e9dc:	b103      	cbz	r3, e9e0 <z_setup_new_thread+0x50>
	new_thread->resource_pool = _current->resource_pool;
    e9de:	6f5b      	ldr	r3, [r3, #116]	; 0x74
}
    e9e0:	4640      	mov	r0, r8
    e9e2:	6763      	str	r3, [r4, #116]	; 0x74
    e9e4:	b004      	add	sp, #16
    e9e6:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
    e9ea:	bf00      	nop
    e9ec:	20010244 	.word	0x20010244

0000e9f0 <z_init_static_threads>:
{
    e9f0:	e92d 47f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
	_FOREACH_STATIC_THREAD(thread_data) {
    e9f4:	4e2a      	ldr	r6, [pc, #168]	; (eaa0 <CONFIG_SYS_PM_MIN_RESIDENCY_DEEP_SLEEP_1+0x40>)
    e9f6:	4d2b      	ldr	r5, [pc, #172]	; (eaa4 <CONFIG_SYS_PM_MIN_RESIDENCY_DEEP_SLEEP_1+0x44>)
    e9f8:	46b0      	mov	r8, r6
{
    e9fa:	b086      	sub	sp, #24
	_FOREACH_STATIC_THREAD(thread_data) {
    e9fc:	42b5      	cmp	r5, r6
    e9fe:	f105 0430 	add.w	r4, r5, #48	; 0x30
    ea02:	d310      	bcc.n	ea26 <z_init_static_threads+0x36>
	k_sched_lock();
    ea04:	f7ff fcb0 	bl	e368 <k_sched_lock>
    ea08:	f44f 4900 	mov.w	r9, #32768	; 0x8000
    ea0c:	f240 36e7 	movw	r6, #999	; 0x3e7
    ea10:	2700      	movs	r7, #0
	_FOREACH_STATIC_THREAD(thread_data) {
    ea12:	4c24      	ldr	r4, [pc, #144]	; (eaa4 <CONFIG_SYS_PM_MIN_RESIDENCY_DEEP_SLEEP_1+0x44>)
    ea14:	f8df a090 	ldr.w	sl, [pc, #144]	; eaa8 <CONFIG_SYS_PM_MIN_RESIDENCY_DEEP_SLEEP_1+0x48>
    ea18:	4544      	cmp	r4, r8
    ea1a:	d321      	bcc.n	ea60 <CONFIG_SYS_PM_MIN_RESIDENCY_DEEP_SLEEP_1>
}
    ea1c:	b006      	add	sp, #24
    ea1e:	e8bd 47f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
	k_sched_unlock();
    ea22:	f7ff bcef 	b.w	e404 <k_sched_unlock>
		z_setup_new_thread(
    ea26:	f854 3c04 	ldr.w	r3, [r4, #-4]
    ea2a:	9305      	str	r3, [sp, #20]
    ea2c:	f854 3c10 	ldr.w	r3, [r4, #-16]
    ea30:	9304      	str	r3, [sp, #16]
    ea32:	f854 3c14 	ldr.w	r3, [r4, #-20]
    ea36:	9303      	str	r3, [sp, #12]
    ea38:	f854 3c18 	ldr.w	r3, [r4, #-24]
    ea3c:	9302      	str	r3, [sp, #8]
    ea3e:	f854 3c1c 	ldr.w	r3, [r4, #-28]
    ea42:	9301      	str	r3, [sp, #4]
    ea44:	f854 3c20 	ldr.w	r3, [r4, #-32]
    ea48:	9300      	str	r3, [sp, #0]
    ea4a:	e954 230a 	ldrd	r2, r3, [r4, #-40]	; 0x28
    ea4e:	e954 010c 	ldrd	r0, r1, [r4, #-48]	; 0x30
    ea52:	f7ff ff9d 	bl	e990 <z_setup_new_thread>
		thread_data->init_thread->init_data = thread_data;
    ea56:	f854 3c30 	ldr.w	r3, [r4, #-48]
    ea5a:	65dd      	str	r5, [r3, #92]	; 0x5c
    ea5c:	4625      	mov	r5, r4
    ea5e:	e7cd      	b.n	e9fc <z_init_static_threads+0xc>
		if (thread_data->init_delay != K_TICKS_FOREVER) {
    ea60:	6a63      	ldr	r3, [r4, #36]	; 0x24
    ea62:	1c5a      	adds	r2, r3, #1
    ea64:	d00d      	beq.n	ea82 <CONFIG_SYS_PM_MIN_RESIDENCY_DEEP_SLEEP_1+0x22>
    ea66:	4630      	mov	r0, r6
    ea68:	4639      	mov	r1, r7
					    K_MSEC(thread_data->init_delay));
    ea6a:	ea23 73e3 	bic.w	r3, r3, r3, asr #31
    ea6e:	fbc9 0103 	smlal	r0, r1, r9, r3
	if (K_TIMEOUT_EQ(delay, K_NO_WAIT)) {
    ea72:	42b9      	cmp	r1, r7
    ea74:	bf08      	it	eq
    ea76:	42b0      	cmpeq	r0, r6
			schedule_new_thread(thread_data->init_thread,
    ea78:	6825      	ldr	r5, [r4, #0]
	if (K_TIMEOUT_EQ(delay, K_NO_WAIT)) {
    ea7a:	d104      	bne.n	ea86 <CONFIG_SYS_PM_MIN_RESIDENCY_DEEP_SLEEP_1+0x26>
	z_sched_start(thread);
    ea7c:	4628      	mov	r0, r5
    ea7e:	f7ff fd11 	bl	e4a4 <z_sched_start>
	_FOREACH_STATIC_THREAD(thread_data) {
    ea82:	3430      	adds	r4, #48	; 0x30
    ea84:	e7c8      	b.n	ea18 <z_init_static_threads+0x28>
    ea86:	f44f 727a 	mov.w	r2, #1000	; 0x3e8
    ea8a:	2300      	movs	r3, #0
    ea8c:	f7fd fbd6 	bl	c23c <__aeabi_uldivmod>
    ea90:	4602      	mov	r2, r0
    ea92:	460b      	mov	r3, r1
    ea94:	f105 0018 	add.w	r0, r5, #24
    ea98:	4651      	mov	r1, sl
    ea9a:	f000 f853 	bl	eb44 <z_add_timeout>
    ea9e:	e7f0      	b.n	ea82 <CONFIG_SYS_PM_MIN_RESIDENCY_DEEP_SLEEP_1+0x22>
    eaa0:	20010090 	.word	0x20010090
    eaa4:	20010090 	.word	0x20010090
    eaa8:	0000f5e5 	.word	0x0000f5e5

0000eaac <elapsed>:
	sys_dlist_remove(&t->node);
}

static int32_t elapsed(void)
{
	return announce_remaining == 0 ? z_clock_elapsed() : 0;
    eaac:	4b03      	ldr	r3, [pc, #12]	; (eabc <elapsed+0x10>)
    eaae:	681b      	ldr	r3, [r3, #0]
    eab0:	b90b      	cbnz	r3, eab6 <elapsed+0xa>
    eab2:	f7fe ba75 	b.w	cfa0 <z_clock_elapsed>
}
    eab6:	2000      	movs	r0, #0
    eab8:	4770      	bx	lr
    eaba:	bf00      	nop
    eabc:	20010280 	.word	0x20010280

0000eac0 <remove_timeout>:
{
    eac0:	b530      	push	{r4, r5, lr}
    eac2:	6803      	ldr	r3, [r0, #0]
	return (node != NULL) ? sys_dlist_peek_next_no_check(list, node) : NULL;
    eac4:	b168      	cbz	r0, eae2 <remove_timeout+0x22>
    eac6:	4a0a      	ldr	r2, [pc, #40]	; (eaf0 <remove_timeout+0x30>)
	return (node == list->tail) ? NULL : node->next;
    eac8:	6852      	ldr	r2, [r2, #4]
    eaca:	4290      	cmp	r0, r2
    eacc:	d009      	beq.n	eae2 <remove_timeout+0x22>
	if (next(t) != NULL) {
    eace:	b143      	cbz	r3, eae2 <remove_timeout+0x22>
		next(t)->dticks += t->dticks;
    ead0:	e9d3 2104 	ldrd	r2, r1, [r3, #16]
    ead4:	e9d0 4504 	ldrd	r4, r5, [r0, #16]
    ead8:	1912      	adds	r2, r2, r4
    eada:	eb45 0101 	adc.w	r1, r5, r1
    eade:	e9c3 2104 	strd	r2, r1, [r3, #16]
	node->prev->next = node->next;
    eae2:	6842      	ldr	r2, [r0, #4]
    eae4:	6013      	str	r3, [r2, #0]
	node->next->prev = node->prev;
    eae6:	605a      	str	r2, [r3, #4]
	node->next = NULL;
    eae8:	2300      	movs	r3, #0
	node->prev = NULL;
    eaea:	e9c0 3300 	strd	r3, r3, [r0]
}
    eaee:	bd30      	pop	{r4, r5, pc}
    eaf0:	20010034 	.word	0x20010034

0000eaf4 <next_timeout>:

static int32_t next_timeout(void)
{
    eaf4:	b538      	push	{r3, r4, r5, lr}
	return list->head == list;
    eaf6:	4b11      	ldr	r3, [pc, #68]	; (eb3c <next_timeout+0x48>)
    eaf8:	681c      	ldr	r4, [r3, #0]
	return sys_dlist_is_empty(list) ? NULL : list->head;
    eafa:	429c      	cmp	r4, r3
    eafc:	bf08      	it	eq
    eafe:	2400      	moveq	r4, #0
	struct _timeout *to = first();
	int32_t ticks_elapsed = elapsed();
    eb00:	f7ff ffd4 	bl	eaac <elapsed>
    eb04:	4605      	mov	r5, r0
	int32_t ret = to == NULL ? MAX_WAIT
    eb06:	b1ac      	cbz	r4, eb34 <next_timeout+0x40>
		: MIN(MAX_WAIT, MAX(0, to->dticks - ticks_elapsed));
    eb08:	e9d4 0104 	ldrd	r0, r1, [r4, #16]
    eb0c:	1b40      	subs	r0, r0, r5
    eb0e:	eb61 71e5 	sbc.w	r1, r1, r5, asr #31
	int32_t ret = to == NULL ? MAX_WAIT
    eb12:	f1b0 4f00 	cmp.w	r0, #2147483648	; 0x80000000
    eb16:	f171 0300 	sbcs.w	r3, r1, #0
    eb1a:	da0b      	bge.n	eb34 <next_timeout+0x40>
		: MIN(MAX_WAIT, MAX(0, to->dticks - ticks_elapsed));
    eb1c:	2800      	cmp	r0, #0
    eb1e:	f171 0300 	sbcs.w	r3, r1, #0
    eb22:	da00      	bge.n	eb26 <next_timeout+0x32>
    eb24:	2000      	movs	r0, #0

#ifdef CONFIG_TIMESLICING
	if (_current_cpu->slice_ticks && _current_cpu->slice_ticks < ret) {
    eb26:	4b06      	ldr	r3, [pc, #24]	; (eb40 <next_timeout+0x4c>)
    eb28:	691b      	ldr	r3, [r3, #16]
    eb2a:	b113      	cbz	r3, eb32 <next_timeout+0x3e>
    eb2c:	4298      	cmp	r0, r3
    eb2e:	bfa8      	it	ge
    eb30:	4618      	movge	r0, r3
		ret = _current_cpu->slice_ticks;
	}
#endif
	return ret;
}
    eb32:	bd38      	pop	{r3, r4, r5, pc}
	int32_t ret = to == NULL ? MAX_WAIT
    eb34:	f06f 4000 	mvn.w	r0, #2147483648	; 0x80000000
    eb38:	e7f5      	b.n	eb26 <next_timeout+0x32>
    eb3a:	bf00      	nop
    eb3c:	20010034 	.word	0x20010034
    eb40:	20010244 	.word	0x20010244

0000eb44 <z_add_timeout>:

void z_add_timeout(struct _timeout *to, _timeout_func_t fn,
		   k_timeout_t timeout)
{
    eb44:	e92d 4ff7 	stmdb	sp!, {r0, r1, r2, r4, r5, r6, r7, r8, r9, sl, fp, lr}
    eb48:	9101      	str	r1, [sp, #4]
    eb4a:	4619      	mov	r1, r3
	if (K_TIMEOUT_EQ(timeout, K_FOREVER)) {
    eb4c:	1c4b      	adds	r3, r1, #1
    eb4e:	bf08      	it	eq
    eb50:	f1b2 3fff 	cmpeq.w	r2, #4294967295
{
    eb54:	4682      	mov	sl, r0
	if (K_TIMEOUT_EQ(timeout, K_FOREVER)) {
    eb56:	d06b      	beq.n	ec30 <z_add_timeout+0xec>
#ifdef CONFIG_LEGACY_TIMEOUT_API
	k_ticks_t ticks = timeout;
#else
	k_ticks_t ticks = timeout.ticks + 1;

	if (IS_ENABLED(CONFIG_TIMEOUT_64BIT) && Z_TICK_ABS(ticks) >= 0) {
    eb58:	f06f 0301 	mvn.w	r3, #1
    eb5c:	f04f 3bff 	mov.w	fp, #4294967295
	k_ticks_t ticks = timeout.ticks + 1;
    eb60:	1c54      	adds	r4, r2, #1
    eb62:	f141 0500 	adc.w	r5, r1, #0
	if (IS_ENABLED(CONFIG_TIMEOUT_64BIT) && Z_TICK_ABS(ticks) >= 0) {
    eb66:	ebb3 0804 	subs.w	r8, r3, r4
    eb6a:	eb6b 0905 	sbc.w	r9, fp, r5
    eb6e:	f1b8 0f00 	cmp.w	r8, #0
    eb72:	f179 0300 	sbcs.w	r3, r9, #0
    eb76:	db0f      	blt.n	eb98 <z_add_timeout+0x54>
		ticks = Z_TICK_ABS(ticks) - (curr_tick + elapsed());
    eb78:	f7ff ff98 	bl	eaac <elapsed>
    eb7c:	f06f 0301 	mvn.w	r3, #1
    eb80:	4a32      	ldr	r2, [pc, #200]	; (ec4c <z_add_timeout+0x108>)
    eb82:	e9d2 1c00 	ldrd	r1, ip, [r2]
    eb86:	1a5b      	subs	r3, r3, r1
    eb88:	eb6b 020c 	sbc.w	r2, fp, ip
    eb8c:	1b1e      	subs	r6, r3, r4
    eb8e:	eb62 0705 	sbc.w	r7, r2, r5
    eb92:	1a34      	subs	r4, r6, r0
    eb94:	eb67 75e0 	sbc.w	r5, r7, r0, asr #31
	}
#endif

	__ASSERT(!sys_dnode_is_linked(&to->node), "");
	to->fn = fn;
    eb98:	9b01      	ldr	r3, [sp, #4]
    eb9a:	f8ca 3008 	str.w	r3, [sl, #8]
	__asm__ volatile(
    eb9e:	f04f 0320 	mov.w	r3, #32
    eba2:	f3ef 8611 	mrs	r6, BASEPRI
    eba6:	f383 8811 	msr	BASEPRI, r3
    ebaa:	f3bf 8f6f 	isb	sy
	ticks = MAX(1, ticks);

	LOCKED(&timeout_lock) {
		struct _timeout *t;

		to->dticks = ticks + elapsed();
    ebae:	f7ff ff7d 	bl	eaac <elapsed>
	ticks = MAX(1, ticks);
    ebb2:	2c01      	cmp	r4, #1
    ebb4:	f175 0300 	sbcs.w	r3, r5, #0
    ebb8:	bfbc      	itt	lt
    ebba:	2401      	movlt	r4, #1
    ebbc:	2500      	movlt	r5, #0
	return list->head == list;
    ebbe:	4b24      	ldr	r3, [pc, #144]	; (ec50 <z_add_timeout+0x10c>)
		to->dticks = ticks + elapsed();
    ebc0:	1824      	adds	r4, r4, r0
    ebc2:	681a      	ldr	r2, [r3, #0]
    ebc4:	eb45 75e0 	adc.w	r5, r5, r0, asr #31
	return sys_dlist_is_empty(list) ? NULL : list->head;
    ebc8:	429a      	cmp	r2, r3
    ebca:	e9ca 4504 	strd	r4, r5, [sl, #16]
    ebce:	d001      	beq.n	ebd4 <z_add_timeout+0x90>
	return (node != NULL) ? sys_dlist_peek_next_no_check(list, node) : NULL;
    ebd0:	685f      	ldr	r7, [r3, #4]
		for (t = first(); t != NULL; t = next(t)) {
    ebd2:	b952      	cbnz	r2, ebea <z_add_timeout+0xa6>
	node->prev = list->tail;
    ebd4:	685a      	ldr	r2, [r3, #4]
	node->next = list;
    ebd6:	f8ca 3000 	str.w	r3, [sl]
	node->prev = list->tail;
    ebda:	f8ca 2004 	str.w	r2, [sl, #4]
	list->tail->next = node;
    ebde:	685a      	ldr	r2, [r3, #4]
    ebe0:	f8c2 a000 	str.w	sl, [r2]
	list->tail = node;
    ebe4:	f8c3 a004 	str.w	sl, [r3, #4]
}
    ebe8:	e014      	b.n	ec14 <z_add_timeout+0xd0>
			if (t->dticks > to->dticks) {
    ebea:	e9d2 8904 	ldrd	r8, r9, [r2, #16]
    ebee:	e9da 4504 	ldrd	r4, r5, [sl, #16]
    ebf2:	4544      	cmp	r4, r8
    ebf4:	eb75 0109 	sbcs.w	r1, r5, r9
    ebf8:	da1d      	bge.n	ec36 <z_add_timeout+0xf2>
				t->dticks -= to->dticks;
    ebfa:	ebb8 0004 	subs.w	r0, r8, r4
    ebfe:	eb69 0105 	sbc.w	r1, r9, r5
    ec02:	e9c2 0104 	strd	r0, r1, [r2, #16]
	node->prev = successor->prev;
    ec06:	6851      	ldr	r1, [r2, #4]
	node->next = successor;
    ec08:	e9ca 2100 	strd	r2, r1, [sl]
	successor->prev->next = node;
    ec0c:	f8c1 a000 	str.w	sl, [r1]
	successor->prev = node;
    ec10:	f8c2 a004 	str.w	sl, [r2, #4]
	return list->head == list;
    ec14:	681a      	ldr	r2, [r3, #0]
	return sys_dlist_is_empty(list) ? NULL : list->head;
    ec16:	429a      	cmp	r2, r3
    ec18:	d006      	beq.n	ec28 <z_add_timeout+0xe4>

		if (t == NULL) {
			sys_dlist_append(&timeout_list, &to->node);
		}

		if (to == first()) {
    ec1a:	4592      	cmp	sl, r2
    ec1c:	d104      	bne.n	ec28 <z_add_timeout+0xe4>
			z_clock_set_timeout(next_timeout(), false);
    ec1e:	f7ff ff69 	bl	eaf4 <next_timeout>
    ec22:	2100      	movs	r1, #0
    ec24:	f7fe f956 	bl	ced4 <z_clock_set_timeout>
	__asm__ volatile(
    ec28:	f386 8811 	msr	BASEPRI, r6
    ec2c:	f3bf 8f6f 	isb	sy
		}
	}
}
    ec30:	b003      	add	sp, #12
    ec32:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
			to->dticks -= t->dticks;
    ec36:	ebb4 0008 	subs.w	r0, r4, r8
    ec3a:	eb65 0109 	sbc.w	r1, r5, r9
	return (node == list->tail) ? NULL : node->next;
    ec3e:	42ba      	cmp	r2, r7
    ec40:	e9ca 0104 	strd	r0, r1, [sl, #16]
    ec44:	d0c6      	beq.n	ebd4 <z_add_timeout+0x90>
    ec46:	6812      	ldr	r2, [r2, #0]
    ec48:	e7c3      	b.n	ebd2 <z_add_timeout+0x8e>
    ec4a:	bf00      	nop
    ec4c:	20010190 	.word	0x20010190
    ec50:	20010034 	.word	0x20010034

0000ec54 <z_clock_announce>:
		}
	}
}

void z_clock_announce(int32_t ticks)
{
    ec54:	e92d 4ff7 	stmdb	sp!, {r0, r1, r2, r4, r5, r6, r7, r8, r9, sl, fp, lr}
    ec58:	4606      	mov	r6, r0
#ifdef CONFIG_TIMESLICING
	z_time_slice(ticks);
    ec5a:	f7ff fc7b 	bl	e554 <z_time_slice>
	__asm__ volatile(
    ec5e:	f04f 0320 	mov.w	r3, #32
    ec62:	f3ef 8411 	mrs	r4, BASEPRI
    ec66:	f383 8811 	msr	BASEPRI, r3
    ec6a:	f3bf 8f6f 	isb	sy
#endif

	k_spinlock_key_t key = k_spin_lock(&timeout_lock);

	announce_remaining = ticks;
    ec6e:	f8df a0b0 	ldr.w	sl, [pc, #176]	; ed20 <z_clock_announce+0xcc>
    ec72:	4d2a      	ldr	r5, [pc, #168]	; (ed1c <z_clock_announce+0xc8>)
    ec74:	4651      	mov	r1, sl
	return list->head == list;
    ec76:	f8df b0ac 	ldr.w	fp, [pc, #172]	; ed24 <z_clock_announce+0xd0>
    ec7a:	602e      	str	r6, [r5, #0]
    ec7c:	f8d5 c000 	ldr.w	ip, [r5]
    ec80:	f8db 0000 	ldr.w	r0, [fp]
    ec84:	4662      	mov	r2, ip
    ec86:	e9da 8900 	ldrd	r8, r9, [sl]
    ec8a:	17d3      	asrs	r3, r2, #31
	return sys_dlist_is_empty(list) ? NULL : list->head;
    ec8c:	4558      	cmp	r0, fp
    ec8e:	e9cd 2300 	strd	r2, r3, [sp]
    ec92:	d00d      	beq.n	ecb0 <z_clock_announce+0x5c>

	while (first() != NULL && first()->dticks <= announce_remaining) {
    ec94:	b160      	cbz	r0, ecb0 <z_clock_announce+0x5c>
    ec96:	e9d0 6704 	ldrd	r6, r7, [r0, #16]
    ec9a:	45b4      	cmp	ip, r6
    ec9c:	41bb      	sbcs	r3, r7
    ec9e:	da1d      	bge.n	ecdc <z_clock_announce+0x88>
		t->fn(t);
		key = k_spin_lock(&timeout_lock);
	}

	if (first() != NULL) {
		first()->dticks -= announce_remaining;
    eca0:	9b00      	ldr	r3, [sp, #0]
    eca2:	ebb6 0c03 	subs.w	ip, r6, r3
    eca6:	9b01      	ldr	r3, [sp, #4]
    eca8:	eb67 0603 	sbc.w	r6, r7, r3
    ecac:	e9c0 c604 	strd	ip, r6, [r0, #16]
	}

	curr_tick += announce_remaining;
	announce_remaining = 0;
    ecb0:	2600      	movs	r6, #0
	curr_tick += announce_remaining;
    ecb2:	9b00      	ldr	r3, [sp, #0]
	announce_remaining = 0;
    ecb4:	602e      	str	r6, [r5, #0]
	curr_tick += announce_remaining;
    ecb6:	eb13 0208 	adds.w	r2, r3, r8
    ecba:	9b01      	ldr	r3, [sp, #4]
    ecbc:	eb43 0309 	adc.w	r3, r3, r9
    ecc0:	e9c1 2300 	strd	r2, r3, [r1]

	z_clock_set_timeout(next_timeout(), false);
    ecc4:	f7ff ff16 	bl	eaf4 <next_timeout>
    ecc8:	4631      	mov	r1, r6
    ecca:	f7fe f903 	bl	ced4 <z_clock_set_timeout>
	__asm__ volatile(
    ecce:	f384 8811 	msr	BASEPRI, r4
    ecd2:	f3bf 8f6f 	isb	sy

	k_spin_unlock(&timeout_lock, key);
}
    ecd6:	b003      	add	sp, #12
    ecd8:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
		t->dticks = 0;
    ecdc:	2200      	movs	r2, #0
    ecde:	2300      	movs	r3, #0
		curr_tick += dt;
    ece0:	eb18 0806 	adds.w	r8, r8, r6
    ece4:	eb49 79e6 	adc.w	r9, r9, r6, asr #31
		t->dticks = 0;
    ece8:	e9c0 2304 	strd	r2, r3, [r0, #16]
		announce_remaining -= dt;
    ecec:	ebac 0606 	sub.w	r6, ip, r6
		curr_tick += dt;
    ecf0:	e9ca 8900 	strd	r8, r9, [sl]
		announce_remaining -= dt;
    ecf4:	602e      	str	r6, [r5, #0]
		remove_timeout(t);
    ecf6:	f7ff fee3 	bl	eac0 <remove_timeout>
    ecfa:	f384 8811 	msr	BASEPRI, r4
    ecfe:	f3bf 8f6f 	isb	sy
		t->fn(t);
    ed02:	6883      	ldr	r3, [r0, #8]
    ed04:	4798      	blx	r3
	__asm__ volatile(
    ed06:	f04f 0320 	mov.w	r3, #32
    ed0a:	f3ef 8411 	mrs	r4, BASEPRI
    ed0e:	f383 8811 	msr	BASEPRI, r3
    ed12:	f3bf 8f6f 	isb	sy

	/* Note that we need to use the underlying arch-specific lock
	 * implementation.  The "irq_lock()" API in SMP context is
	 * actually a wrapper for a global spinlock!
	 */
	k.key = arch_irq_lock();
    ed16:	4902      	ldr	r1, [pc, #8]	; (ed20 <z_clock_announce+0xcc>)
#endif

#ifdef CONFIG_SPIN_VALIDATE
	z_spin_lock_set_owner(l);
#endif
	return k;
    ed18:	e7b0      	b.n	ec7c <z_clock_announce+0x28>
    ed1a:	bf00      	nop
    ed1c:	20010280 	.word	0x20010280
    ed20:	20010190 	.word	0x20010190
    ed24:	20010034 	.word	0x20010034

0000ed28 <z_tick_get>:

int64_t z_tick_get(void)
{
    ed28:	b510      	push	{r4, lr}
    ed2a:	f04f 0320 	mov.w	r3, #32
    ed2e:	f3ef 8411 	mrs	r4, BASEPRI
    ed32:	f383 8811 	msr	BASEPRI, r3
    ed36:	f3bf 8f6f 	isb	sy
	uint64_t t = 0U;

	LOCKED(&timeout_lock) {
		t = curr_tick + z_clock_elapsed();
    ed3a:	f7fe f931 	bl	cfa0 <z_clock_elapsed>
    ed3e:	4b06      	ldr	r3, [pc, #24]	; (ed58 <z_tick_get+0x30>)
    ed40:	e9d3 2300 	ldrd	r2, r3, [r3]
    ed44:	1812      	adds	r2, r2, r0
    ed46:	f143 0300 	adc.w	r3, r3, #0
	__asm__ volatile(
    ed4a:	f384 8811 	msr	BASEPRI, r4
    ed4e:	f3bf 8f6f 	isb	sy
	}
	return t;
}
    ed52:	4610      	mov	r0, r2
    ed54:	4619      	mov	r1, r3
    ed56:	bd10      	pop	{r4, pc}
    ed58:	20010190 	.word	0x20010190

0000ed5c <statics_init>:
	z_waitq_init(&h->wait_q);
	sys_heap_init(&h->heap, mem, bytes);
}

static int statics_init(const struct device *unused)
{
    ed5c:	b538      	push	{r3, r4, r5, lr}
	ARG_UNUSED(unused);
	Z_STRUCT_SECTION_FOREACH(k_heap, h) {
    ed5e:	4c06      	ldr	r4, [pc, #24]	; (ed78 <statics_init+0x1c>)
    ed60:	4d06      	ldr	r5, [pc, #24]	; (ed7c <statics_init+0x20>)
    ed62:	42ac      	cmp	r4, r5
    ed64:	d301      	bcc.n	ed6a <statics_init+0xe>
		k_heap_init(h, h->heap.init_mem, h->heap.init_bytes);
	}
	return 0;
}
    ed66:	2000      	movs	r0, #0
    ed68:	bd38      	pop	{r3, r4, r5, pc}
		k_heap_init(h, h->heap.init_mem, h->heap.init_bytes);
    ed6a:	4620      	mov	r0, r4
    ed6c:	e9d4 1201 	ldrd	r1, r2, [r4, #4]
    ed70:	f000 fcf4 	bl	f75c <k_heap_init>
	Z_STRUCT_SECTION_FOREACH(k_heap, h) {
    ed74:	3414      	adds	r4, #20
    ed76:	e7f4      	b.n	ed62 <statics_init+0x6>
    ed78:	20010090 	.word	0x20010090
    ed7c:	20010090 	.word	0x20010090

0000ed80 <z_impl_gpio_port_toggle_bits>:
					       gpio_port_pins_t pins)
{
	const struct gpio_driver_api *api =
		(const struct gpio_driver_api *)port->api;

	return api->port_toggle_bits(port, pins);
    ed80:	6883      	ldr	r3, [r0, #8]
    ed82:	695b      	ldr	r3, [r3, #20]
    ed84:	4718      	bx	r3

0000ed86 <gpio_pin_configure.constprop.0>:
static inline int gpio_pin_configure(const struct device *port,
    ed86:	b538      	push	{r3, r4, r5, lr}
    ed88:	460c      	mov	r4, r1
	struct gpio_driver_data *data =
    ed8a:	68c5      	ldr	r5, [r0, #12]
	return api->pin_configure(port, pin, flags);
    ed8c:	6883      	ldr	r3, [r0, #8]
    ed8e:	f44f 7200 	mov.w	r2, #512	; 0x200
    ed92:	681b      	ldr	r3, [r3, #0]
    ed94:	4798      	blx	r3
	if (ret != 0) {
    ed96:	b930      	cbnz	r0, eda6 <gpio_pin_configure.constprop.0+0x20>
		data->invert &= ~(gpio_port_pins_t)BIT(pin);
    ed98:	2301      	movs	r3, #1
    ed9a:	fa03 f104 	lsl.w	r1, r3, r4
    ed9e:	682b      	ldr	r3, [r5, #0]
    eda0:	ea23 0301 	bic.w	r3, r3, r1
    eda4:	602b      	str	r3, [r5, #0]
}
    eda6:	bd38      	pop	{r3, r4, r5, pc}

0000eda8 <sys_notify_validate>:

int sys_notify_validate(struct sys_notify *notify)
{
	int rv = 0;

	if (notify == NULL) {
    eda8:	4603      	mov	r3, r0
    edaa:	b158      	cbz	r0, edc4 <sys_notify_validate+0x1c>
	uint32_t method = notify->flags >> SYS_NOTIFY_METHOD_POS;
    edac:	6842      	ldr	r2, [r0, #4]
	return method & SYS_NOTIFY_METHOD_MASK;
    edae:	f002 0203 	and.w	r2, r2, #3
		return -EINVAL;
	}

	/* Validate configuration based on mode */
	switch (sys_notify_get_method(notify)) {
    edb2:	2a01      	cmp	r2, #1
    edb4:	d003      	beq.n	edbe <sys_notify_validate+0x16>
    edb6:	2a03      	cmp	r2, #3
    edb8:	d104      	bne.n	edc4 <sys_notify_validate+0x1c>
	case SYS_NOTIFY_METHOD_SPINWAIT:
		break;
	case SYS_NOTIFY_METHOD_CALLBACK:
		if (notify->method.callback == NULL) {
    edba:	6802      	ldr	r2, [r0, #0]
    edbc:	b112      	cbz	r2, edc4 <sys_notify_validate+0x1c>
		break;
	}

	/* Clear the result here instead of in all callers. */
	if (rv == 0) {
		notify->result = 0;
    edbe:	2000      	movs	r0, #0
    edc0:	6098      	str	r0, [r3, #8]
    edc2:	4770      	bx	lr
		return -EINVAL;
    edc4:	f06f 0015 	mvn.w	r0, #21
	}

	return rv;
}
    edc8:	4770      	bx	lr

0000edca <sys_notify_finalize>:
	uint32_t method = notify->flags >> SYS_NOTIFY_METHOD_POS;
    edca:	6842      	ldr	r2, [r0, #4]

sys_notify_generic_callback sys_notify_finalize(struct sys_notify *notify,
						    int res)
{
    edcc:	4603      	mov	r3, r0
	return method & SYS_NOTIFY_METHOD_MASK;
    edce:	f002 0203 	and.w	r2, r2, #3

	/* Store the result and capture secondary notification
	 * information.
	 */
	notify->result = res;
	switch (method) {
    edd2:	2a03      	cmp	r2, #3
    edd4:	f04f 0200 	mov.w	r2, #0
	notify->result = res;
    edd8:	6081      	str	r1, [r0, #8]
	sys_notify_generic_callback rv = 0;
    edda:	bf14      	ite	ne
    eddc:	4610      	movne	r0, r2
	case SYS_NOTIFY_METHOD_SPINWAIT:
		break;
	case SYS_NOTIFY_METHOD_CALLBACK:
		rv = notify->method.callback;
    edde:	6800      	ldreq	r0, [r0, #0]
	/* Mark completion by clearing the flags field to the
	 * completed state, releasing any spin-waiters, then complete
	 * secondary notification.
	 */
	compiler_barrier();
	notify->flags = SYS_NOTIFY_METHOD_COMPLETED;
    ede0:	605a      	str	r2, [r3, #4]
	if (IS_ENABLED(CONFIG_POLL) && (sig != NULL)) {
		k_poll_signal_raise(sig, res);
	}

	return rv;
}
    ede2:	4770      	bx	lr

0000ede4 <arch_printk_char_out>:
}
    ede4:	2000      	movs	r0, #0
    ede6:	4770      	bx	lr

0000ede8 <printk>:
 * @param fmt formatted string to output
 *
 * @return N/A
 */
void printk(const char *fmt, ...)
{
    ede8:	b40f      	push	{r0, r1, r2, r3}
    edea:	b507      	push	{r0, r1, r2, lr}
    edec:	a904      	add	r1, sp, #16
    edee:	f851 0b04 	ldr.w	r0, [r1], #4
	va_list ap;

	va_start(ap, fmt);
    edf2:	9101      	str	r1, [sp, #4]

	if (IS_ENABLED(CONFIG_LOG_PRINTK)) {
		log_printk(fmt, ap);
	} else {
		vprintk(fmt, ap);
    edf4:	f7fd fd54 	bl	c8a0 <vprintk>
	}
	va_end(ap);
}
    edf8:	b003      	add	sp, #12
    edfa:	f85d eb04 	ldr.w	lr, [sp], #4
    edfe:	b004      	add	sp, #16
    ee00:	4770      	bx	lr

0000ee02 <process_recheck>:
	uint32_t state = mgr->flags & ONOFF_STATE_MASK;
    ee02:	8b03      	ldrh	r3, [r0, #24]
	if ((state == ONOFF_STATE_OFF)
    ee04:	f013 0307 	ands.w	r3, r3, #7
    ee08:	d105      	bne.n	ee16 <process_recheck+0x14>
	    && !sys_slist_is_empty(&mgr->clients)) {
    ee0a:	6803      	ldr	r3, [r0, #0]
    ee0c:	2b00      	cmp	r3, #0
		evt = EVT_START;
    ee0e:	bf0c      	ite	eq
    ee10:	2000      	moveq	r0, #0
    ee12:	2003      	movne	r0, #3
    ee14:	4770      	bx	lr
	} else if ((state == ONOFF_STATE_ON)
    ee16:	2b02      	cmp	r3, #2
    ee18:	d105      	bne.n	ee26 <process_recheck+0x24>
		   && (mgr->refs == 0)) {
    ee1a:	8b43      	ldrh	r3, [r0, #26]
    ee1c:	2b00      	cmp	r3, #0
		evt = EVT_STOP;
    ee1e:	bf14      	ite	ne
    ee20:	2000      	movne	r0, #0
    ee22:	2004      	moveq	r0, #4
    ee24:	4770      	bx	lr
	} else if ((state == ONOFF_STATE_ERROR)
    ee26:	2b01      	cmp	r3, #1
    ee28:	d105      	bne.n	ee36 <process_recheck+0x34>
		   && !sys_slist_is_empty(&mgr->clients)) {
    ee2a:	6803      	ldr	r3, [r0, #0]
    ee2c:	2b00      	cmp	r3, #0
		evt = EVT_RESET;
    ee2e:	bf0c      	ite	eq
    ee30:	2000      	moveq	r0, #0
    ee32:	2005      	movne	r0, #5
    ee34:	4770      	bx	lr
	int evt = EVT_NOP;
    ee36:	2000      	movs	r0, #0
}
    ee38:	4770      	bx	lr

0000ee3a <notify_one>:
{
    ee3a:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    ee3e:	460d      	mov	r5, r1
    ee40:	4607      	mov	r7, r0
		(onoff_client_callback)sys_notify_finalize(&cli->notify, res);
    ee42:	4619      	mov	r1, r3
    ee44:	1d28      	adds	r0, r5, #4
{
    ee46:	4690      	mov	r8, r2
    ee48:	461e      	mov	r6, r3
		(onoff_client_callback)sys_notify_finalize(&cli->notify, res);
    ee4a:	f7ff ffbe 	bl	edca <sys_notify_finalize>
	if (cb) {
    ee4e:	4604      	mov	r4, r0
    ee50:	b138      	cbz	r0, ee62 <notify_one+0x28>
		cb(mgr, cli, state, res);
    ee52:	4633      	mov	r3, r6
    ee54:	4642      	mov	r2, r8
    ee56:	4629      	mov	r1, r5
    ee58:	4638      	mov	r0, r7
    ee5a:	46a4      	mov	ip, r4
}
    ee5c:	e8bd 41f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
		cb(mgr, cli, state, res);
    ee60:	4760      	bx	ip
}
    ee62:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}

0000ee66 <transition_complete>:
{
    ee66:	b410      	push	{r4}
	__asm__ volatile(
    ee68:	f04f 0420 	mov.w	r4, #32
    ee6c:	f3ef 8211 	mrs	r2, BASEPRI
    ee70:	f384 8811 	msr	BASEPRI, r4
    ee74:	f3bf 8f6f 	isb	sy
	mgr->last_res = res;
    ee78:	6141      	str	r1, [r0, #20]
}
    ee7a:	bc10      	pop	{r4}
	process_event(mgr, EVT_COMPLETE, key);
    ee7c:	2101      	movs	r1, #1
    ee7e:	f7fd bd1d 	b.w	c8bc <process_event>

0000ee82 <validate_args>:
{
    ee82:	b510      	push	{r4, lr}
    ee84:	460c      	mov	r4, r1
	if ((mgr == NULL) || (cli == NULL)) {
    ee86:	b140      	cbz	r0, ee9a <validate_args+0x18>
    ee88:	b139      	cbz	r1, ee9a <validate_args+0x18>
	int rv = sys_notify_validate(&cli->notify);
    ee8a:	1d08      	adds	r0, r1, #4
    ee8c:	f7ff ff8c 	bl	eda8 <sys_notify_validate>
	if ((rv == 0)
    ee90:	b928      	cbnz	r0, ee9e <validate_args+0x1c>
	    && ((cli->notify.flags
    ee92:	68a3      	ldr	r3, [r4, #8]
    ee94:	f033 0303 	bics.w	r3, r3, #3
    ee98:	d001      	beq.n	ee9e <validate_args+0x1c>
		rv = -EINVAL;
    ee9a:	f06f 0015 	mvn.w	r0, #21
}
    ee9e:	bd10      	pop	{r4, pc}

0000eea0 <onoff_manager_init>:
{
    eea0:	b538      	push	{r3, r4, r5, lr}
    eea2:	460c      	mov	r4, r1
	if ((mgr == NULL)
    eea4:	4605      	mov	r5, r0
    eea6:	b158      	cbz	r0, eec0 <onoff_manager_init+0x20>
	    || (transitions == NULL)
    eea8:	b151      	cbz	r1, eec0 <onoff_manager_init+0x20>
	    || (transitions->start == NULL)
    eeaa:	680b      	ldr	r3, [r1, #0]
    eeac:	b143      	cbz	r3, eec0 <onoff_manager_init+0x20>
	    || (transitions->stop == NULL)) {
    eeae:	684b      	ldr	r3, [r1, #4]
    eeb0:	b133      	cbz	r3, eec0 <onoff_manager_init+0x20>
	*mgr = (struct onoff_manager)ONOFF_MANAGER_INITIALIZER(transitions);
    eeb2:	221c      	movs	r2, #28
    eeb4:	2100      	movs	r1, #0
    eeb6:	f000 fa56 	bl	f366 <memset>
	return 0;
    eeba:	2000      	movs	r0, #0
	*mgr = (struct onoff_manager)ONOFF_MANAGER_INITIALIZER(transitions);
    eebc:	612c      	str	r4, [r5, #16]
}
    eebe:	bd38      	pop	{r3, r4, r5, pc}
		return -EINVAL;
    eec0:	f06f 0015 	mvn.w	r0, #21
    eec4:	e7fb      	b.n	eebe <onoff_manager_init+0x1e>

0000eec6 <onoff_request>:

int onoff_request(struct onoff_manager *mgr,
		  struct onoff_client *cli)
{
    eec6:	b570      	push	{r4, r5, r6, lr}
    eec8:	4604      	mov	r4, r0
    eeca:	460e      	mov	r6, r1
	bool add_client = false;        /* add client to pending list */
	bool start = false;             /* trigger a start transition */
	bool notify = false;            /* do client notification */
	int rv = validate_args(mgr, cli);
    eecc:	f7ff ffd9 	bl	ee82 <validate_args>

	if (rv < 0) {
    eed0:	1e05      	subs	r5, r0, #0
    eed2:	db31      	blt.n	ef38 <onoff_request+0x72>
    eed4:	f04f 0320 	mov.w	r3, #32
    eed8:	f3ef 8111 	mrs	r1, BASEPRI
    eedc:	f383 8811 	msr	BASEPRI, r3
    eee0:	f3bf 8f6f 	isb	sy

	k_spinlock_key_t key = k_spin_lock(&mgr->lock);
	uint32_t state = mgr->flags & ONOFF_STATE_MASK;

	/* Reject if this would overflow the reference count. */
	if (mgr->refs == SERVICE_REFS_MAX) {
    eee4:	f64f 75ff 	movw	r5, #65535	; 0xffff
    eee8:	8b63      	ldrh	r3, [r4, #26]
	uint32_t state = mgr->flags & ONOFF_STATE_MASK;
    eeea:	8b20      	ldrh	r0, [r4, #24]
	if (mgr->refs == SERVICE_REFS_MAX) {
    eeec:	42ab      	cmp	r3, r5
    eeee:	f000 0207 	and.w	r2, r0, #7
    eef2:	d02e      	beq.n	ef52 <onoff_request+0x8c>
		rv = -EAGAIN;
		goto out;
	}

	rv = state;
	if (state == ONOFF_STATE_ON) {
    eef4:	2a02      	cmp	r2, #2
    eef6:	d10e      	bne.n	ef16 <onoff_request+0x50>
		/* Increment reference count, notify in exit */
		notify = true;
		mgr->refs += 1U;
    eef8:	3301      	adds	r3, #1
    eefa:	8363      	strh	r3, [r4, #26]
	rv = state;
    eefc:	4615      	mov	r5, r2
		notify = true;
    eefe:	2301      	movs	r3, #1
	__asm__ volatile(
    ef00:	f381 8811 	msr	BASEPRI, r1
    ef04:	f3bf 8f6f 	isb	sy
	if (start) {
		process_event(mgr, EVT_RECHECK, key);
	} else {
		k_spin_unlock(&mgr->lock, key);

		if (notify) {
    ef08:	b1b3      	cbz	r3, ef38 <onoff_request+0x72>
			notify_one(mgr, cli, state, 0);
    ef0a:	2300      	movs	r3, #0
    ef0c:	4631      	mov	r1, r6
    ef0e:	4620      	mov	r0, r4
    ef10:	f7ff ff93 	bl	ee3a <notify_one>
    ef14:	e010      	b.n	ef38 <onoff_request+0x72>
	} else if ((state == ONOFF_STATE_OFF)
    ef16:	0783      	lsls	r3, r0, #30
    ef18:	d001      	beq.n	ef1e <onoff_request+0x58>
		   || (state == ONOFF_STATE_TO_ON)) {
    ef1a:	2a06      	cmp	r2, #6
    ef1c:	d10e      	bne.n	ef3c <onoff_request+0x76>
	parent->next = child;
    ef1e:	2300      	movs	r3, #0
    ef20:	6033      	str	r3, [r6, #0]
Z_GENLIST_APPEND(slist, snode)
    ef22:	6863      	ldr	r3, [r4, #4]
    ef24:	b993      	cbnz	r3, ef4c <onoff_request+0x86>
	list->head = node;
    ef26:	e9c4 6600 	strd	r6, r6, [r4]
	if (start) {
    ef2a:	4615      	mov	r5, r2
    ef2c:	b962      	cbnz	r2, ef48 <onoff_request+0x82>
		process_event(mgr, EVT_RECHECK, key);
    ef2e:	460a      	mov	r2, r1
    ef30:	4620      	mov	r0, r4
    ef32:	2102      	movs	r1, #2
    ef34:	f7fd fcc2 	bl	c8bc <process_event>
		}
	}

	return rv;
}
    ef38:	4628      	mov	r0, r5
    ef3a:	bd70      	pop	{r4, r5, r6, pc}
		rv = -EIO;
    ef3c:	2a05      	cmp	r2, #5
    ef3e:	bf0c      	ite	eq
    ef40:	f06f 0522 	mvneq.w	r5, #34	; 0x22
    ef44:	f06f 0504 	mvnne.w	r5, #4
    ef48:	2300      	movs	r3, #0
    ef4a:	e7d9      	b.n	ef00 <onoff_request+0x3a>
	parent->next = child;
    ef4c:	601e      	str	r6, [r3, #0]
	list->tail = node;
    ef4e:	6066      	str	r6, [r4, #4]
}
    ef50:	e7eb      	b.n	ef2a <onoff_request+0x64>
		rv = -EAGAIN;
    ef52:	f06f 050a 	mvn.w	r5, #10
    ef56:	e7f7      	b.n	ef48 <onoff_request+0x82>

0000ef58 <z_thread_entry>:
 * This routine does not return, and is marked as such so the compiler won't
 * generate preamble code that is only used by functions that actually return.
 */
FUNC_NORETURN void z_thread_entry(k_thread_entry_t entry,
				 void *p1, void *p2, void *p3)
{
    ef58:	4604      	mov	r4, r0
    ef5a:	b508      	push	{r3, lr}
    ef5c:	4608      	mov	r0, r1
    ef5e:	4611      	mov	r1, r2
	entry(p1, p2, p3);
    ef60:	461a      	mov	r2, r3
    ef62:	47a0      	blx	r4
	return z_impl_k_current_get();
    ef64:	f7ff fcc4 	bl	e8f0 <z_impl_k_current_get>
	z_impl_k_thread_abort(thread);
    ef68:	f7fe fa7c 	bl	d464 <z_impl_k_thread_abort>

0000ef6c <chunk_field>:
				 enum chunk_fields f)
{
	chunk_unit_t *buf = chunk_buf(h);
	void *cmem = &buf[c];

	if (big_heap(h)) {
    ef6c:	6883      	ldr	r3, [r0, #8]
	void *cmem = &buf[c];
    ef6e:	eb00 01c1 	add.w	r1, r0, r1, lsl #3
	if (big_heap(h)) {
    ef72:	f5b3 4f00 	cmp.w	r3, #32768	; 0x8000
		return ((uint32_t *)cmem)[f];
    ef76:	bf2c      	ite	cs
    ef78:	f851 0022 	ldrcs.w	r0, [r1, r2, lsl #2]
	} else {
		return ((uint16_t *)cmem)[f];
    ef7c:	f831 0012 	ldrhcc.w	r0, [r1, r2, lsl #1]
	}
}
    ef80:	4770      	bx	lr

0000ef82 <chunk_set>:
			     enum chunk_fields f, chunkid_t val)
{
	CHECK(c <= h->len);

	chunk_unit_t *buf = chunk_buf(h);
	void *cmem = &buf[c];
    ef82:	eb00 01c1 	add.w	r1, r0, r1, lsl #3

	if (big_heap(h)) {
    ef86:	6880      	ldr	r0, [r0, #8]
    ef88:	f5b0 4f00 	cmp.w	r0, #32768	; 0x8000
		CHECK(val == (uint32_t)val);
		((uint32_t *)cmem)[f] = val;
    ef8c:	bf2c      	ite	cs
    ef8e:	f841 3022 	strcs.w	r3, [r1, r2, lsl #2]
	} else {
		CHECK(val == (uint16_t)val);
		((uint16_t *)cmem)[f] = val;
    ef92:	f821 3012 	strhcc.w	r3, [r1, r2, lsl #1]
	}
}
    ef96:	4770      	bx	lr

0000ef98 <chunk_size>:
	return chunk_field(h, c, SIZE_AND_USED) & 1;
}

static inline size_t chunk_size(struct z_heap *h, chunkid_t c)
{
	return chunk_field(h, c, SIZE_AND_USED) >> 1;
    ef98:	2201      	movs	r2, #1
{
    ef9a:	b508      	push	{r3, lr}
	return chunk_field(h, c, SIZE_AND_USED) >> 1;
    ef9c:	f7ff ffe6 	bl	ef6c <chunk_field>
}
    efa0:	0840      	lsrs	r0, r0, #1
    efa2:	bd08      	pop	{r3, pc}

0000efa4 <set_chunk_used>:
static inline void set_chunk_used(struct z_heap *h, chunkid_t c, bool used)
{
	chunk_unit_t *buf = chunk_buf(h);
	void *cmem = &buf[c];

	if (big_heap(h)) {
    efa4:	6883      	ldr	r3, [r0, #8]
	void *cmem = &buf[c];
    efa6:	eb00 01c1 	add.w	r1, r0, r1, lsl #3
	if (big_heap(h)) {
    efaa:	f5b3 4f00 	cmp.w	r3, #32768	; 0x8000
    efae:	d308      	bcc.n	efc2 <set_chunk_used+0x1e>
		if (used) {
    efb0:	684b      	ldr	r3, [r1, #4]
    efb2:	b11a      	cbz	r2, efbc <set_chunk_used+0x18>
			((uint32_t *)cmem)[SIZE_AND_USED] |= 1;
    efb4:	f043 0301 	orr.w	r3, r3, #1
		} else {
			((uint32_t *)cmem)[SIZE_AND_USED] &= ~1;
    efb8:	604b      	str	r3, [r1, #4]
    efba:	4770      	bx	lr
    efbc:	f023 0301 	bic.w	r3, r3, #1
    efc0:	e7fa      	b.n	efb8 <set_chunk_used+0x14>
		}
	} else {
		if (used) {
    efc2:	884b      	ldrh	r3, [r1, #2]
    efc4:	b11a      	cbz	r2, efce <set_chunk_used+0x2a>
			((uint16_t *)cmem)[SIZE_AND_USED] |= 1;
    efc6:	f043 0301 	orr.w	r3, r3, #1
		} else {
			((uint16_t *)cmem)[SIZE_AND_USED] &= ~1;
    efca:	804b      	strh	r3, [r1, #2]
		}
	}
}
    efcc:	4770      	bx	lr
			((uint16_t *)cmem)[SIZE_AND_USED] &= ~1;
    efce:	f023 0301 	bic.w	r3, r3, #1
    efd2:	e7fa      	b.n	efca <set_chunk_used+0x26>

0000efd4 <set_chunk_size>:
 * when its size is modified, and potential set_chunk_used() is always
 * invoked after set_chunk_size().
 */
static inline void set_chunk_size(struct z_heap *h, chunkid_t c, size_t size)
{
	chunk_set(h, c, SIZE_AND_USED, size << 1);
    efd4:	0053      	lsls	r3, r2, #1
    efd6:	2201      	movs	r2, #1
    efd8:	f7ff bfd3 	b.w	ef82 <chunk_set>

0000efdc <bucket_idx>:
	return big_heap(h) && chunk_size(h, c) == 1;
}

static inline size_t chunk_header_bytes(struct z_heap *h)
{
	return big_heap(h) ? 8 : 4;
    efdc:	6880      	ldr	r0, [r0, #8]
	return bytes_to_chunksz(h, 1);
}

static inline int bucket_idx(struct z_heap *h, size_t sz)
{
	size_t usable_sz = sz - min_chunk_size(h) + 1;
    efde:	3101      	adds	r1, #1
	return (bytes + CHUNK_UNIT - 1) / CHUNK_UNIT;
    efe0:	f5b0 4f00 	cmp.w	r0, #32768	; 0x8000
    efe4:	bf2c      	ite	cs
    efe6:	2002      	movcs	r0, #2
    efe8:	2001      	movcc	r0, #1
	size_t usable_sz = sz - min_chunk_size(h) + 1;
    efea:	1a08      	subs	r0, r1, r0
	return 31 - __builtin_clz(usable_sz);
    efec:	fab0 f080 	clz	r0, r0
}
    eff0:	f1c0 001f 	rsb	r0, r0, #31
    eff4:	4770      	bx	lr

0000eff6 <free_list_add>:
		set_prev_free_chunk(h, second, c);
	}
}

static void free_list_add(struct z_heap *h, chunkid_t c)
{
    eff6:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    effa:	4604      	mov	r4, r0
    effc:	460d      	mov	r5, r1
	return sizeof(void *) > 4 || chunks > 0x7fff;
    effe:	f7ff ffcb 	bl	ef98 <chunk_size>
	return big_heap(h) && chunk_size(h, c) == 1;
    f002:	68a3      	ldr	r3, [r4, #8]
    f004:	4601      	mov	r1, r0
    f006:	f5b3 4f00 	cmp.w	r3, #32768	; 0x8000
    f00a:	d301      	bcc.n	f010 <free_list_add+0x1a>
	if (!solo_free_header(h, c)) {
    f00c:	2801      	cmp	r0, #1
    f00e:	d035      	beq.n	f07c <free_list_add+0x86>
		int bidx = bucket_idx(h, chunk_size(h, c));
    f010:	4620      	mov	r0, r4
    f012:	f7ff ffe3 	bl	efdc <bucket_idx>
	if (b->next == 0) {
    f016:	eb04 0280 	add.w	r2, r4, r0, lsl #2
    f01a:	6916      	ldr	r6, [r2, #16]
    f01c:	b99e      	cbnz	r6, f046 <free_list_add+0x50>
		h->avail_buckets |= (1 << bidx);
    f01e:	2301      	movs	r3, #1
    f020:	fa03 f000 	lsl.w	r0, r3, r0
    f024:	68e3      	ldr	r3, [r4, #12]
	chunk_set(h, c, FREE_PREV, prev);
    f026:	4629      	mov	r1, r5
    f028:	4303      	orrs	r3, r0
    f02a:	60e3      	str	r3, [r4, #12]
    f02c:	4620      	mov	r0, r4
		b->next = c;
    f02e:	6115      	str	r5, [r2, #16]
    f030:	462b      	mov	r3, r5
    f032:	2202      	movs	r2, #2
    f034:	f7ff ffa5 	bl	ef82 <chunk_set>
	chunk_set(h, c, FREE_NEXT, next);
    f038:	2203      	movs	r2, #3
    f03a:	4629      	mov	r1, r5
	chunk_set(h, c, FREE_PREV, prev);
    f03c:	4620      	mov	r0, r4
		free_list_add_bidx(h, c, bidx);
	}
}
    f03e:	e8bd 41f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
    f042:	f7ff bf9e 	b.w	ef82 <chunk_set>
	return chunk_field(h, c, FREE_PREV);
    f046:	2202      	movs	r2, #2
    f048:	4631      	mov	r1, r6
    f04a:	4620      	mov	r0, r4
    f04c:	f7ff ff8e 	bl	ef6c <chunk_field>
    f050:	4607      	mov	r7, r0
	chunk_set(h, c, FREE_PREV, prev);
    f052:	4603      	mov	r3, r0
    f054:	2202      	movs	r2, #2
    f056:	4629      	mov	r1, r5
    f058:	4620      	mov	r0, r4
    f05a:	f7ff ff92 	bl	ef82 <chunk_set>
	chunk_set(h, c, FREE_NEXT, next);
    f05e:	4633      	mov	r3, r6
    f060:	2203      	movs	r2, #3
    f062:	4629      	mov	r1, r5
    f064:	4620      	mov	r0, r4
    f066:	f7ff ff8c 	bl	ef82 <chunk_set>
    f06a:	2203      	movs	r2, #3
    f06c:	4639      	mov	r1, r7
    f06e:	462b      	mov	r3, r5
    f070:	4620      	mov	r0, r4
    f072:	f7ff ff86 	bl	ef82 <chunk_set>
	chunk_set(h, c, FREE_PREV, prev);
    f076:	2202      	movs	r2, #2
    f078:	4631      	mov	r1, r6
    f07a:	e7df      	b.n	f03c <free_list_add+0x46>
    f07c:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}

0000f080 <sys_heap_init>:
	return big_heap_bytes(size) ? 8 : 4;
    f080:	f5b2 2f80 	cmp.w	r2, #262144	; 0x40000
	set_chunk_used(h, c, true);
	return mem;
}

void sys_heap_init(struct sys_heap *heap, void *mem, size_t bytes)
{
    f084:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
    f086:	bf2c      	ite	cs
    f088:	2508      	movcs	r5, #8
    f08a:	2504      	movcc	r5, #4
	CHECK(end > addr);
	__ASSERT(buf_sz > chunksz(sizeof(struct z_heap)), "heap size is too small");

	struct z_heap *h = (struct z_heap *)addr;
	heap->heap = h;
	h->chunk0_hdr_area = 0;
    f08c:	2300      	movs	r3, #0
	bytes -= heap_footer_bytes(bytes);
    f08e:	1b55      	subs	r5, r2, r5
	h->chunk0_hdr_area = 0;
    f090:	2200      	movs	r2, #0
	uintptr_t addr = ROUND_UP(mem, CHUNK_UNIT);
    f092:	1dcc      	adds	r4, r1, #7
    f094:	f024 0407 	bic.w	r4, r4, #7
	heap->heap = h;
    f098:	6004      	str	r4, [r0, #0]
	h->chunk0_hdr_area = 0;
    f09a:	e9c4 2300 	strd	r2, r3, [r4]
	h->len = buf_sz;
	h->avail_buckets = 0;
    f09e:	2300      	movs	r3, #0
	uintptr_t end = ROUND_DOWN((uint8_t *)mem + bytes, CHUNK_UNIT);
    f0a0:	440d      	add	r5, r1
    f0a2:	f025 0507 	bic.w	r5, r5, #7
	size_t buf_sz = (end - addr) / CHUNK_UNIT;
    f0a6:	1b2d      	subs	r5, r5, r4
    f0a8:	08ed      	lsrs	r5, r5, #3

	int nb_buckets = bucket_idx(h, buf_sz) + 1;
    f0aa:	4629      	mov	r1, r5
    f0ac:	4620      	mov	r0, r4
	h->len = buf_sz;
    f0ae:	60a5      	str	r5, [r4, #8]
	h->avail_buckets = 0;
    f0b0:	60e3      	str	r3, [r4, #12]
	int nb_buckets = bucket_idx(h, buf_sz) + 1;
    f0b2:	f7ff ff93 	bl	efdc <bucket_idx>
	size_t chunk0_size = chunksz(sizeof(struct z_heap) +
    f0b6:	0086      	lsls	r6, r0, #2
	int nb_buckets = bucket_idx(h, buf_sz) + 1;
    f0b8:	1c41      	adds	r1, r0, #1
				     nb_buckets * sizeof(struct z_heap_bucket));

	__ASSERT(chunk0_size + min_chunk_size(h) < buf_sz, "heap size is too small");

	for (int i = 0; i < nb_buckets; i++) {
		h->buckets[i].next = 0;
    f0ba:	4618      	mov	r0, r3
	return (bytes + CHUNK_UNIT - 1) / CHUNK_UNIT;
    f0bc:	361b      	adds	r6, #27
    f0be:	08f6      	lsrs	r6, r6, #3
	for (int i = 0; i < nb_buckets; i++) {
    f0c0:	f104 0210 	add.w	r2, r4, #16
    f0c4:	428b      	cmp	r3, r1
    f0c6:	db29      	blt.n	f11c <sys_heap_init+0x9c>
	}

	/* chunk containing our struct z_heap */
	set_chunk_size(h, 0, chunk0_size);
    f0c8:	4632      	mov	r2, r6
    f0ca:	4620      	mov	r0, r4
    f0cc:	2100      	movs	r1, #0
    f0ce:	f7ff ff81 	bl	efd4 <set_chunk_size>
	set_chunk_used(h, 0, true);

	/* chunk containing the free heap */
	set_chunk_size(h, chunk0_size, buf_sz - chunk0_size);
    f0d2:	1baf      	subs	r7, r5, r6
	set_chunk_used(h, 0, true);
    f0d4:	4620      	mov	r0, r4
    f0d6:	2201      	movs	r2, #1
    f0d8:	2100      	movs	r1, #0
    f0da:	f7ff ff63 	bl	efa4 <set_chunk_used>
	set_chunk_size(h, chunk0_size, buf_sz - chunk0_size);
    f0de:	463a      	mov	r2, r7
    f0e0:	4631      	mov	r1, r6
    f0e2:	f7ff ff77 	bl	efd4 <set_chunk_size>
	chunk_set(h, c, LEFT_SIZE, size);
    f0e6:	4633      	mov	r3, r6
    f0e8:	4631      	mov	r1, r6
    f0ea:	4620      	mov	r0, r4
    f0ec:	2200      	movs	r2, #0
    f0ee:	f7ff ff48 	bl	ef82 <chunk_set>
	set_left_chunk_size(h, chunk0_size, chunk0_size);

	/* the end marker chunk */
	set_chunk_size(h, buf_sz, 0);
    f0f2:	4629      	mov	r1, r5
    f0f4:	4620      	mov	r0, r4
    f0f6:	2200      	movs	r2, #0
    f0f8:	f7ff ff6c 	bl	efd4 <set_chunk_size>
    f0fc:	463b      	mov	r3, r7
    f0fe:	4629      	mov	r1, r5
    f100:	4620      	mov	r0, r4
    f102:	2200      	movs	r2, #0
    f104:	f7ff ff3d 	bl	ef82 <chunk_set>
	set_left_chunk_size(h, buf_sz, buf_sz - chunk0_size);
	set_chunk_used(h, buf_sz, true);
    f108:	4629      	mov	r1, r5
    f10a:	4620      	mov	r0, r4
    f10c:	2201      	movs	r2, #1
    f10e:	f7ff ff49 	bl	efa4 <set_chunk_used>

	free_list_add(h, chunk0_size);
    f112:	4631      	mov	r1, r6
}
    f114:	e8bd 40f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, lr}
	free_list_add(h, chunk0_size);
    f118:	f7ff bf6d 	b.w	eff6 <free_list_add>
		h->buckets[i].next = 0;
    f11c:	f842 0b04 	str.w	r0, [r2], #4
	for (int i = 0; i < nb_buckets; i++) {
    f120:	3301      	adds	r3, #1
    f122:	e7cf      	b.n	f0c4 <sys_heap_init+0x44>

0000f124 <_ConfigAbsSyms>:
GEN_ABSOLUTE_SYM(CONFIG_OUTPUT_PRINT_MEMORY_USAGE, 1);
GEN_ABSOLUTE_SYM(CONFIG_BUILD_OUTPUT_BIN, 1);
GEN_ABSOLUTE_SYM(CONFIG_REBOOT, 1);
GEN_ABSOLUTE_SYM(CONFIG_COMPAT_INCLUDES, 1);

GEN_ABS_SYM_END
    f124:	4770      	bx	lr

0000f126 <z_platform_init>:

void z_platform_init(void)
{
	SystemInit();
    f126:	f7fe bec5 	b.w	deb4 <SystemInit>

0000f12a <get_status>:
	return GET_STATUS(get_sub_data(dev, type)->flags);
    f12a:	b2cb      	uxtb	r3, r1
    f12c:	210c      	movs	r1, #12
    f12e:	68c2      	ldr	r2, [r0, #12]
    f130:	fb03 2101 	mla	r1, r3, r1, r2
    f134:	6c08      	ldr	r0, [r1, #64]	; 0x40
}
    f136:	f000 0007 	and.w	r0, r0, #7
    f13a:	4770      	bx	lr

0000f13c <set_off_state>:
	__asm__ volatile(
    f13c:	f04f 0320 	mov.w	r3, #32
    f140:	f3ef 8211 	mrs	r2, BASEPRI
    f144:	f383 8811 	msr	BASEPRI, r3
    f148:	f3bf 8f6f 	isb	sy
	uint32_t current_ctx = GET_CTX(*flags);
    f14c:	6803      	ldr	r3, [r0, #0]
	if ((current_ctx != 0) && (current_ctx != ctx)) {
    f14e:	f013 03c0 	ands.w	r3, r3, #192	; 0xc0
    f152:	d001      	beq.n	f158 <set_off_state+0x1c>
    f154:	428b      	cmp	r3, r1
    f156:	d107      	bne.n	f168 <set_off_state+0x2c>
		*flags = CLOCK_CONTROL_STATUS_OFF;
    f158:	2301      	movs	r3, #1
    f15a:	6003      	str	r3, [r0, #0]
	int err = 0;
    f15c:	2000      	movs	r0, #0
	__asm__ volatile(
    f15e:	f382 8811 	msr	BASEPRI, r2
    f162:	f3bf 8f6f 	isb	sy
}
    f166:	4770      	bx	lr
		err = -EPERM;
    f168:	f04f 30ff 	mov.w	r0, #4294967295
    f16c:	e7f7      	b.n	f15e <set_off_state+0x22>

0000f16e <set_starting_state>:
{
    f16e:	b510      	push	{r4, lr}
	__asm__ volatile(
    f170:	f04f 0320 	mov.w	r3, #32
    f174:	f3ef 8211 	mrs	r2, BASEPRI
    f178:	f383 8811 	msr	BASEPRI, r3
    f17c:	f3bf 8f6f 	isb	sy
	uint32_t current_ctx = GET_CTX(*flags);
    f180:	6803      	ldr	r3, [r0, #0]
	if ((*flags & (STATUS_MASK)) == CLOCK_CONTROL_STATUS_OFF) {
    f182:	f003 0407 	and.w	r4, r3, #7
    f186:	2c01      	cmp	r4, #1
    f188:	d106      	bne.n	f198 <set_starting_state+0x2a>
		*flags = CLOCK_CONTROL_STATUS_STARTING | ctx;
    f18a:	6001      	str	r1, [r0, #0]
	int err = 0;
    f18c:	2000      	movs	r0, #0
	__asm__ volatile(
    f18e:	f382 8811 	msr	BASEPRI, r2
    f192:	f3bf 8f6f 	isb	sy
}
    f196:	bd10      	pop	{r4, pc}
	uint32_t current_ctx = GET_CTX(*flags);
    f198:	f003 03c0 	and.w	r3, r3, #192	; 0xc0
	} else if (current_ctx != ctx) {
    f19c:	428b      	cmp	r3, r1
		err = -EBUSY;
    f19e:	bf14      	ite	ne
    f1a0:	f04f 30ff 	movne.w	r0, #4294967295
    f1a4:	f06f 000f 	mvneq.w	r0, #15
    f1a8:	e7f1      	b.n	f18e <set_starting_state+0x20>

0000f1aa <set_on_state>:
	__asm__ volatile(
    f1aa:	f04f 0320 	mov.w	r3, #32
    f1ae:	f3ef 8211 	mrs	r2, BASEPRI
    f1b2:	f383 8811 	msr	BASEPRI, r3
    f1b6:	f3bf 8f6f 	isb	sy
	*flags = CLOCK_CONTROL_STATUS_ON | GET_CTX(*flags);
    f1ba:	6803      	ldr	r3, [r0, #0]
    f1bc:	f003 03c0 	and.w	r3, r3, #192	; 0xc0
    f1c0:	f043 0302 	orr.w	r3, r3, #2
    f1c4:	6003      	str	r3, [r0, #0]
	__asm__ volatile(
    f1c6:	f382 8811 	msr	BASEPRI, r2
    f1ca:	f3bf 8f6f 	isb	sy
}
    f1ce:	4770      	bx	lr

0000f1d0 <onoff_started_callback>:
{
    f1d0:	b410      	push	{r4}
	notify(mgr, 0);
    f1d2:	241c      	movs	r4, #28
	return &data->mgr[type];
    f1d4:	68c0      	ldr	r0, [r0, #12]
    f1d6:	b2cb      	uxtb	r3, r1
	notify(mgr, 0);
    f1d8:	fb03 0004 	mla	r0, r3, r4, r0
    f1dc:	2100      	movs	r1, #0
}
    f1de:	bc10      	pop	{r4}
	notify(mgr, 0);
    f1e0:	4710      	bx	r2

0000f1e2 <blocking_start_callback>:
{
    f1e2:	4610      	mov	r0, r2
		arch_syscall_invoke1(*(uintptr_t *)&sem, K_SYSCALL_K_SEM_GIVE);
		return;
	}
#endif
	compiler_barrier();
	z_impl_k_sem_give(sem);
    f1e4:	f7ff bb8a 	b.w	e8fc <z_impl_k_sem_give>

0000f1e8 <lfclk_stop>:
    nrfx_clock_stop(NRF_CLOCK_DOMAIN_LFCLK);
    f1e8:	2000      	movs	r0, #0
    f1ea:	f7fe bead 	b.w	df48 <nrfx_clock_stop>

0000f1ee <lfclk_start>:
    nrfx_clock_start(NRF_CLOCK_DOMAIN_LFCLK);
    f1ee:	2000      	movs	r0, #0
    f1f0:	f7fe be78 	b.w	dee4 <nrfx_clock_start>

0000f1f4 <api_stop>:
{
    f1f4:	b538      	push	{r3, r4, r5, lr}
	err = set_off_state(&subdata->flags, ctx);
    f1f6:	230c      	movs	r3, #12
    f1f8:	b2cc      	uxtb	r4, r1
    f1fa:	4363      	muls	r3, r4
{
    f1fc:	4605      	mov	r5, r0
	err = set_off_state(&subdata->flags, ctx);
    f1fe:	68c0      	ldr	r0, [r0, #12]
    f200:	3340      	adds	r3, #64	; 0x40
    f202:	2180      	movs	r1, #128	; 0x80
    f204:	4418      	add	r0, r3
    f206:	f7ff ff99 	bl	f13c <set_off_state>
	if (err < 0) {
    f20a:	2800      	cmp	r0, #0
    f20c:	db05      	blt.n	f21a <api_stop+0x26>
	get_sub_config(dev, type)->stop();
    f20e:	6869      	ldr	r1, [r5, #4]
    f210:	eb01 04c4 	add.w	r4, r1, r4, lsl #3
    f214:	6863      	ldr	r3, [r4, #4]
    f216:	4798      	blx	r3
	return 0;
    f218:	2000      	movs	r0, #0
}
    f21a:	bd38      	pop	{r3, r4, r5, pc}

0000f21c <api_start>:
{
    f21c:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	err = set_starting_state(&subdata->flags, ctx);
    f220:	f04f 080c 	mov.w	r8, #12
    f224:	b2cd      	uxtb	r5, r1
    f226:	fb08 f805 	mul.w	r8, r8, r5
	struct nrf_clock_control_sub_data *subdata = get_sub_data(dev, type);
    f22a:	68c4      	ldr	r4, [r0, #12]
{
    f22c:	4606      	mov	r6, r0
	err = set_starting_state(&subdata->flags, ctx);
    f22e:	f108 0040 	add.w	r0, r8, #64	; 0x40
    f232:	2180      	movs	r1, #128	; 0x80
    f234:	4420      	add	r0, r4
{
    f236:	4617      	mov	r7, r2
	err = set_starting_state(&subdata->flags, ctx);
    f238:	f7ff ff99 	bl	f16e <set_starting_state>
	if (err < 0) {
    f23c:	2800      	cmp	r0, #0
    f23e:	db09      	blt.n	f254 <api_start+0x38>
	subdata->cb = data->cb;
    f240:	687b      	ldr	r3, [r7, #4]
    f242:	4444      	add	r4, r8
    f244:	63a3      	str	r3, [r4, #56]	; 0x38
	subdata->user_data = data->user_data;
    f246:	68bb      	ldr	r3, [r7, #8]
    f248:	63e3      	str	r3, [r4, #60]	; 0x3c
	 get_sub_config(dev, type)->start();
    f24a:	6873      	ldr	r3, [r6, #4]
    f24c:	f853 3035 	ldr.w	r3, [r3, r5, lsl #3]
    f250:	4798      	blx	r3
	return 0;
    f252:	2000      	movs	r0, #0
}
    f254:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}

0000f258 <z_clock_isr>:
/* Weak-linked noop defaults for optional driver interfaces: */

void __weak z_clock_isr(void *arg)
{
	__ASSERT_NO_MSG(false);
}
    f258:	4770      	bx	lr

0000f25a <z_clock_idle_exit>:
{
}

void __weak z_clock_idle_exit(void)
{
}
    f25a:	4770      	bx	lr

0000f25c <z_irq_spurious>:
 */
void z_irq_spurious(const void *unused)
{
	ARG_UNUSED(unused);

	z_arm_fatal_error(K_ERR_SPURIOUS_IRQ, NULL);
    f25c:	2100      	movs	r1, #0
    f25e:	2001      	movs	r0, #1
    f260:	f000 b804 	b.w	f26c <z_arm_fatal_error>

0000f264 <configure_builtin_stack_guard>:
  __ASM volatile ("MSR psplim, %0" : : "r" (ProcStackPtrLimit));
    f264:	6e83      	ldr	r3, [r0, #104]	; 0x68
    f266:	f383 880b 	msr	PSPLIM, r3
}
    f26a:	4770      	bx	lr

0000f26c <z_arm_fatal_error>:
{

	if (esf != NULL) {
		esf_dump(esf);
	}
	z_fatal_error(reason, esf);
    f26c:	f000 b961 	b.w	f532 <z_fatal_error>

0000f270 <z_do_kernel_oops>:
 *   fault handler will executed insted of the SVC.
 *
 * @param esf exception frame
 */
void z_do_kernel_oops(const z_arch_esf_t *esf)
{
    f270:	4601      	mov	r1, r0
	z_fatal_error(reason, esf);
    f272:	6800      	ldr	r0, [r0, #0]
    f274:	f000 b95d 	b.w	f532 <z_fatal_error>

0000f278 <z_arm_nmi>:
 *
 * @return N/A
 */

void z_arm_nmi(void)
{
    f278:	b508      	push	{r3, lr}
	handler();
    f27a:	f7fd ff89 	bl	d190 <z_SysNmiOnReset>
	z_arm_int_exit();
}
    f27e:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
	z_arm_int_exit();
    f282:	f7fe b8c3 	b.w	d40c <z_arm_exc_exit>

0000f286 <mpu_configure_region>:
{
    f286:	b530      	push	{r4, r5, lr}
	get_region_attr_from_k_mem_partition_info(&region_conf.attr,
    f288:	684b      	ldr	r3, [r1, #4]
	region_conf.base = new_region->start;
    f28a:	680c      	ldr	r4, [r1, #0]
{
    f28c:	b085      	sub	sp, #20
	p_attr->rbar = attr->rbar &
    f28e:	890a      	ldrh	r2, [r1, #8]
    f290:	7a8d      	ldrb	r5, [r1, #10]
	region_conf.base = new_region->start;
    f292:	9400      	str	r4, [sp, #0]
	p_attr->r_limit = REGION_LIMIT_ADDR(base, size);
    f294:	3b01      	subs	r3, #1
    f296:	f024 041f 	bic.w	r4, r4, #31
    f29a:	4423      	add	r3, r4
	p_attr->rbar = attr->rbar &
    f29c:	f002 021f 	and.w	r2, r2, #31
    f2a0:	ea42 1245 	orr.w	r2, r2, r5, lsl #5
	p_attr->r_limit = REGION_LIMIT_ADDR(base, size);
    f2a4:	f023 031f 	bic.w	r3, r3, #31
	if (index > (get_num_regions() - 1)) {
    f2a8:	280f      	cmp	r0, #15
    f2aa:	4604      	mov	r4, r0
	p_attr->rbar = attr->rbar &
    f2ac:	f88d 2008 	strb.w	r2, [sp, #8]
	p_attr->r_limit = REGION_LIMIT_ADDR(base, size);
    f2b0:	9303      	str	r3, [sp, #12]
    f2b2:	d805      	bhi.n	f2c0 <mpu_configure_region+0x3a>
	region_init(index, region_conf);
    f2b4:	4669      	mov	r1, sp
    f2b6:	f7fe f92b 	bl	d510 <region_init>
}
    f2ba:	4620      	mov	r0, r4
    f2bc:	b005      	add	sp, #20
    f2be:	bd30      	pop	{r4, r5, pc}
		return -EINVAL;
    f2c0:	f06f 0415 	mvn.w	r4, #21
	return region_allocate_and_init(index,
    f2c4:	e7f9      	b.n	f2ba <mpu_configure_region+0x34>

0000f2c6 <arm_cmse_mpu_region_get>:
__CMSE_TT_ASM ()

__extension__ static __inline __attribute__ ((__always_inline__))
cmse_address_info_t
cmse_TT (void *__p)
__CMSE_TT_ASM ()
    f2c6:	e840 f300 	tt	r3, r0

int arm_cmse_mpu_region_get(uint32_t addr)
{
	cmse_address_info_t addr_info =	cmse_TT((void *)addr);

	if (addr_info.flags.mpu_region_valid) {
    f2ca:	f413 3f80 	tst.w	r3, #65536	; 0x10000
    f2ce:	b2d8      	uxtb	r0, r3
		return addr_info.flags.mpu_region;
	}

	return -EINVAL;
}
    f2d0:	bf08      	it	eq
    f2d2:	f06f 0015 	mvneq.w	r0, #21
    f2d6:	4770      	bx	lr

0000f2d8 <strcmp>:
 * @return negative # if <s1> < <s2>, 0 if <s1> == <s2>, else positive #
 */

int strcmp(const char *s1, const char *s2)
{
	while ((*s1 == *s2) && (*s1 != '\0')) {
    f2d8:	1e43      	subs	r3, r0, #1
    f2da:	3901      	subs	r1, #1
    f2dc:	f813 2f01 	ldrb.w	r2, [r3, #1]!
    f2e0:	f811 0f01 	ldrb.w	r0, [r1, #1]!
    f2e4:	4282      	cmp	r2, r0
    f2e6:	d101      	bne.n	f2ec <strcmp+0x14>
    f2e8:	2a00      	cmp	r2, #0
    f2ea:	d1f7      	bne.n	f2dc <strcmp+0x4>
		s1++;
		s2++;
	}

	return *s1 - *s2;
}
    f2ec:	1a10      	subs	r0, r2, r0
    f2ee:	4770      	bx	lr

0000f2f0 <memcmp>:
 * @brief Compare two memory areas
 *
 * @return negative # if <m1> < <m2>, 0 if <m1> == <m2>, else positive #
 */
int memcmp(const void *m1, const void *m2, size_t n)
{
    f2f0:	b510      	push	{r4, lr}
	const char *c1 = m1;
	const char *c2 = m2;

	if (!n) {
    f2f2:	b15a      	cbz	r2, f30c <memcmp+0x1c>
    f2f4:	3901      	subs	r1, #1
    f2f6:	1884      	adds	r4, r0, r2
		return 0;
	}

	while ((--n > 0) && (*c1 == *c2)) {
    f2f8:	f810 2b01 	ldrb.w	r2, [r0], #1
    f2fc:	f811 3f01 	ldrb.w	r3, [r1, #1]!
    f300:	42a0      	cmp	r0, r4
    f302:	d001      	beq.n	f308 <memcmp+0x18>
    f304:	429a      	cmp	r2, r3
    f306:	d0f7      	beq.n	f2f8 <memcmp+0x8>
		c1++;
		c2++;
	}

	return *c1 - *c2;
    f308:	1ad0      	subs	r0, r2, r3
}
    f30a:	bd10      	pop	{r4, pc}
		return 0;
    f30c:	4610      	mov	r0, r2
    f30e:	e7fc      	b.n	f30a <memcmp+0x1a>

0000f310 <memcpy>:
 *
 * @return pointer to start of destination buffer
 */

void *memcpy(void *_MLIBC_RESTRICT d, const void *_MLIBC_RESTRICT s, size_t n)
{
    f310:	b5f0      	push	{r4, r5, r6, r7, lr}

	unsigned char *d_byte = (unsigned char *)d;
	const unsigned char *s_byte = (const unsigned char *)s;
	const uintptr_t mask = sizeof(mem_word_t) - 1;

	if ((((uintptr_t)d ^ (uintptr_t)s_byte) & mask) == 0) {
    f312:	ea81 0400 	eor.w	r4, r1, r0
    f316:	07a5      	lsls	r5, r4, #30
    f318:	4603      	mov	r3, r0
    f31a:	d00b      	beq.n	f334 <memcpy+0x24>
    f31c:	3b01      	subs	r3, #1
    f31e:	440a      	add	r2, r1
		s_byte = (unsigned char *)s_word;
	}

	/* do byte-sized copying until finished */

	while (n > 0) {
    f320:	4291      	cmp	r1, r2
    f322:	d11b      	bne.n	f35c <memcpy+0x4c>
		*(d_byte++) = *(s_byte++);
		n--;
	}

	return d;
}
    f324:	bdf0      	pop	{r4, r5, r6, r7, pc}
			if (n == 0) {
    f326:	2a00      	cmp	r2, #0
    f328:	d0fc      	beq.n	f324 <memcpy+0x14>
			*(d_byte++) = *(s_byte++);
    f32a:	f811 4b01 	ldrb.w	r4, [r1], #1
			n--;
    f32e:	3a01      	subs	r2, #1
			*(d_byte++) = *(s_byte++);
    f330:	f803 4b01 	strb.w	r4, [r3], #1
		while (((uintptr_t)d_byte) & mask) {
    f334:	079c      	lsls	r4, r3, #30
    f336:	d1f6      	bne.n	f326 <memcpy+0x16>
    f338:	f022 0403 	bic.w	r4, r2, #3
    f33c:	1f1d      	subs	r5, r3, #4
    f33e:	0896      	lsrs	r6, r2, #2
    f340:	190f      	adds	r7, r1, r4
		while (n >= sizeof(mem_word_t)) {
    f342:	42b9      	cmp	r1, r7
    f344:	d105      	bne.n	f352 <memcpy+0x42>
    f346:	f06f 0503 	mvn.w	r5, #3
    f34a:	4423      	add	r3, r4
    f34c:	fb05 2206 	mla	r2, r5, r6, r2
    f350:	e7e4      	b.n	f31c <memcpy+0xc>
			*(d_word++) = *(s_word++);
    f352:	f851 cb04 	ldr.w	ip, [r1], #4
    f356:	f845 cf04 	str.w	ip, [r5, #4]!
			n -= sizeof(mem_word_t);
    f35a:	e7f2      	b.n	f342 <memcpy+0x32>
		*(d_byte++) = *(s_byte++);
    f35c:	f811 4b01 	ldrb.w	r4, [r1], #1
    f360:	f803 4f01 	strb.w	r4, [r3, #1]!
		n--;
    f364:	e7dc      	b.n	f320 <memcpy+0x10>

0000f366 <memset>:

void *memset(void *buf, int c, size_t n)
{
	/* do byte-sized initialization until word-aligned or finished */

	unsigned char *d_byte = (unsigned char *)buf;
    f366:	4603      	mov	r3, r0
{
    f368:	b570      	push	{r4, r5, r6, lr}
	unsigned char c_byte = (unsigned char)c;
    f36a:	b2c9      	uxtb	r1, r1

	while (((uintptr_t)d_byte) & (sizeof(mem_word_t) - 1)) {
    f36c:	079c      	lsls	r4, r3, #30
    f36e:	d111      	bne.n	f394 <memset+0x2e>
	/* do word-sized initialization as long as possible */

	mem_word_t *d_word = (mem_word_t *)d_byte;
	mem_word_t c_word = (mem_word_t)c_byte;

	c_word |= c_word << 8;
    f370:	ea41 2401 	orr.w	r4, r1, r1, lsl #8
	c_word |= c_word << 16;
    f374:	f022 0603 	bic.w	r6, r2, #3
    f378:	ea44 4504 	orr.w	r5, r4, r4, lsl #16
#if Z_MEM_WORD_T_WIDTH > 32
	c_word |= c_word << 32;
#endif

	while (n >= sizeof(mem_word_t)) {
    f37c:	441e      	add	r6, r3
    f37e:	0894      	lsrs	r4, r2, #2
    f380:	42b3      	cmp	r3, r6
    f382:	d10d      	bne.n	f3a0 <memset+0x3a>
    f384:	f06f 0503 	mvn.w	r5, #3
    f388:	fb05 2204 	mla	r2, r5, r4, r2
    f38c:	441a      	add	r2, r3

	/* do byte-sized initialization until finished */

	d_byte = (unsigned char *)d_word;

	while (n > 0) {
    f38e:	4293      	cmp	r3, r2
    f390:	d109      	bne.n	f3a6 <memset+0x40>
		*(d_byte++) = c_byte;
		n--;
	}

	return buf;
}
    f392:	bd70      	pop	{r4, r5, r6, pc}
		if (n == 0) {
    f394:	2a00      	cmp	r2, #0
    f396:	d0fc      	beq.n	f392 <memset+0x2c>
		*(d_byte++) = c_byte;
    f398:	f803 1b01 	strb.w	r1, [r3], #1
		n--;
    f39c:	3a01      	subs	r2, #1
    f39e:	e7e5      	b.n	f36c <memset+0x6>
		*(d_word++) = c_word;
    f3a0:	f843 5b04 	str.w	r5, [r3], #4
		n -= sizeof(mem_word_t);
    f3a4:	e7ec      	b.n	f380 <memset+0x1a>
		*(d_byte++) = c_byte;
    f3a6:	f803 1b01 	strb.w	r1, [r3], #1
		n--;
    f3aa:	e7f0      	b.n	f38e <memset+0x28>

0000f3ac <_stdout_hook_default>:
}
    f3ac:	f04f 30ff 	mov.w	r0, #4294967295
    f3b0:	4770      	bx	lr

0000f3b2 <gpio_nrfx_port_get_raw>:
	NRF_GPIO_Type *reg = get_port_cfg(port)->port;
    f3b2:	6843      	ldr	r3, [r0, #4]
}
    f3b4:	2000      	movs	r0, #0
	NRF_GPIO_Type *reg = get_port_cfg(port)->port;
    f3b6:	685b      	ldr	r3, [r3, #4]
    return p_reg->IN;
    f3b8:	691b      	ldr	r3, [r3, #16]
	*value = nrf_gpio_port_in_read(reg);
    f3ba:	600b      	str	r3, [r1, #0]
}
    f3bc:	4770      	bx	lr

0000f3be <gpio_nrfx_port_set_masked_raw>:
	NRF_GPIO_Type *reg = get_port_cfg(port)->port;
    f3be:	6843      	ldr	r3, [r0, #4]
    f3c0:	685b      	ldr	r3, [r3, #4]
    return p_reg->OUT;
    f3c2:	6858      	ldr	r0, [r3, #4]
	nrf_gpio_port_out_write(reg, value_tmp | (mask & value));
    f3c4:	4042      	eors	r2, r0
    f3c6:	400a      	ands	r2, r1
    f3c8:	4042      	eors	r2, r0
    p_reg->OUT = value;
    f3ca:	605a      	str	r2, [r3, #4]
}
    f3cc:	2000      	movs	r0, #0
    f3ce:	4770      	bx	lr

0000f3d0 <gpio_nrfx_port_set_bits_raw>:
	NRF_GPIO_Type *reg = get_port_cfg(port)->port;
    f3d0:	6843      	ldr	r3, [r0, #4]
}
    f3d2:	2000      	movs	r0, #0
	NRF_GPIO_Type *reg = get_port_cfg(port)->port;
    f3d4:	685b      	ldr	r3, [r3, #4]
    p_reg->OUTSET = set_mask;
    f3d6:	6099      	str	r1, [r3, #8]
}
    f3d8:	4770      	bx	lr

0000f3da <gpio_nrfx_port_clear_bits_raw>:
	NRF_GPIO_Type *reg = get_port_cfg(port)->port;
    f3da:	6843      	ldr	r3, [r0, #4]
}
    f3dc:	2000      	movs	r0, #0
	NRF_GPIO_Type *reg = get_port_cfg(port)->port;
    f3de:	685b      	ldr	r3, [r3, #4]
    p_reg->OUTCLR = clr_mask;
    f3e0:	60d9      	str	r1, [r3, #12]
}
    f3e2:	4770      	bx	lr

0000f3e4 <gpio_nrfx_port_toggle_bits>:
	NRF_GPIO_Type *reg = get_port_cfg(port)->port;
    f3e4:	6843      	ldr	r3, [r0, #4]
}
    f3e6:	2000      	movs	r0, #0
	NRF_GPIO_Type *reg = get_port_cfg(port)->port;
    f3e8:	685a      	ldr	r2, [r3, #4]
    return p_reg->OUT;
    f3ea:	6853      	ldr	r3, [r2, #4]
	nrf_gpio_port_out_write(reg, value ^ mask);
    f3ec:	404b      	eors	r3, r1
    p_reg->OUT = value;
    f3ee:	6053      	str	r3, [r2, #4]
}
    f3f0:	4770      	bx	lr

0000f3f2 <gpio_nrfx_manage_callback>:
	return gpio_manage_callback(&get_port_data(port)->callbacks,
    f3f2:	68c3      	ldr	r3, [r0, #12]
{
    f3f4:	b530      	push	{r4, r5, lr}
Z_GENLIST_IS_EMPTY(slist)
    f3f6:	6858      	ldr	r0, [r3, #4]
	if (!sys_slist_is_empty(callbacks)) {
    f3f8:	b158      	cbz	r0, f412 <gpio_nrfx_manage_callback+0x20>
 * @return true if node was removed
 */
static inline bool sys_slist_find_and_remove(sys_slist_t *list,
					     sys_snode_t *node);

Z_GENLIST_FIND_AND_REMOVE(slist, snode)
    f3fa:	2400      	movs	r4, #0
    f3fc:	4281      	cmp	r1, r0
    f3fe:	d113      	bne.n	f428 <gpio_nrfx_manage_callback+0x36>
Z_GENLIST_REMOVE(slist, snode)
    f400:	6808      	ldr	r0, [r1, #0]
    f402:	b95c      	cbnz	r4, f41c <gpio_nrfx_manage_callback+0x2a>
    f404:	689c      	ldr	r4, [r3, #8]
	list->head = node;
    f406:	6058      	str	r0, [r3, #4]
Z_GENLIST_REMOVE(slist, snode)
    f408:	42a1      	cmp	r1, r4
    f40a:	d100      	bne.n	f40e <gpio_nrfx_manage_callback+0x1c>
	list->tail = node;
    f40c:	6098      	str	r0, [r3, #8]
	parent->next = child;
    f40e:	2000      	movs	r0, #0
    f410:	6008      	str	r0, [r1, #0]
	if (set) {
    f412:	b972      	cbnz	r2, f432 <gpio_nrfx_manage_callback+0x40>
	return 0;
    f414:	2000      	movs	r0, #0
}
    f416:	bd30      	pop	{r4, r5, pc}
    f418:	4628      	mov	r0, r5
    f41a:	e7ef      	b.n	f3fc <gpio_nrfx_manage_callback+0xa>
    f41c:	6020      	str	r0, [r4, #0]
Z_GENLIST_REMOVE(slist, snode)
    f41e:	6898      	ldr	r0, [r3, #8]
    f420:	4281      	cmp	r1, r0
	list->tail = node;
    f422:	bf08      	it	eq
    f424:	609c      	streq	r4, [r3, #8]
}
    f426:	e7f2      	b.n	f40e <gpio_nrfx_manage_callback+0x1c>
Z_GENLIST_PEEK_NEXT_NO_CHECK(slist, snode)
    f428:	6805      	ldr	r5, [r0, #0]
Z_GENLIST_FIND_AND_REMOVE(slist, snode)
    f42a:	4604      	mov	r4, r0
    f42c:	2d00      	cmp	r5, #0
    f42e:	d1f3      	bne.n	f418 <gpio_nrfx_manage_callback+0x26>
			if (!set) {
    f430:	b13a      	cbz	r2, f442 <gpio_nrfx_manage_callback+0x50>
Z_GENLIST_PREPEND(slist, snode)
    f432:	685a      	ldr	r2, [r3, #4]
	parent->next = child;
    f434:	600a      	str	r2, [r1, #0]
Z_GENLIST_PREPEND(slist, snode)
    f436:	6898      	ldr	r0, [r3, #8]
	list->head = node;
    f438:	6059      	str	r1, [r3, #4]
Z_GENLIST_PREPEND(slist, snode)
    f43a:	2800      	cmp	r0, #0
    f43c:	d1ea      	bne.n	f414 <gpio_nrfx_manage_callback+0x22>
	list->tail = node;
    f43e:	6099      	str	r1, [r3, #8]
}
    f440:	e7e9      	b.n	f416 <gpio_nrfx_manage_callback+0x24>
				return -EINVAL;
    f442:	f06f 0015 	mvn.w	r0, #21
	return gpio_manage_callback(&get_port_data(port)->callbacks,
    f446:	e7e6      	b.n	f416 <gpio_nrfx_manage_callback+0x24>

0000f448 <uarte_nrfx_config_get>:
{
    f448:	460b      	mov	r3, r1
	*cfg = get_dev_data(dev)->uart_config;
    f44a:	68c2      	ldr	r2, [r0, #12]
    f44c:	e9d2 0101 	ldrd	r0, r1, [r2, #4]
    f450:	e883 0003 	stmia.w	r3, {r0, r1}
}
    f454:	2000      	movs	r0, #0
    f456:	4770      	bx	lr

0000f458 <uarte_nrfx_err_check>:
	return config->uarte_regs;
    f458:	6843      	ldr	r3, [r0, #4]
    f45a:	681b      	ldr	r3, [r3, #0]
    uint32_t errsrc_mask = p_reg->ERRORSRC;
    f45c:	f8d3 0480 	ldr.w	r0, [r3, #1152]	; 0x480
    p_reg->ERRORSRC = errsrc_mask;
    f460:	f8c3 0480 	str.w	r0, [r3, #1152]	; 0x480
}
    f464:	4770      	bx	lr

0000f466 <uarte_nrfx_poll_in>:
	return config->uarte_regs;
    f466:	6843      	ldr	r3, [r0, #4]
	const struct uarte_nrfx_data *data = get_dev_data(dev);
    f468:	68c2      	ldr	r2, [r0, #12]
	return config->uarte_regs;
    f46a:	681b      	ldr	r3, [r3, #0]
    return (bool)*(volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event);
    f46c:	f8d3 0110 	ldr.w	r0, [r3, #272]	; 0x110
	if (!nrf_uarte_event_check(uarte, NRF_UARTE_EVENT_ENDRX)) {
    f470:	b148      	cbz	r0, f486 <uarte_nrfx_poll_in+0x20>
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0x0UL;
    f472:	2000      	movs	r0, #0
	*c = data->rx_data;
    f474:	7c12      	ldrb	r2, [r2, #16]
    f476:	700a      	strb	r2, [r1, #0]
    f478:	f8c3 0110 	str.w	r0, [r3, #272]	; 0x110
    f47c:	f8d3 2110 	ldr.w	r2, [r3, #272]	; 0x110
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)task)) = 0x1UL;
    f480:	2201      	movs	r2, #1
    f482:	601a      	str	r2, [r3, #0]
	return 0;
    f484:	4770      	bx	lr
		return -1;
    f486:	f04f 30ff 	mov.w	r0, #4294967295
}
    f48a:	4770      	bx	lr

0000f48c <uarte_nrfx_poll_out>:
{
    f48c:	e92d 41f3 	stmdb	sp!, {r0, r1, r4, r5, r6, r7, r8, lr}
	return config->uarte_regs;
    f490:	6843      	ldr	r3, [r0, #4]
{
    f492:	f88d 1007 	strb.w	r1, [sp, #7]
	return config->uarte_regs;
    f496:	681c      	ldr	r4, [r3, #0]
	struct uarte_nrfx_data *data = get_dev_data(dev);
    f498:	68c6      	ldr	r6, [r0, #12]
	if (!k_is_in_isr()) {
    f49a:	f000 f913 	bl	f6c4 <k_is_in_isr>
    f49e:	bb98      	cbnz	r0, f508 <uarte_nrfx_poll_out+0x7c>
		lock = &data->poll_out_lock;
    f4a0:	2564      	movs	r5, #100	; 0x64
	return __atomic_compare_exchange_n(target, &old_value, new_value,
    f4a2:	f04f 0801 	mov.w	r8, #1
    f4a6:	f106 070c 	add.w	r7, r6, #12
    f4aa:	e8d7 3fef 	ldaex	r3, [r7]
    f4ae:	2b00      	cmp	r3, #0
    f4b0:	d103      	bne.n	f4ba <uarte_nrfx_poll_out+0x2e>
    f4b2:	e8c7 8fe2 	stlex	r2, r8, [r7]
    f4b6:	2a00      	cmp	r2, #0
    f4b8:	d1f7      	bne.n	f4aa <uarte_nrfx_poll_out+0x1e>
		while (atomic_cas((atomic_t *) lock,
    f4ba:	d007      	beq.n	f4cc <uarte_nrfx_poll_out+0x40>
	return z_impl_k_sleep(timeout);
    f4bc:	2021      	movs	r0, #33	; 0x21
    f4be:	2100      	movs	r1, #0
    f4c0:	3d01      	subs	r5, #1
    f4c2:	f7ff f9f5 	bl	e8b0 <z_impl_k_sleep>
			if (--safety_cnt == 0) {
    f4c6:	f015 05ff 	ands.w	r5, r5, #255	; 0xff
    f4ca:	d1ee      	bne.n	f4aa <uarte_nrfx_poll_out+0x1e>
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0x0UL;
    f4cc:	2300      	movs	r3, #0
    f4ce:	f8c4 3120 	str.w	r3, [r4, #288]	; 0x120
    f4d2:	f8d4 3120 	ldr.w	r3, [r4, #288]	; 0x120
    p_reg->TXD.PTR    = (uint32_t)p_buffer;
    f4d6:	f10d 0307 	add.w	r3, sp, #7
    f4da:	f8c4 3544 	str.w	r3, [r4, #1348]	; 0x544
    p_reg->TXD.MAXCNT = length;
    f4de:	2301      	movs	r3, #1
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)task)) = 0x1UL;
    f4e0:	f44f 757a 	mov.w	r5, #1000	; 0x3e8
    p_reg->TXD.MAXCNT = length;
    f4e4:	f8c4 3548 	str.w	r3, [r4, #1352]	; 0x548
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)task)) = 0x1UL;
    f4e8:	60a3      	str	r3, [r4, #8]
    return (bool)*(volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event);
    f4ea:	f8d4 3120 	ldr.w	r3, [r4, #288]	; 0x120
	NRFX_WAIT_FOR(nrf_uarte_event_check(uarte, NRF_UARTE_EVENT_ENDTX),
    f4ee:	b923      	cbnz	r3, f4fa <uarte_nrfx_poll_out+0x6e>
    f4f0:	2001      	movs	r0, #1
    f4f2:	f000 f811 	bl	f518 <nrfx_busy_wait>
    f4f6:	3d01      	subs	r5, #1
    f4f8:	d1f7      	bne.n	f4ea <uarte_nrfx_poll_out+0x5e>
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)task)) = 0x1UL;
    f4fa:	2301      	movs	r3, #1
    f4fc:	60e3      	str	r3, [r4, #12]
	*lock = 0;
    f4fe:	2300      	movs	r3, #0
    f500:	60f3      	str	r3, [r6, #12]
}
    f502:	b002      	add	sp, #8
    f504:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
		*lock = 1;
    f508:	2301      	movs	r3, #1
    f50a:	60f3      	str	r3, [r6, #12]
    f50c:	e7de      	b.n	f4cc <uarte_nrfx_poll_out+0x40>

0000f50e <k_sys_fatal_error_handler>:
	ARG_UNUSED(reason);

	LOG_PANIC();

	LOG_ERR("Resetting system");
	sys_arch_reboot(0);
    f50e:	2000      	movs	r0, #0
{
    f510:	b508      	push	{r3, lr}
	sys_arch_reboot(0);
    f512:	f7fd ff89 	bl	d428 <sys_arch_reboot>

0000f516 <nrfx_isr>:
#include <nrfx.h>
#include <kernel.h>

void nrfx_isr(const void *irq_handler)
{
	((nrfx_irq_handler_t)irq_handler)();
    f516:	4700      	bx	r0

0000f518 <nrfx_busy_wait>:
	z_impl_k_busy_wait(usec_to_wait);
    f518:	f000 b8da 	b.w	f6d0 <z_impl_k_busy_wait>

0000f51c <nrfx_clock_enable>:
{
    f51c:	b508      	push	{r3, lr}
    priority = NRFX_CLOCK_DEFAULT_CONFIG_IRQ_PRIORITY;
#else
    #error "This code is not supposed to be compiled when neither POWER nor CLOCK is enabled."
#endif

    if (!NRFX_IRQ_IS_ENABLED(nrfx_get_irq_number(NRF_CLOCK)))
    f51e:	2005      	movs	r0, #5
    f520:	f7fd fdbe 	bl	d0a0 <arch_irq_is_enabled>
    f524:	b920      	cbnz	r0, f530 <nrfx_clock_enable+0x14>
}
    f526:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
    {
        NRFX_IRQ_PRIORITY_SET(nrfx_get_irq_number(NRF_CLOCK), priority);
        NRFX_IRQ_ENABLE(nrfx_get_irq_number(NRF_CLOCK));
    f52a:	2005      	movs	r0, #5
    f52c:	f7fd bda8 	b.w	d080 <arch_irq_enable>
    f530:	bd08      	pop	{r3, pc}

0000f532 <z_fatal_error>:
	return 0;
#endif
}

void z_fatal_error(unsigned int reason, const z_arch_esf_t *esf)
{
    f532:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
    f534:	4605      	mov	r5, r0
    f536:	460e      	mov	r6, r1
	__asm__ volatile(
    f538:	f04f 0320 	mov.w	r3, #32
    f53c:	f3ef 8711 	mrs	r7, BASEPRI
    f540:	f383 8811 	msr	BASEPRI, r3
    f544:	f3bf 8f6f 	isb	sy
	return z_impl_k_current_get();
    f548:	f7ff f9d2 	bl	e8f0 <z_impl_k_current_get>
	LOG_ERR("Current thread: %p (%s)", thread,
		log_strdup(thread_name_get(thread)));

	z_coredump(reason, esf, thread);

	k_sys_fatal_error_handler(reason, esf);
    f54c:	4631      	mov	r1, r6
    f54e:	4604      	mov	r4, r0
    f550:	4628      	mov	r0, r5
    f552:	f7ff ffdc 	bl	f50e <k_sys_fatal_error_handler>
	__asm__ volatile(
    f556:	f387 8811 	msr	BASEPRI, r7
    f55a:	f3bf 8f6f 	isb	sy
	z_impl_k_thread_abort(thread);
    f55e:	4620      	mov	r0, r4
#endif /*CONFIG_ARCH_HAS_NESTED_EXCEPTION_DETECTION */
	}

	arch_irq_unlock(key);
	k_thread_abort(thread);
}
    f560:	e8bd 40f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, lr}
    f564:	f7fd bf7e 	b.w	d464 <z_impl_k_thread_abort>

0000f568 <z_sys_power_save_idle_exit>:
	z_clock_idle_exit();
    f568:	f7ff be77 	b.w	f25a <z_clock_idle_exit>

0000f56c <z_reschedule_irqlock>:
	return arch_irq_unlocked(key) && !arch_is_in_isr();
    f56c:	4603      	mov	r3, r0
    f56e:	b920      	cbnz	r0, f57a <z_reschedule_irqlock+0xe>
  __ASM volatile ("MRS %0, ipsr" : "=r" (result) );
    f570:	f3ef 8205 	mrs	r2, IPSR
    f574:	b90a      	cbnz	r2, f57a <z_reschedule_irqlock+0xe>
    f576:	f7fd bd2d 	b.w	cfd4 <arch_swap>
    f57a:	f383 8811 	msr	BASEPRI, r3
    f57e:	f3bf 8f6f 	isb	sy
}
    f582:	4770      	bx	lr

0000f584 <z_reschedule_unlocked>:
	__asm__ volatile(
    f584:	f04f 0320 	mov.w	r3, #32
    f588:	f3ef 8011 	mrs	r0, BASEPRI
    f58c:	f383 8811 	msr	BASEPRI, r3
    f590:	f3bf 8f6f 	isb	sy
	(void) z_reschedule_irqlock(arch_irq_lock());
    f594:	f7ff bfea 	b.w	f56c <z_reschedule_irqlock>

0000f598 <unpend_thread_no_timeout>:
{
    f598:	4601      	mov	r1, r0
    f59a:	b508      	push	{r3, lr}
	_priq_wait_remove(&pended_on(thread)->waitq, thread);
    f59c:	6880      	ldr	r0, [r0, #8]
    f59e:	f7fe fef7 	bl	e390 <z_priq_dumb_remove>
	thread->base.thread_state &= ~_THREAD_PENDING;
    f5a2:	7b4b      	ldrb	r3, [r1, #13]
    f5a4:	f023 0302 	bic.w	r3, r3, #2
    f5a8:	734b      	strb	r3, [r1, #13]
	thread->base.pended_on = NULL;
    f5aa:	2300      	movs	r3, #0
    f5ac:	608b      	str	r3, [r1, #8]
}
    f5ae:	bd08      	pop	{r3, pc}

0000f5b0 <z_priq_dumb_best>:
{
    f5b0:	4603      	mov	r3, r0
	return list->head == list;
    f5b2:	6800      	ldr	r0, [r0, #0]
	return sys_dlist_is_empty(list) ? NULL : list->head;
    f5b4:	4283      	cmp	r3, r0
    f5b6:	d003      	beq.n	f5c0 <z_priq_dumb_best+0x10>
	if (n != NULL) {
    f5b8:	2800      	cmp	r0, #0
    f5ba:	bf38      	it	cc
    f5bc:	2000      	movcc	r0, #0
    f5be:	4770      	bx	lr
	struct k_thread *thread = NULL;
    f5c0:	2000      	movs	r0, #0
}
    f5c2:	4770      	bx	lr

0000f5c4 <z_ready_thread>:
{
    f5c4:	b510      	push	{r4, lr}
    f5c6:	f04f 0320 	mov.w	r3, #32
    f5ca:	f3ef 8411 	mrs	r4, BASEPRI
    f5ce:	f383 8811 	msr	BASEPRI, r3
    f5d2:	f3bf 8f6f 	isb	sy
		ready_thread(thread);
    f5d6:	f7fe ff31 	bl	e43c <ready_thread>
	__asm__ volatile(
    f5da:	f384 8811 	msr	BASEPRI, r4
    f5de:	f3bf 8f6f 	isb	sy
}
    f5e2:	bd10      	pop	{r4, pc}

0000f5e4 <z_thread_timeout>:
{
    f5e4:	b570      	push	{r4, r5, r6, lr}
    f5e6:	4604      	mov	r4, r0
	__asm__ volatile(
    f5e8:	f04f 0320 	mov.w	r3, #32
    f5ec:	f3ef 8611 	mrs	r6, BASEPRI
    f5f0:	f383 8811 	msr	BASEPRI, r3
    f5f4:	f3bf 8f6f 	isb	sy
		if (thread->base.pended_on != NULL) {
    f5f8:	f850 3c10 	ldr.w	r3, [r0, #-16]
		struct k_thread *thread = CONTAINER_OF(timeout,
    f5fc:	f1a0 0518 	sub.w	r5, r0, #24
		if (thread->base.pended_on != NULL) {
    f600:	b113      	cbz	r3, f608 <z_thread_timeout+0x24>
			unpend_thread_no_timeout(thread);
    f602:	4628      	mov	r0, r5
    f604:	f7ff ffc8 	bl	f598 <unpend_thread_no_timeout>
	thread->base.thread_state &= ~_THREAD_SUSPENDED;
    f608:	f814 3c0b 	ldrb.w	r3, [r4, #-11]
		ready_thread(thread);
    f60c:	4628      	mov	r0, r5
    f60e:	f023 0314 	bic.w	r3, r3, #20
    f612:	f804 3c0b 	strb.w	r3, [r4, #-11]
    f616:	f7fe ff11 	bl	e43c <ready_thread>
	__asm__ volatile(
    f61a:	f386 8811 	msr	BASEPRI, r6
    f61e:	f3bf 8f6f 	isb	sy
}
    f622:	bd70      	pop	{r4, r5, r6, pc}

0000f624 <add_to_waitq_locked>:
{
    f624:	b538      	push	{r3, r4, r5, lr}
    f626:	4604      	mov	r4, r0
    f628:	460d      	mov	r5, r1
	unready_thread(thread);
    f62a:	f7ff f865 	bl	e6f8 <unready_thread>
	thread->base.thread_state |= _THREAD_PENDING;
    f62e:	7b63      	ldrb	r3, [r4, #13]
    f630:	f043 0302 	orr.w	r3, r3, #2
    f634:	7363      	strb	r3, [r4, #13]
	if (wait_q != NULL) {
    f636:	b1c5      	cbz	r5, f66a <add_to_waitq_locked+0x46>
	return list->head == list;
    f638:	682b      	ldr	r3, [r5, #0]
		thread->base.pended_on = wait_q;
    f63a:	60a5      	str	r5, [r4, #8]
	return sys_dlist_is_empty(list) ? NULL : list->head;
    f63c:	429d      	cmp	r5, r3
    f63e:	bf08      	it	eq
    f640:	2300      	moveq	r3, #0
    f642:	2b00      	cmp	r3, #0
    f644:	bf38      	it	cc
    f646:	2300      	movcc	r3, #0
	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
    f648:	b183      	cbz	r3, f66c <add_to_waitq_locked+0x48>
	if (thread_1->base.prio < thread_2->base.prio) {
    f64a:	f994 100e 	ldrsb.w	r1, [r4, #14]
    f64e:	f993 200e 	ldrsb.w	r2, [r3, #14]
    f652:	4291      	cmp	r1, r2
    f654:	db04      	blt.n	f660 <add_to_waitq_locked+0x3c>
	return (node == list->tail) ? NULL : node->next;
    f656:	686a      	ldr	r2, [r5, #4]
    f658:	429a      	cmp	r2, r3
    f65a:	d007      	beq.n	f66c <add_to_waitq_locked+0x48>
    f65c:	681b      	ldr	r3, [r3, #0]
    f65e:	e7f3      	b.n	f648 <add_to_waitq_locked+0x24>
	node->prev = successor->prev;
    f660:	685a      	ldr	r2, [r3, #4]
	node->next = successor;
    f662:	e9c4 3200 	strd	r3, r2, [r4]
	successor->prev->next = node;
    f666:	6014      	str	r4, [r2, #0]
	successor->prev = node;
    f668:	605c      	str	r4, [r3, #4]
}
    f66a:	bd38      	pop	{r3, r4, r5, pc}
	node->prev = list->tail;
    f66c:	686b      	ldr	r3, [r5, #4]
	node->next = list;
    f66e:	6025      	str	r5, [r4, #0]
	node->prev = list->tail;
    f670:	6063      	str	r3, [r4, #4]
	list->tail->next = node;
    f672:	686b      	ldr	r3, [r5, #4]
    f674:	601c      	str	r4, [r3, #0]
	list->tail = node;
    f676:	606c      	str	r4, [r5, #4]
    f678:	e7f7      	b.n	f66a <add_to_waitq_locked+0x46>

0000f67a <z_unpend_first_thread>:
{
    f67a:	b538      	push	{r3, r4, r5, lr}
	__asm__ volatile(
    f67c:	f04f 0320 	mov.w	r3, #32
    f680:	f3ef 8211 	mrs	r2, BASEPRI
    f684:	f383 8811 	msr	BASEPRI, r3
    f688:	f3bf 8f6f 	isb	sy
		ret = _priq_wait_best(&wait_q->waitq);
    f68c:	f7ff ff90 	bl	f5b0 <z_priq_dumb_best>
    f690:	4604      	mov	r4, r0
	__asm__ volatile(
    f692:	f382 8811 	msr	BASEPRI, r2
    f696:	f3bf 8f6f 	isb	sy

static inline struct k_thread *z_unpend1_no_timeout(_wait_q_t *wait_q)
{
	struct k_thread *thread = z_find_first_thread_to_unpend(wait_q, NULL);

	if (thread != NULL) {
    f69a:	b188      	cbz	r0, f6c0 <z_unpend_first_thread+0x46>
	__asm__ volatile(
    f69c:	f04f 0320 	mov.w	r3, #32
    f6a0:	f3ef 8511 	mrs	r5, BASEPRI
    f6a4:	f383 8811 	msr	BASEPRI, r3
    f6a8:	f3bf 8f6f 	isb	sy
		unpend_thread_no_timeout(thread);
    f6ac:	f7ff ff74 	bl	f598 <unpend_thread_no_timeout>
	__asm__ volatile(
    f6b0:	f385 8811 	msr	BASEPRI, r5
    f6b4:	f3bf 8f6f 	isb	sy
	return z_abort_timeout(&thread->base.timeout);
    f6b8:	f104 0018 	add.w	r0, r4, #24
    f6bc:	f000 f80a 	bl	f6d4 <z_abort_timeout>
}
    f6c0:	4620      	mov	r0, r4
    f6c2:	bd38      	pop	{r3, r4, r5, pc}

0000f6c4 <k_is_in_isr>:
    f6c4:	f3ef 8005 	mrs	r0, IPSR
}
    f6c8:	3800      	subs	r0, #0
    f6ca:	bf18      	it	ne
    f6cc:	2001      	movne	r0, #1
    f6ce:	4770      	bx	lr

0000f6d0 <z_impl_k_busy_wait>:
	arch_busy_wait(usec_to_wait);
    f6d0:	f7fd b9ee 	b.w	cab0 <arch_busy_wait>

0000f6d4 <z_abort_timeout>:
{
    f6d4:	b510      	push	{r4, lr}
	__asm__ volatile(
    f6d6:	f04f 0220 	mov.w	r2, #32
    f6da:	f3ef 8411 	mrs	r4, BASEPRI
    f6de:	f382 8811 	msr	BASEPRI, r2
    f6e2:	f3bf 8f6f 	isb	sy
		if (sys_dnode_is_linked(&to->node)) {
    f6e6:	6803      	ldr	r3, [r0, #0]
    f6e8:	b13b      	cbz	r3, f6fa <z_abort_timeout+0x26>
			remove_timeout(to);
    f6ea:	f7ff f9e9 	bl	eac0 <remove_timeout>
			ret = 0;
    f6ee:	2000      	movs	r0, #0
	__asm__ volatile(
    f6f0:	f384 8811 	msr	BASEPRI, r4
    f6f4:	f3bf 8f6f 	isb	sy
}
    f6f8:	bd10      	pop	{r4, pc}
	int ret = -EINVAL;
    f6fa:	f06f 0015 	mvn.w	r0, #21
    f6fe:	e7f7      	b.n	f6f0 <z_abort_timeout+0x1c>

0000f700 <z_get_next_timeout_expiry>:
{
    f700:	b510      	push	{r4, lr}
	__asm__ volatile(
    f702:	f04f 0320 	mov.w	r3, #32
    f706:	f3ef 8411 	mrs	r4, BASEPRI
    f70a:	f383 8811 	msr	BASEPRI, r3
    f70e:	f3bf 8f6f 	isb	sy
		ret = next_timeout();
    f712:	f7ff f9ef 	bl	eaf4 <next_timeout>
	__asm__ volatile(
    f716:	f384 8811 	msr	BASEPRI, r4
    f71a:	f3bf 8f6f 	isb	sy
}
    f71e:	bd10      	pop	{r4, pc}

0000f720 <z_set_timeout_expiry>:
{
    f720:	b570      	push	{r4, r5, r6, lr}
    f722:	4604      	mov	r4, r0
    f724:	460d      	mov	r5, r1
	__asm__ volatile(
    f726:	f04f 0320 	mov.w	r3, #32
    f72a:	f3ef 8611 	mrs	r6, BASEPRI
    f72e:	f383 8811 	msr	BASEPRI, r3
    f732:	f3bf 8f6f 	isb	sy
		int next_to = next_timeout();
    f736:	f7ff f9dd 	bl	eaf4 <next_timeout>
		if (!imminent && (sooner || IS_ENABLED(CONFIG_SMP))) {
    f73a:	2801      	cmp	r0, #1
    f73c:	dd05      	ble.n	f74a <z_set_timeout_expiry+0x2a>
    f73e:	42a0      	cmp	r0, r4
    f740:	dd03      	ble.n	f74a <z_set_timeout_expiry+0x2a>
			z_clock_set_timeout(ticks, is_idle);
    f742:	4629      	mov	r1, r5
    f744:	4620      	mov	r0, r4
    f746:	f7fd fbc5 	bl	ced4 <z_clock_set_timeout>
	__asm__ volatile(
    f74a:	f386 8811 	msr	BASEPRI, r6
    f74e:	f3bf 8f6f 	isb	sy
}
    f752:	bd70      	pop	{r4, r5, r6, pc}

0000f754 <z_tick_get_32>:

uint32_t z_tick_get_32(void)
{
    f754:	b508      	push	{r3, lr}
#ifdef CONFIG_TICKLESS_KERNEL
	return (uint32_t)z_tick_get();
    f756:	f7ff fae7 	bl	ed28 <z_tick_get>
#else
	return (uint32_t)curr_tick;
#endif
}
    f75a:	bd08      	pop	{r3, pc}

0000f75c <k_heap_init>:
{
    f75c:	b410      	push	{r4}
    f75e:	f100 040c 	add.w	r4, r0, #12
	list->tail = (sys_dnode_t *)list;
    f762:	e9c0 4403 	strd	r4, r4, [r0, #12]
}
    f766:	bc10      	pop	{r4}
	sys_heap_init(&h->heap, mem, bytes);
    f768:	f7ff bc8a 	b.w	f080 <sys_heap_init>

0000f76c <_OffsetAbsSyms>:
#include "offsets_aarch64.c"
#else
#include "offsets_aarch32.c"
#endif

GEN_ABS_SYM_END
    f76c:	4770      	bx	lr
